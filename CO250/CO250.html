<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>CO250 | Anthony Zhang</title>
  <link rel="stylesheet" href="../css/base.css" type="text/css">
  <link rel="stylesheet" href="../css/note.css" type="text/css">
  <link rel="stylesheet" href="../highlight/styles/default.css">
  <link rel="stylesheet" href="../highlight/styles/paraiso-light.css">
  <script src="../highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script src="../katex/katex.min.js" type="text/javascript"></script>
  <link rel="stylesheet" href="../katex/katex.min.css" />
  <script type="text/javascript">
  window.onload = function() {
    document.getElementsByClassName("status-banner")[0].style.display = "block";
    setTimeout(function() {
      renderMathElements(document.getElementsByClassName("math"));
      document.getElementsByClassName("status-banner")[0].style.display = "none";
    }, 50); // delay to allow status banner to show
  }

  function renderMathElements(mathElements) {
    var mathOptions = {
      macros: {
        "\\set": "\\left\\{ #1 \\right\\}",
        "\\tup": "\\left\\langle #1 \\right\\rangle",
        "\\abs": "\\left\\lvert #1 \\right\\rvert",
        "\\floor": "\\left\\lfloor #1 \\right\\rfloor",
        "\\ceil": "\\left\\lceil#1 \\right\\rceil",
        "\\mb": "\\mathbb{#1}",
        "\\rem": "\\operatorname{rem}",
        "\\ord": "\\operatorname{ord}",
        "\\sign": "\\operatorname{sign}",
        "\\imag": "\\bm{i}",
        "\\dee": "\\mathop{}\\!\\mathrm{d}",
        "\\lH": "\\overset{\\text{l'H}}{=}",
        "\\evalat": "\\left.\\left(#1\\right)\\right|",
        "\\sech": "\\operatorname{sech}",
        "\\spn": "\\operatorname{Span}",
        "\\proj": "\\operatorname{proj}",
        "\\prp": "\\operatorname{perp}",
        "\\refl": "\\operatorname{refl}",
        "\\magn": "\\left\\lVert #1 \\right\\rVert",
        "\\rank": "\\operatorname{rank}",
        "\\trace": "\\operatorname{trace}",
        "\\sys": "\\left[ #1 \\mid #2\\space \\right]",
        "\\range": "\\operatorname{Range}",
        "\\adj": "\\operatorname{adj}",
        "\\cof": "\\operatorname{cof}",
        "\\coord": "{\\left\\lbrack #1 \\right\\rbrack}_{#2}",
        "\\diag": "\\operatorname{diag}",
        "\\formlp": "\\operatorname{Form}(\\mathcal{L}^P)",
        "\\argmin": "\\operatorname{argmin}",
        "\\argmax": "\\operatorname{argmax}",
        "\\sgn": "\\operatorname{sgn}",

        // not yet available in KaTeX
        "\\bm": "\\mathbf", //wip: should be italic, but isn't
      },
    };
    for (var i=0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      try {
        katex.render(texText.data, mathElements[i], mathOptions);
      } catch (e) {
        console.error(e);
        console.log(mathElements[i]);
      }
    }
  }
  </script>
</head>
<body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68271407-1', 'auto');
    ga('send', 'pageview');

  </script>
  <h1>Lecture Notes by <a href="/">Anthony Zhang</a>.</h1>
  <ul class="site_links">
    <li><a href="/blog/" class="page">blog</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.github.io/University-Notes" class="page">notes</a></li>
    <span class="divider"></span>
    <li><a href="/resume.pdf" class="page">résumé</a></li>
    <span class="divider"></span>
    <li><a href="https://github.com/Uberi" class="contact">github</a></li>
    <span class="divider"></span>
    <li><a href="https://www.linkedin.com/in/uberi/" class="contact">linkedin</a></li>
    <span class="divider"></span>
    <li><a href="mailto:me@anthonyz.ca" class="contact">email</a></li>
    <span class="divider"></span>
    <li><a href="https://www.facebook.com/anthony.zhang.user" class="contact">facebook</a></li>
    <span class="divider"></span>
    <li><a href="https://twitter.com/anthony926535" class="contact">twitter</a></li>
    <span class="divider"></span>
    <li><a href="https://keybase.io/uberi" class="info">public key</a></li>
  </ul>
<h1 id="co250">CO250</h1>
<p>Introduction to optimization.</p>
<pre><code>Levent Tunçel
Section 081 (online)
Email: ltuncel@uwaterloo.ca</code></pre>
<h1 id="section">3/1/17</h1>
<p>In this course, we will be studying linear programming, integer programming, the Simplex algorithm, and the concept of duality, as well as various ways to efficiently approximate answers to these sorts of problems.</p>
<p>An <strong>abstract optimization problem</strong> (also known as a &quot;P&quot;) is a problem in which we are trying to maximize or minimize a certain objective function - finding the inputs to the function, subject to certain constraints, such that the value of the function is maximised. In other words, given <span class="math inline">A \subseteq \mb{R}^n</span> (the set of all <strong>feasible inputs</strong>, also known as the <strong>feasible region</strong>) and a function <span class="math inline">f: A \to \mb{R}</span> (the <strong>objective function</strong>), find <span class="math inline">x \in A</span> such that <span class="math inline">f(x)</span> is the global maximum/minimum.</p>
<p>Optimization problems show up in almost every industry - hardware companies might want to simplify their circuit layouts, hotels might want to fill the most rooms possible at the highest price, and a factory might want to generate the most profit given constraints on materials and labour. Also, you can use it to play Pandemic optimally.</p>
<p>There are three types of abstract optimization problems:</p>
<ul>
<li>Linear programming problems (also known as LPs) are abstract optimization problems where <span class="math inline">A</span> is representable as a set of linear equations/inequalities, and <span class="math inline">f</span> is a linear function.</li>
<li>Integer programming problems (also known as IPs) are linear programming problems where <span class="math inline">A \subseteq \mb{Z}^n</span>.</li>
<li>Non-linear programming problems (also known as NLPs) are abstract optimization problems where <span class="math inline">A</span> cannot be represented as a set of linear equations/inequalities, or <span class="math inline">f</span> is non-linear.</li>
</ul>
<p>Abstract optimization problems are usually given as prose descriptions of the problems, which we then turn into abstract mathematical models/programs/problems. Then, we can take advantage of the many powerful computer solvers available today to automatically find optimal solutions.</p>
<p>Suppose a company produces either plastic carrots (which sell for $5 each and take 4 minutes to make) or rubber potatoes (which sell for $8 each and take 8 minutes to make). The company has 500 minutes available in the rest of the day, and the machine that makes either of these products can only be used up to 100 times - how many of each product should be made to maximize profit?</p>
<blockquote>
<p>First, we define our decision variables - the actual values we are trying to find. Let <span class="math inline">c</span> be the number of carrots, and <span class="math inline">p</span> be the number of potatoes.<br />
Profit can now be defined as a function of those decision variables: <span class="math inline">f(c, p) = 5c + 8p</span>.<br />
Next, we can define constraints to specify <span class="math inline">A</span>. There are only 500 minutes left, and the time spent depends on the number of each product made, so <span class="math inline">4c + 8p \le 500</span>. There are only 100 products left that we can make, and this is simply the number of carrots and potatoes, so <span class="math inline">c + p \le 100</span>. Additionally, <span class="math inline">c</span> and <span class="math inline">p</span> must be non-negative, since they represent the number of each product.<br />
We now have a mathematical model of the problem: &quot;maximize <span class="math inline">5c + 3p</span> subject to <span class="math inline">4c + 3p \le 500</span> and <span class="math inline">c + p \le 100</span>&quot;.</p>
</blockquote>
<p>A <strong>feasible solution</strong> to an abstract optimization problem is any <span class="math inline">x \in A</span> - any variable assignment such that the constraints of the problem are satisfied, like <span class="math inline">c = 50, p = 10</span>. An <strong>optimal</strong> solution is one that actually solves the problem - a feasible solution that results in the global maximum/minimum of the objective function. Likewise, feasible solutions to prose descriptions of the problem are assignments to the unknowns, like &quot;make 50 carrots and 10 potatoes&quot;.</p>
<p>To show that a mathematical model of a problem is correct (properly represents the prose description of the problem), we usually define a bijection between feasible solutions for the mathematical model and feasible solutions for the prose description of the problem, such that the bijection <strong>preserves cost</strong> - each <span class="math inline">x \in A</span> for the mathematical model must have <span class="math inline">f(x)</span> equal to the the profit in the prose description for its corresponding feasible solution.</p>
<p>For example, show that the model from the above example is correct:</p>
<blockquote>
<p><span class="math inline">4c + 3p \le 500 \land c + p \le 100</span> can be trivially bijected to &quot;carrots take 4 minutes to make and potatoes take 8 minutes, and the machine can only be used to make 100 products&quot;.<br />
Clearly, <span class="math inline">f(c, p) = 5c + 8p</span> has the same value as the profit since &quot;carrots sell for $5 each and potatoes sell for $8 each&quot;.</p>
</blockquote>
<h1 id="section-1">5/1/17</h1>
<p>In this course we will mostly focus on affine optimization problems, since solving general optimization problems is much harder.</p>
<p>An <strong>affine function</strong> is one that can be written as <span class="math inline">f(\vec{x}) = \vec{a} \cdot \vec{x} + \beta</span> where <span class="math inline">\vec{a} \in \mb{R}^n</span> and <span class="math inline">\beta \in \mb{R}</span>. If <span class="math inline">\beta = 0</span>, the function is also <strong>linear</strong>.</p>
<p>A <strong>linear program</strong> is an abstract optimization problem of the form <span class="math inline">\min \set{f(x) : x \in \mb{R}^n \wedge \left(\forall 1 \le i \le m, g_i(x) \le b_i\right)}</span> where <span class="math inline">f</span> is affine, <span class="math inline">g_1, \ldots, g_m</span> are all linear, and <span class="math inline">m</span> is finite. We might also replace <span class="math inline">\min</span> with <span class="math inline">\max</span> depending on the problem.</p>
<p>Usually we write this as: &quot;minimize <span class="math inline">f(x)</span> subject to <span class="math inline">g_1 \le b_1, \ldots, g_m \le b_m</span>&quot;, or &quot;maximize <span class="math inline">f(x)</span> s.t. <span class="math inline">g_1 \le b_1, \ldots, g_m \le b_m</span>&quot;. It's also common to use <span class="math inline">\vec{x} \le \mb{0}</span> as shorthand for <span class="math inline">x_1 \ge 0, \ldots, x_n \ge 0</span>.</p>
<p>Suppose an oil company in the next 4 months needs to supply 5000L, 8000L, 9000L, and 6000L, respectively, and oil costs them 0.75/L, 0.72/L, 0.92/L, and 0.90/L, respectively. The company has an oil tank that can store up to 4000L, and starts off with 2000L. Oil is bought at the beginning of the month, is used throughout the month, and is all dumped into the tank at the end of the month. What quantity of oil should be bought in each month to minimize cost?</p>
<blockquote>
<p>Clearly, the inputs are the quantity of oil bought in each month, <span class="math inline">b_1, b_2, b_3, b_4</span>. For convenience, we will also define the tank value at the beginning of each month, <span class="math inline">t_1, t_2, t_3, t_4</span>. Clearly, <span class="math inline">0 \le t_1 \le 4000, 0 \le t_2 \le 4000, 0 \le t_3 \le 4000, 0 \le t_4 \le 4000</span>, since the capacity of the tank is 4000L.<br />
The objective function we are minimizing is <span class="math inline">f(b_1, b_2, b_3, b_4) = 0.75b_1 + 0.72b_2 + 0.92b_3 + 0.90b_4</span>.<br />
Clearly, the tank level in month <span class="math inline">i</span> is <span class="math inline">t_1 = 2000, t_2 = t_1 + b_1 - 5000, t_3 = t_2 + b_2 - 8000, t_4 = t_3 + b_3 - 9000</span>, since the tank level is just the leftover oil after supplying the last month's oil.<br />
Clearly, in order to supply enough oil, we must have <span class="math inline">t_1 + b_1 \ge 5000, t_2 + b_2 \ge 8000, t_3 + b_3 \ge 9000, t_4 + b_4 \ge 6000</span>. However, the first three constraints are redundant with the previously defined constraints <span class="math inline">t_2 = t_1 + b_1 - 5000, t_3 = t_2 + b_2 - 8000, t_4 = t_3 + b_3 - 9000</span> and <span class="math inline">0 \le t_1, 0 \le t_2, 0 \le t_3, 0 \le t_4</span>, so we only need the <span class="math inline">t_4 + b_4 \ge 6000</span> constraint.<br />
These encode all of the problem constraints, so we have &quot;minimize <span class="math inline">0.75b_1 + 0.72b_2 + 0.92b_3 + 0.90b_4</span> subject to <span class="math inline">0 \le t_1 \le 4000, 0 \le t_2 \le 4000, 0 \le t_3 \le 4000, 0 \le t_4 \le 4000</span> and <span class="math inline">t_1 = 2000, t_2 = t_1 + b_1 - 5000, t_3 = t_2 + b_2 - 8000, t_4 = t_3 + b_3 - 9000</span> and <span class="math inline">t_4 \ge 6000</span>&quot;.<br />
If we use a linear programming solver, we get <span class="math inline">b_1 = 3000, b_2 = 12000, b_3 = 5000, b_4 = 6000</span>, which gives us the minimum cost 20890.</p>
</blockquote>
<p>Same thing, but minimise the maximum amount of oil purchased in any single month, and then show that the model is correct assuming that the above example's model was correct:</p>
<blockquote>
<p>From the previous example, we have the same constraints <span class="math inline">0 \le t_1 \le 4000, 0 \le t_2 \le 4000, 0 \le t_3 \le 4000, 0 \le t_4 \le 4000</span> and <span class="math inline">t_1 = 2000, t_2 = t_1 + b_1 - 5000, t_3 = t_2 + b_2 - 8000, t_4 = t_3 + b_3 - 9000</span> and <span class="math inline">t_4 \ge 6000</span>.<br />
However, the objective function is different - let <span class="math inline">M</span> be the maximum amount of oil bought in a single month, and we can minimize this value. We can define <span class="math inline">M</span> to be the maximum amount of oil bought in a single month by adding the constraints <span class="math inline">b_1 \le M, b_2 \le M, b_3 \le M, b_4 \le M</span>.<br />
These encode all of the problem constraints, so we have &quot;minimize <span class="math inline">M</span> subject to <span class="math inline">0 \le t_1 \le 4000, 0 \le t_2 \le 4000, 0 \le t_3 \le 4000, 0 \le t_4 \le 4000</span> and <span class="math inline">t_1 = 2000, t_2 = t_1 + b_1 - 5000, t_3 = t_2 + b_2 - 8000, t_4 = t_3 + b_3 - 9000</span> and <span class="math inline">t_4 \ge 6000</span> and <span class="math inline">b_1 \le M, b_2 \le M, b_3 \le M, b_4 \le M</span>&quot;.<br />
Now to show correctness. Suppose that <span class="math inline">M</span> is an optimal solution that has values <span class="math inline">b_1, b_2, b_3, b_4</span>. Since <span class="math inline">M</span> is a feasible solution, <span class="math inline">M \ge \max\set{b_1, b_2, b_3, b_4}</span>, and since <span class="math inline">M</span> is an optimal solution, it is the lowest such value that satisfies that, so <span class="math inline">M = \max\set{b_1, b_2, b_3, b_4}</span>. Therefore, <span class="math inline">M</span> is also the minimum maximum amount of oil purchased in any single month.</p>
</blockquote>
<h1 id="section-2">10/1/17</h1>
<p>Integer programs are just linear programs plus a integrality constraint - a constraint that all of the variables must be integers. When we formulate integer programs, we just add the constraint <span class="math inline">x_1, \ldots, x_n \text{ are integral}</span>.</p>
<p>An integer program is <strong>mixed</strong> if there are still non-integral variables, and <strong>pure</strong> if it only has integral variables. Integer programs are harder to solve than LPs.</p>
<p>The size of a linear/integer program generally refers to either the number of variables, of the number of constraints. The running time of an IP/LP solver algorithm is the number of steps it takes, as a function of the size of the IP/LP.</p>
<p>Efficient algorithms are polynomially. All LPs can be solved in polynomial time, though with a high exponent. Solving integer programs, however, are in NP, and so are highly unlikely to be solvable in polynomial time.</p>
<p>The knapsack problem is a special case of integer programs. Given a set of <span class="math inline">n</span> items, with values <span class="math inline">v_1, \ldots, v_n</span> and weights <span class="math inline">w_1, \ldots, w_n</span>, how do we maximize the total value of the items we can carry in a knapsack given that the total weight cannot exceed <span class="math inline">m</span>? From CS341, we know that if the number of items can be fractional, we can just use a greedy algorithm.</p>
<p>As an integer program, we have: maximize <span class="math inline">v_1 x_1 + \ldots = v_n x_n</span> subject to <span class="math inline">w_1 x_1 + \ldots + w_n x_n \le m</span>, <span class="math inline">x_1, \ldots, x_n \text{ are integral}</span>.</p>
<p>Write the IP for a knapsack problem where we have <span class="math inline">n = 4</span> and either <span class="math inline">x_1 + x_2</span> is at least 4, or <span class="math inline">x_3 + x_4</span> is at least 4, and we can only send <span class="math inline">x_3</span> if we send at least one <span class="math inline">x_4</span>:</p>
<blockquote>
<p>We're trying to maximize <span class="math inline">v_1 x_1 + v_2 x_2 + v_3 x_3 + v_4 x_4</span>.<br />
Clearly, we can express <span class="math inline">x_1 + x_2 \ge 4</span> AND <span class="math inline">x_3 = x_4 \ge 4</span>, but how do we express <span class="math inline">x_1 + x_2 \ge 4</span> OR <span class="math inline">x_3 + x_4 \ge 4</span>?<br />
One way to do this is by adding a binary variable <span class="math inline">y</span> to our IP, constrained such that <span class="math inline">0 \le y \le 1</span> and <span class="math inline">y \text{ is integral}</span>.<br />
We can now express <span class="math inline">x_1 + x_2 \ge 4 \lor x_3 + x_4 \ge 4</span> as <span class="math inline">x_1 + x_2 \ge 4y, x_3 + x_4 \ge 4(1 - y)</span>. Whenever <span class="math inline">y</span> is 0, <span class="math inline">4y</span> is 0, so <span class="math inline">x_1 + x_2</span> will always be true (since <span class="math inline">x_1</span> and <span class="math inline">x_2</span> are non-negative), while <span class="math inline">4(1 - y)</span> is 4, so the second constraint becomes <span class="math inline">x_3 + x_4 \ge 4</span>. Whenever <span class="math inline">y</span> is 1, <span class="math inline">4y</span> is 4, so the first constraint becomes <span class="math inline">x_1 + x_2 \ge 4</span>, while the second constraint is always true (since <span class="math inline">x_3</span> and <span class="math inline">x_4</span> are non-negative).<br />
Now, how do we express sending <span class="math inline">x_3</span> only if we send at least one <span class="math inline">x_4</span>? We want to express that <span class="math inline">x_4 = 0 \implies x_3 = 0</span>.<br />
One way to do this is to multiply <span class="math inline">x_4</span> by a large enough value so that if it's 1 or more, the resulting value will definitely be greater than <span class="math inline">x_3</span>. For example, <span class="math inline">x_3</span> must be no greater than <span class="math inline">\floor{\frac m {w_3}}</span>, so we can add the constraint <span class="math inline">x_3 \le \floor{\frac m {w_3}} x_4</span> to do this. When <span class="math inline">x_4 = 0</span>, <span class="math inline">\floor{\frac m {w_3}} x_4</span> is also 0, so <span class="math inline">x_3</span> must be 0 as well. When <span class="math inline">x_4 \ge 1</span>, <span class="math inline">\floor{\frac m {w_3}} x_4 \ge \floor{\frac m {w_3}}</span>, so <span class="math inline">x_3 \le \floor{\frac m {w_3}} x_4</span> is always true.<br />
Therefore, we can write this as &quot;maximize <span class="math inline">v_1 x_1 + v_2 x_2 + v_3 x_3 + v_4 x_4</span> subject to <span class="math inline">w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 \le m</span>, <span class="math inline">x_1 + x_2 \ge 4y</span>, <span class="math inline">x_3 + x_4 \ge 4(1 - y)</span>, <span class="math inline">0 \le y \le 1</span>, <span class="math inline">y \text{ is integral}</span>, <span class="math inline">x_3 \le \floor{\frac m {w_3}} x_4</span>, <span class="math inline">x_1, x_2, x_3, x_4 \ge 0</span>, <span class="math inline">x_1, x_2, x_3, x_4 \text{ is integral}</span>&quot;.</p>
</blockquote>
<p>The above example demonstrates a common trick of using a <strong>binary variable</strong> to express logical constraints involving disjunction. The binary variable lets us make constraints that apply when it has one value, and always be true for other values.</p>
<p>Scheduling is one of the most common optimization problems in industry. Suppose we have the coffee shop that is open on weekdays, hires workers that work for 4 consecutive weekdays per week (can wrap around weeks, and ignoring weekends), and requires 3, 5, 9, 2, and 7 workers to meet demand on Monday through Friday, respectively. How do we hire the smallest number of workers that meets this demand, and how do we schedule them to meet this demand?</p>
<p>First, we could define 5 variables, <span class="math inline">x_1, \ldots, x_5</span>, for the number of workers who should start working on each weekday. Then, the objective becomes to minimize <span class="math inline">x_1 + \ldots + x_5</span>.</p>
<p>What are the feasible solutions? Well, the constraints are that the number of workers starting on each day must be non-negative, and that the demand is met each day. To ensure we have enough demand for each day, we can define five constraints for each weekday. For example, for Monday demand to be met, we need the number of workers who start on Monday, Friday, Thursday, or Wednesday to be at least 3, since Monday demand is 3 and on Monday, we have workers from up to 4 days ago: <span class="math inline">x_1 + x_5 + x_4 + x_3 \ge 3</span>.</p>
<p>So, the problem becomes: &quot;minimize <span class="math inline">x_1 + \ldots + x_5</span> subject to <span class="math inline">x_1 + x_5 + x_4 + x_3 \ge 3</span>, <span class="math inline">x_2 + x_1 + x_5 + x_4 \ge 5</span>, <span class="math inline">x_3 + x_2 + x_1 + x_5 \ge 9</span>, <span class="math inline">x_4 + x_3 + x_2 + x_1 \ge 2</span>, <span class="math inline">x_5 + x_4 + x_3 + x_2 \ge 7</span>, and <span class="math inline">x_1, \ldots, x_5 \ge 0</span>&quot;.</p>
<p>Suppose we wanted to constrain a variable <span class="math inline">x</span> to be one of <span class="math inline">k_1, \ldots, k_n</span>. One way we could do this is to have binary variables <span class="math inline">y_1, \ldots, y_n</span>, where <span class="math inline">y_i</span> represents <span class="math inline">x = k_i</span> - adding a constraint of the form <span class="math inline">x = k_1 y_1 + \ldots + k_n y_n</span>. Then, we can ensure that exactly one of them is true by adding the constraint <span class="math inline">y_1 + \ldots y_n = 1</span>.</p>
<h1 id="section-3">12/1/17</h1>
<p>Another common type of linear programming problem in the real world is graph optimization. For example, how do we find the shortest path on a map? How do we optimize a microchip layout?</p>
<p>For the shortest path on a map example, we can associate street intersections with vertices, and streets with edges, weighted by the distance (a non-negative real number) along its length between intersections.</p>
<p>An <span class="math inline">s, t</span>-walk in a graph is a sequence of edges <span class="math inline">s v_1, v_1 v_2, \ldots, v_k t</span>. An <span class="math inline">s, t</span>-path is an <span class="math inline">s, t</span>-walk such that non-consecutive edges in the sequence don't share any vertices (we never revisit the same vertex twice).</p>
<p>The length of an <span class="math inline">s, t</span>-path is the sum of the weights of the edges in the path. So, given a graph <span class="math inline">G = \tup{V, E}</span>, a weight function <span class="math inline">w: E \to \mb{R}</span>, and two vertices <span class="math inline">s, t</span>, we want to find the minimum length <span class="math inline">s, t</span>-path. How do we write this as an IP?</p>
<p>Suppose we have tasks <span class="math inline">t = t_1, \ldots, t_n</span> and machines <span class="math inline">m = m_1, \ldots, m_n</span>, and <span class="math inline">c_{m_i, t_j}</span> represents the cost of having machine <span class="math inline">m_i</span> perform task <span class="math inline">t_j</span>. How do we match machines to tasks to minimize total cost?</p>
<blockquote>
<p>Create a graph with one vertex for each job and edges between them weighted by the corresponding cost.<br />
We want to find the perfect (every vertex in the graph is incident to an edge in the matching) matching (subset of edges such that none share vertices) in the bipartite graph with the minimum total weight.<br />
Let <span class="math inline">\delta(v)</span> be a function that returns the set of all edges incident to a given vertex. Then a set of edges <span class="math inline">M</span> is a perfect matching if and only if <span class="math inline">\forall v \in V, \magn{M \cap \delta(v)} = 1</span>.<br />
For our IP, we can have a binary variable <span class="math inline">x_{\text{machine}, \text{task}}</span> for every edge <span class="math inline">\tup{\text{machine}, \text{task}}</span>. Now we can simply minimize <span class="math inline">\sum_{m_i \in m, t_j \in t} c_{m_i, t_j} x_{m_i, t_j}</span>.<br />
To constrain solutions to perfect matchings only, we can add the constraints <span class="math inline">\sum_{m_i \in m} \sum_{t_j \in \delta(m_i)} x_{m_i, t_j} = 1</span> and <span class="math inline">\sum_{t_j \in t} \sum_{m_i \in \delta(t_j)} x_{m_i, t_j} = 1</span> (for each vertex, choose exactly one incident edge).</p>
</blockquote>
<h1 id="section-4">17/1/17</h1>
<p>The <strong>shortest path</strong> problem: given a graph <span class="math inline">G = \tup{V, E}</span>, what is the <span class="math inline">s, t</span>-path that has the minimum total length? We want to formulate this as an IP.</p>
<p>Recall from MATH239 that a <strong>cut</strong> in a graph is a partitioning of <span class="math inline">V</span> into two disjoint subsets, often written as just one of the sets. In other words, a cut is a pair <span class="math inline">\tup{S, T}</span> such that <span class="math inline">S \subseteq V, T \subseteq V, S \cap T = \emptyset, S \cup T = V</span>.</p>
<p>An <span class="math inline">s, t</span>-cut is a set of edges rather than a pair of sets of vertices. Let <span class="math inline">\delta(S) = \set{\set{u, v} \in E : u \in S, v \notin S}</span> for <span class="math inline">S \subseteq V</span>. Then given <span class="math inline">s \in S</span> and <span class="math inline">t \notin S</span>, <span class="math inline">\delta(S)</span> is an <span class="math inline">s, t</span>-cut. To enumerate all <span class="math inline">s, t</span>-cuts, we can simply find all subsets of <span class="math inline">V</span> that contain <span class="math inline">s</span> but not <span class="math inline">t</span>, then apply <span class="math inline">\delta</span> to those sets of vertices.</p>
<p>Clearly, if we remove the edges contained in the <span class="math inline">s, t</span>-cut from the graph, <span class="math inline">s</span> and <span class="math inline">t</span> would no longer be connected. Therefore, every <span class="math inline">s, t</span>-path must contain at least one edge from every <span class="math inline">s, t</span>-cut.</p>
<p>Also, if <span class="math inline">S \subseteq E</span> contains at least one edge from every <span class="math inline">s, t</span>-cut, then <span class="math inline">S</span> also is a superset of an <span class="math inline">s, t</span>-path. This is because if <span class="math inline">S</span> had an edge from every <span class="math inline">s, t</span>-cut and didn't have an <span class="math inline">s, t</span>-path, the set of all vertices <span class="math inline">R</span> that can be reached from <span class="math inline">s</span> is an <span class="math inline">s, t</span>-cut (since it includes <span class="math inline">s</span> but not <span class="math inline">t</span>, as no <span class="math inline">s, t</span>-path exists by assumption), so <span class="math inline">S</span> must include an edge from <span class="math inline">\delta(R)</span>. However, <span class="math inline">S</span> can't contain any edges from <span class="math inline">\delta(R)</span>, because if it did contain an edge <span class="math inline">\set{u, v}</span> then both <span class="math inline">u</span> and <span class="math inline">v</span> should have been in <span class="math inline">R</span> (since they're reachable from <span class="math inline">s</span>). Therefore, <span class="math inline">S</span> must also contain an <span class="math inline">s, t</span>-path.</p>
<p>Define binary variables <span class="math inline">x_1, \ldots, x_m</span> for each edge <span class="math inline">e_1, \ldots, e_m</span> being or not being in the shortest path, respectively. Let <span class="math inline">w_1, \ldots, w_n</span> be the weights of each edge <span class="math inline">e_1, \ldots, e_m</span>, respectively.</p>
<p>Clearly, we want to minimize <span class="math inline">x_1 w_1 + \ldots + x_m w_m</span> (i.e., the length of the path). What are the feasible solutions (i.e., supersets of <span class="math inline">s, t</span>-paths)?</p>
<p>To be an <span class="math inline">s, t</span>-path, the edges of the path must include at least one edge from every <span class="math inline">s, t</span>-cut. This is a lot easier to write as constraints: we have one constraint for each <span class="math inline">s, t</span>-cut <span class="math inline">\delta(S)</span>, and each constraint ensures that at least one of the edge variables <span class="math inline">T \subseteq \set{x_1, \ldots, x_m}</span> corresponding to <span class="math inline">\delta(S)</span> is true.</p>
<p>For example, given the graph <span class="math inline">G = \tup{\set{a, b, s, t}, \set{ab, as, at, bs, bt}}</span> with weights <span class="math inline">w_1, \ldots, w_5</span>, we might write the shortest path problem as &quot;minimize <span class="math inline">x_1 w_1 + \ldots + x_5 w_5</span> subject to <span class="math inline">x_2 + x_4 \ge 1</span> (for the <span class="math inline">s, t</span>-cut <span class="math inline">\set{sa, sb}</span>), <span class="math inline">x_1 + x_2 + x_3 \ge 1</span> (for the <span class="math inline">s, t</span>-cut <span class="math inline">\set{ab, as, at}</span>), <span class="math inline">x_1 + x_2 + x_5 \ge 1</span> (for the <span class="math inline">s, t</span>-cut <span class="math inline">\set{ab, as, bt}</span>), <span class="math inline">x_3 + x_5</span> (for the <span class="math inline">s, t</span>-cut <span class="math inline">\set{at, bt}</span>), and <span class="math inline">x_1, \ldots, x_m</span> are non-negative integers&quot;.</p>
<p>Note that we don't need an upper bound on <span class="math inline">x_1, \ldots, x_m</span>. This is because if it was greater than zero, then it wouldn't be an optimal solution.</p>
<p><strong>Nonlinear programs</strong> are problems of the form &quot;minimize <span class="math inline">f(x)</span> subject to <span class="math inline">g_1(x) \le 0, \ldots, g_m(x) \le 0</span>&quot; where <span class="math inline">f, g_1, \ldots, g_m: \mb{R}^n \to \mb{R}</span>. This is a superset of linear programs and integer programs. Basically, we can do arbitrary constraints, math permitting.</p>
<p>For example, we can minimize Euclidean distance by using an objective function <span class="math inline">(x_1 - p_1)^2 + (x_2 - p_2)^2 + (x_3 - p_3)^2</span>. Another example is constraining variables to integers: simply add the constraint <span class="math inline">\sin(\pi x) = 0</span> to ensure that <span class="math inline">x</span> is an integer, or <span class="math inline">x(1 - x) = 0</span> to ensure that <span class="math inline">x</span> is either 0 or 1.</p>
<p>It's even possible to write Fermat's last theorem as a single NLP: &quot;minimize <span class="math inline">(a^n + b^n - c^n)^2</span> subject to <span class="math inline">\sin(\pi a) = 0, \sin(\pi b) = 0, \sin(\pi c) = 0, \sin(\pi n) = 0, a, b, c \ge 1, n \ge 3</span>&quot; - the objective function solution is 0 if and only if <span class="math inline">a^n + b^n = c^n</span>, and the theorem is true if and only if the optimal value is greater than 0.</p>
<h1 id="section-5">23/1/17</h1>
<p>What does it mean to solve an optimization problem? What is a solution to an optimization problem?</p>
<p>Consider the LP &quot;maximize <span class="math inline">2x_1 + 3x_2</span> subject to <span class="math inline">x_1 + x_2 \le 1, x_1, x_2 \ge 0</span>&quot;. Clearly, in this case the optimal solution is simply <span class="math inline">x_1 = 1, x_2 = 0</span>. However, in general, it is more difficult to say what exactly can be considered a solution.</p>
<p>A <strong>feasible solution</strong> is an assignment of values to each of the variables in the LP such that all of the constraints are satisfied - regardless of the objective function value. A <strong>feasible</strong> optimization problem is one that has at least one feasible solution, and an <strong>infeasible</strong> optimization problem is one that has none. An <strong>optimal solution</strong> is a feasible solution where the objective function is maximized (for a maximization problem), or minimized (for a minimization problem).</p>
<p>However, an optimization problem having a feasible solution doesn't mean that it has an optimal solution - the maximum/minimum objective function value could be unbounded, like for &quot;maximize <span class="math inline">x</span> subject to <span class="math inline">x \ge 0</span>&quot;. If for any feasible solution there exists another with a higher/lower objective function value (depending on whether it's a maximization/minimization problem), the optimization problem is <strong>unbounded</strong>, and otherwise, it is <strong>bounded</strong>.</p>
<p>Consider the optimization problem &quot;maximize <span class="math inline">x</span> subject to <span class="math inline">x &lt; 1</span>&quot;. Clearly, this is feasible (<span class="math inline">x = 0</span> is a solution), and bounded (<span class="math inline">x \le 1</span> because <span class="math inline">x &lt; 1</span>), yet it has no optimal solution - the objective function can always get closer to 1 for any given value of <span class="math inline">x</span>! The same occurs for the optimization problem &quot;minimize <span class="math inline">\frac 1 x</span> subject to <span class="math inline">x \ge 1</span>&quot;. Note that neither of these are LPs, because one uses a strict inequality, and the other a division.</p>
<p>LPs are a bit better behaved than general optimization problems. According to the <strong>Fundamental Theorem of Linear Programming</strong>, an LP either has at least one optimal solution, is infeasible, or is unbounded.</p>
<p>An LP solver should therefore output one of the following: an optimal solution to the input LP (plus proof that it's optimal), a proof that the LP is infeasible, or a proof that the LP is unbounded.</p>
<p>Consider the linear system <span class="math inline">A\vec x = \vec b, \vec x \ge \vec 0</span>. If we can find a <span class="math inline">\vec y</span> such that <span class="math inline">{\vec y}^T A \ge {\vec 0}^T</span> and <span class="math inline">{\vec y}^T \vec b &lt; {\vec 0}^T</span>, then the system can't have any solutions. In other words, we can add/subtract/scale certain equality constraints in the linear system together to get a new constraint such that the coefficients of the constraint are all non-negative, yet the right hand side is negative. Here, <span class="math inline">\vec y</span> simply represents the fact that we're adding/subtracting/scaling rows in <span class="math inline">A</span> and elements in <span class="math inline">\vec b</span> to form a new constraint.</p>
<p>If we have such a constraint (left side coefficients non-negative, right side negative), then the left side of that constraint must be a non-negative value (since the elements of <span class="math inline">\vec x</span> are also non-negative) and the right side is negative (by assumption), so this constraint is not satisfiable - <strong>the LP must be infeasible</strong>.</p>
<p>According to <strong>Farkas' Lemma</strong>, if there's no feasible solutions, then a <span class="math inline">\vec y</span> that satisfies those conditions must exist. Therefore, a value of <span class="math inline">\vec y</span> such that <span class="math inline">{\vec y}^T A \ge {\vec 0}^T</span> and <span class="math inline">{\vec y}^T \vec b &lt; 0</span> is a <strong>proof of infeasibility</strong>. For an LP in SEF, a value <span class="math inline">\vec y</span> such that <span class="math inline">{\vec y}^T A = {\vec 0}^T</span> and <span class="math inline">{\vec y}^T \vec b \ne 0</span> works just as well for proof purposes - a linear combination of constraints that results in the left side being zero and the right side nonzero.</p>
<p>For example, consider an LP with constraints <span class="math inline">3x_1 - 2x_2 = 6, 2x_1 - x_2 = 2</span>. If we choose <span class="math inline">y = \begin{bmatrix} -1 \\ 2 \end{bmatrix}</span>, then we get <span class="math inline">{\vec y}^T A = \begin{bmatrix} 1 &amp; 0 \end{bmatrix}</span> and <span class="math inline">{\vec y}^T \vec b = -4</span>. This means that the two constraints, with the first one subtracted from the second one doubled, imply the constraint <span class="math inline">x_1 = -2</span>, which is always infeasible because <span class="math inline">\vec x \ge \vec 0</span>.</p>
<p>To prove that an optimal solution <span class="math inline">\vec x</span> for an LP is actually optimal, we simply need to prove that for any feasible solution <span class="math inline">\vec x&#39;</span>, the objective function value is less or equal to the objective function value for <span class="math inline">\vec x</span> - basically, proving that the upper bound of the objective function occurs at <span class="math inline">\vec x</span>. This is a <strong>proof of optimality</strong>. We will look at how to construct these proofs systematically later on, using the strong duality theorem.</p>
<p>Consider the LP &quot;maximize <span class="math inline">2x_1 + 3x_2</span> subject to <span class="math inline">x_1 + x_2 \le 1, x_1, x_2 \ge 0</span>&quot;. Clearly, any feasible solution <span class="math inline">x_1, x_2</span> must be</p>
<p>To prove that an LP is unbounded, we construct a family of feasible solutions <span class="math inline">\vec x(t)</span> for all <span class="math inline">t \ge 0</span>, then show that as <span class="math inline">t</span> goes to infinity, so does the value of the objective function. In other words, we need to prove that for any arbitrarily high objective function value (assuming a maximization problem), we can construct a variable assignment that is both a feasible solution, and results in that objective function value - a <strong>proof of unboundedness</strong>.</p>
<p>This family of feasible solutions is always a line in the linear space. Therefore, a family of feasible solutions <span class="math inline">\vec x(t) = \vec x_0 + t \vec r</span> such that for any <span class="math inline">z</span>, there exists a <span class="math inline">t</span> such that <span class="math inline">\vec x(t) = z</span> is a <strong>proof of unboundedness</strong>. In matrix form, a proof of unboundedness is simply a value of <span class="math inline">\vec x_0, \vec r</span> such that <span class="math inline">\vec x_0 \ge \vec 0, \vec r \ge \vec 0, A \vec x_0 = \vec b, A \vec r = \vec 0, {\vec c}^T \vec r &gt; 0</span>. Also, if the LP is unbounded, those values of <span class="math inline">\vec x_0, \vec r</span> must exist.</p>
<p>Consider the LP &quot;maximize <span class="math inline">x</span> subject to <span class="math inline">x \ge 0</span>&quot;. Clearly, for any objective function value <span class="math inline">z \ge 0</span>, we can construct an assignment <span class="math inline">x = z</span>, which must be a feasible solution since <span class="math inline">z \ge 0</span>. Additionally, the objective function value for the feasible solution <span class="math inline">x</span> must be <span class="math inline">z</span>. Therefore, the LP is unbounded, and a proof for that would be <span class="math inline">\vec x_0 = \begin{bmatrix} 0 \end{bmatrix}, \vec r = \begin{bmatrix} 1 \end{bmatrix}</span>.</p>
<p>Basically, whichever outcome an LP has, there must exist a proof that that outcome is the case.</p>
<p>A <strong>free variable</strong> is a variable that is not constrained.</p>
<p>An LP is in <strong>standard equality form</strong> (SEF) if and only if all of the following are true:</p>
<ul>
<li>The LP is a maximization problem.</li>
<li>Every variable is constrained to be non-negative.</li>
<li>All constraints are equality constraints.</li>
</ul>
<p>In other words, an LP in SEF is a problem of the form &quot;maximize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">A \vec x = \vec b, \vec x \ge \vec 0</span>&quot;, where <span class="math inline">A</span> is an <span class="math inline">n</span> by <span class="math inline">m</span> coefficients matrix and <span class="math inline">\vec x, \vec b, \vec c \in \mb{R}^m</span>.</p>
<p>Every LP has an &quot;equivalent&quot; LP that is in SEF. By equivalent, we mean the original LP is unbounded if and only if the equivalent LP is unbounded, the original LP is infeasible if and only if the equivalent LP is infeasible, and an optimal solution of one can easily be used to compute an optimal solution of another.</p>
<p>To convert an LP into its equivalent in SEF:</p>
<ul>
<li>If the LP is a minimization problem, turn it into a maximization problem by inverting the objective function: &quot;minimize <span class="math inline">f(x)</span> subject to ...&quot; becomes &quot;maximize <span class="math inline">-f(x)</span> subject to ...&quot;.</li>
<li>Replace constraints of the form <span class="math inline">c_1 x_1 + \ldots c_k x_k \le b</span> with <span class="math inline">c_1 x_1 + \ldots c_k x_k + s = b</span> where <span class="math inline">s \ge 0</span> is a new variable.</li>
<li>Replace constraints of the form <span class="math inline">c_1 x_1 + \ldots c_k x_k \ge b</span> with <span class="math inline">c_1 x_1 + \ldots c_k x_k - s = b</span> where <span class="math inline">s \ge 0</span> is a new variable.</li>
<li>Replace free variables (variables that don't have upper or lower bounds) with <span class="math inline">a - b</span> where <span class="math inline">a \ge 0, b \ge 0</span> are new variables. Their difference can have any value, positive or negative.</li>
</ul>
<p>Once this is done, we have an equivalent LP in SEF. Also, we can easily convert optimal solutions for the LP in SEF into optimal solutions for the original LP, simply by taking the values of the corresponding variables and ignoring the newly introduced variables.</p>
<h1 id="section-6">25/1/17</h1>
<p>We can actually solve LPs by hand, by building an intuition for what would maximise the objective function, and trying to satisfy the constraints with that in mind.</p>
<p>For example, suppose we have the LP &quot;maximise <span class="math inline">4x_1 + 3x_2 + 7</span> subject to <span class="math inline">3x_1 + 2x_2 + x_3 = 2</span> and <span class="math inline">x_1 + x_2 + x_4 = 1</span> and <span class="math inline">x_1, x_2, x_3, x_4 \ge 0</span>&quot;. Clearly, <span class="math inline">x_1 = 0, x_2 = 0, x_3 = 2, x_4 = 1</span> is a feasible solution, because if we set <span class="math inline">x_1 = x_2 = 0</span>, the constraints become <span class="math inline">x_2 = 2, x_4 = 1</span>. This has objective value 7. How do we find a feasible solution with a higher objective function value?</p>
<p>To get a better objective function value, we need to either increase <span class="math inline">x_1</span> or <span class="math inline">x_2</span>, the two variables in the objective function. To keep things simple, we'll just arbitrarily choose to modify only one of the variables for now - maximize <span class="math inline">x_1</span> while keeping <span class="math inline">x_2 = 0</span>.</p>
<p>Now the LP becomes &quot;maximise <span class="math inline">4x_1 + 7</span> subject to <span class="math inline">3x_1 + x_3 = 2</span> and <span class="math inline">x_1 + x_4 = 1</span> and <span class="math inline">x_1, x_3, x_4 \ge 0</span>&quot;. To maximize this, we just need to maximize <span class="math inline">x_1</span>. Clearly, the LP is feasible whenever <span class="math inline">x_3 = 2 - 3x_1</span> and <span class="math inline">x_4 = 1 - x_1</span> - we have a feasible solution for every possible value of <span class="math inline">x_1</span> where all the non-negativity constraints are satisfied.</p>
<p>Since <span class="math inline">x_3 \ge 0</span> and <span class="math inline">x_3 = 2 - 3x_1</span>, <span class="math inline">2 - 3x_1 \ge 0</span>, so <span class="math inline">x_1 \le \frac 2 3</span>. Since <span class="math inline">x_4 \ge 0</span> and <span class="math inline">x_4 = 1 - x_1</span>, <span class="math inline">1 - x_1 \ge 0</span>, so <span class="math inline">x_1 \le 1</span>. Therefore, since we also know that <span class="math inline">x_1 \ge 0</span>, <span class="math inline">0 \le x_1 \le \frac 2 3</span>. Since we're trying to find the largest value of <span class="math inline">x_1</span> that still satisfies the constraints, <span class="math inline">x_1 = \frac 2 3</span>. This gives us an objective function value of <span class="math inline">\frac 8 3 + 7</span> with the solution <span class="math inline">x_1 = \frac 2 3, x_2 = 0, x_3 = 0, x_4 = \frac 1 3</span>, which is better than our original solution.</p>
<p>Turns out, however, this solution is still not optimal. Additionally, we can't increase <span class="math inline">x_2</span> without decreasing <span class="math inline">x_1</span> at this point, so we can't just repeat the trick with <span class="math inline">x_2</span> this time instead of <span class="math inline">x_1</span>. However, it would be possible to use the &quot;maximize one variable while keeping others in the objective function the same&quot; trick again if we rewrote the LP in what's known as <strong>canonical form</strong>. We will look at how to do this later.</p>
<p>The basic idea behind the simplex algorithm:</p>
<ol type="1">
<li>Find a feasible solution <span class="math inline">\vec x</span>. If not found, give a proof of infeasibility and stop.</li>
<li>Rewrite the LP in canonical form.</li>
<li>If <span class="math inline">\vec x</span> is optimal, give a proof of optimality and stop.</li>
<li>If <span class="math inline">\vec x</span> is unbounded, give a proof of unboundedness and stop.</li>
<li>Find a feasible solution with a higher objective function value than <span class="math inline">\vec x</span>.</li>
<li>Repeat steps 2-6 until the algorithm terminates.</li>
</ol>
<p>The main questions are: What's canonical form and how do we rewrite LPs in that form? Why does it ensure that we can find a better feasible solution?</p>
<h1 id="section-7">4/2/17</h1>
<p>The <strong>column sub-matrix</strong> notation allows us to select a subset of columns from a matrix into a new matrix: if <span class="math inline">A = \begin{bmatrix} a_{1, 1} &amp; \ldots &amp; a_{1, m} \\ \vdots &amp; \vdots &amp; \vdots \\ a_{n, 1} &amp; \ldots &amp; a_{n, m} \end{bmatrix}</span> and <span class="math inline">B = \set{b_1, \ldots, b_k}, 1 \le b_i \le m</span>, then <span class="math inline">A_B = \begin{bmatrix} a_{1, b_1} &amp; \ldots &amp; a_{1, b_k} \\ \vdots &amp; \vdots &amp; \vdots \\ a_{n, b_1} &amp; \ldots &amp; a_{n, b_k} \end{bmatrix}</span>. As a short form, we can also do <span class="math inline">A_j</span> where <span class="math inline">1 \le j \le m</span>, which means &quot;column <span class="math inline">j</span> of the matrix <span class="math inline">A</span>&quot;, a vector of size <span class="math inline">n</span>.</p>
<p>For a vector <span class="math inline">\vec x = \begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}</span>, we also often use the subscript to denote the row sub-matrix <span class="math inline">\vec x_B = \begin{bmatrix} x_{b_1} \\ \vdots \\ x_{b_k} \end{bmatrix}</span>. However, this isn't that common and it's generally preferred to write it out in full to avoid confusion.</p>
<h2 id="bases-and-basic-solutions">Bases and basic solutions</h2>
<p>A <strong>basis</strong> of a matrix is a subset of column indices <span class="math inline">B \subseteq \set{1, \ldots, m}</span> such that <span class="math inline">A_B</span> is a square matrix and <span class="math inline">A_B</span> is non-singular. In other words, <span class="math inline">B</span> is a set of size <span class="math inline">n</span>, and the columns of <span class="math inline">A_B</span> are linearly independent (so they can't be written as linear combinations of each other). Not all matrices will have a basis; for example, a 2 by 2 zero matrix (the only value of <span class="math inline">B</span> that could result in a square <span class="math inline">A_B</span> is <span class="math inline">\set{1, 2}</span>, but <span class="math inline">A_B</span> is singular).</p>
<p>We often denote the inverse of the basis as <span class="math inline">\overline B = \set{1, \ldots, m} - B</span> - the column indices for columns that are not in the basis <span class="math inline">B</span>.</p>
<p>From MATH136 we learned that the number of linearly independent columns in a matrix is the same as the number of linearly independent rows. This means that the number of independent columns is between 0 and the number of independent rows. Therefore, if we have a square matrix <span class="math inline">A_B</span>, it can only possibly be a basis if all of the rows of <span class="math inline">A</span> are independent; if there were less than <span class="math inline">n</span> independent rows, there would also be less than <span class="math inline">n</span> independent columns, so <span class="math inline">A_B</span> must be singular. Therefore, <strong>a matrix has a basis if and only if all of its rows are independent</strong>, and that basis is a <strong>set of <span class="math inline">n</span> independent columns in the matrix</strong> (which is a maximal set of independent columns in the matrix).</p>
<p>Suppose we have an LP in standard equality form: &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span>&quot;. If <span class="math inline">B</span> is a basis of <span class="math inline">A</span>, then a variable <span class="math inline">x_i</span> is a <strong>basic variable for <span class="math inline">B</span></strong> if <span class="math inline">i \in B</span>, or a <strong>non-basic variable for <span class="math inline">B</span></strong> if <span class="math inline">i \notin B</span> (i.e., <span class="math inline">i \in \overline B</span>). Essentially, the coefficients of each non-basic variable can be written as a linear combination of the coefficients of the basic variables.</p>
<p>A <strong>basic solution</strong> for an LP and a basis <span class="math inline">B</span> is a solution <span class="math inline">\vec x</span> for the LP such that <span class="math inline">A \vec x = \vec b</span> and all non-basic variables are set to 0. For the basic solution for a basis <span class="math inline">B = \set{b_1, \ldots, b_k}</span>, the LP becomes &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A_B \begin{bmatrix} x_{b_1} \\ \vdots \\ x_{b_k} \end{bmatrix} = \vec b</span>&quot;.</p>
<p>Since <span class="math inline">B</span> is a basis, <span class="math inline">A_B</span> must be invertible, so <span class="math inline">A_B^{-1} A_B \begin{bmatrix} x_{b_1} \\ \vdots \\ x_{b_k} \end{bmatrix} = A_B^{-1} \vec b</span>, or <span class="math inline">\vec x_B = A_B^{-1} \vec b</span>. Interestingly, this means that <strong>a basis <span class="math inline">B</span> has exactly one basic solution</strong>, and that solution is a vector <span class="math inline">\vec x</span> where <span class="math inline">{\vec x}_B = A_B^{-1} \vec b</span> and <span class="math inline">{\vec x}_{\overline B} = \vec 0</span>.</p>
<p>Note that a basic solution doesn't necessarily satisfy the non-negativity constraints <span class="math inline">\vec x \ge \vec 0</span>. A basic solution <span class="math inline">\vec x</span> is <strong>feasible</strong> if and only if it does satisfy this constraint <span class="math inline">\vec x \ge \vec 0</span>, because by definition it already satisfies <span class="math inline">A \vec x = \vec b</span>. Solutions can be any combination of feasible/not-feasible and basic/not-basic.</p>
<p>A <strong>basic solution</strong> <span class="math inline">\vec x</span> for an LP (without a specified basis) is a feasible solution that is a basic solution for the LP for one or more bases for that LP. So for some set of <span class="math inline">n</span> linearly independent columns <span class="math inline">\vec x</span> has corresponding values that result in the constraints being satisfied, and for all other columns <span class="math inline">\vec x</span> has the element 0.</p>
<p>Suppose again that we have an LP in standard equality form: &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span>&quot;. If the rows of <span class="math inline">A</span> are dependent (at least one row can be written as a linear combination of others), then either the LP is infeasible, or <span class="math inline">A</span> has a redundant constraint, which we can remove. Here's why: since there are dependent rows, one of the rows could be written as a linear combination of others, so we could cancel out its coefficients by adding/subtracting/scaling constraints to get the new constraint <span class="math inline">0x_1 + \ldots + 0x_m = k</span>. If <span class="math inline">k \ne 0</span>, then the constraint is clearly not satisfiable, so the LP is infeasible, and if <span class="math inline">k = 0</span>, then that constraint is redundant because it just says <span class="math inline">0 = 0</span>.</p>
<h2 id="canonical-form">Canonical form</h2>
<p>Suppose again that we have an LP in standard equality form: &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span>&quot;. Suppose <span class="math inline">B</span> is a basis for <span class="math inline">A</span>.</p>
<p>The LP is in <strong>canonical form</strong> if and only if <span class="math inline">A_B = I</span> (the column sub-matrix is the identity matrix) and <span class="math inline">c_{b_1} = \ldots = c_{b_k} = 0</span> (the objective function only contains non-basic variables).</p>
<p>Since <span class="math inline">A_B = I</span> for an LP in canonical form with respect to a basis <span class="math inline">B</span>, <span class="math inline">A_B^{-1} = I^{-1} = I</span>, so the basic solution for <span class="math inline">B</span> is just <span class="math inline">\vec x</span> such that <span class="math inline">{\vec x}_B = \vec b</span> and <span class="math inline">{\vec x}_{\overline B} = \vec 0</span>.</p>
<p>Interestingly, it's always possible to write an LP into canonical form given a basis, such that the new LP has the same feasible region and feasible solutions have the same objective function value as the original LP. How do we do this?</p>
<p>Suppose we have the LP in SEF &quot;maximize <span class="math inline">\begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} \vec x</span> subject to <span class="math inline">\begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 1 &amp; 2 \end{bmatrix} \vec x = \begin{bmatrix} 1 \\ 2 \end{bmatrix}</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;. One basis for this LP is <span class="math inline">B = \set{2, 3}</span> - it's a square matrix, and its columns are linearly independent.</p>
<p>To convert this LP into canonical form given <span class="math inline">B</span>, we start by making <span class="math inline">A_B</span> into the identity matrix. To do this, we subtract the first equality constraint from the second, and then swap them to get the equality constraints <span class="math inline">\begin{bmatrix} -1 &amp; 1 &amp; 0 &amp; 3 \\ 1 &amp; 0 &amp; 1 &amp; -1 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}</span>.</p>
<p>In general, to do this we left multiply both sides of <span class="math inline">A \vec x = \vec b</span> by <span class="math inline">A_B^{-1}</span> to get <span class="math inline">A_B^{-1} A \vec x = A_B^{-1} \vec b</span>. Since <span class="math inline">A_B^{-1} A</span> is the matrix formed by multiplying <span class="math inline">A_B^{-1}</span> with the columns of <span class="math inline">A</span> individually, the columns in <span class="math inline">B</span> will end up as columns of the identity matrix, so <span class="math inline">(A_B^{-1} A)_B</span> is indeed the identity matrix. Because <span class="math inline">A_B</span> is non-singular, <span class="math inline">A_B^{-1} A \vec x = A_B^{-1} \vec b</span> has the exact same solutions for <span class="math inline">\vec x</span> as <span class="math inline">A \vec x = \vec b</span>, too.</p>
<p>Now, we need to make <span class="math inline">\begin{bmatrix} c_{b_1} \\ \vdots \\ c_{b_k} \end{bmatrix} = \vec 0</span> - all basic variables should be removed from the objective function. To do this, we'll take a linear combination <span class="math inline">\vec y</span> of the equality constraints, to get <span class="math inline">{\vec y}^T \begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 1 &amp; 2 \end{bmatrix} \vec x = {\vec y}^T \begin{bmatrix} 1 \\ 2 \end{bmatrix}</span>, or <span class="math inline">0 = -{\vec y}^T \begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 1 &amp; 2 \end{bmatrix} \vec x + {\vec y}^T \begin{bmatrix} 1 \\ 2 \end{bmatrix}</span>.</p>
<p>We'll add the objective function to both sides of that, to get <span class="math inline">\begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} \vec x + {\vec y}^T \begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 1 &amp; 2 \end{bmatrix} \vec x = \begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} \vec x + {\vec y}^T \begin{bmatrix} 1 \\ 2 \end{bmatrix}</span>. Rearranging, we get <span class="math inline">\begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} \vec x = \left(\begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} - {\vec y}^T \begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 1 &amp; 2 \end{bmatrix}\right) \vec x + {\vec y}^T \begin{bmatrix} 1 \\ 2 \end{bmatrix}</span>.</p>
<p>Clearly, the left side is the objective function, and it's equal to the right side. However, we can manipulate <span class="math inline">\vec y</span> until the value that's being multiplied with <span class="math inline">\vec x</span> has zero entries for our basic variables! Basically, we want to choose <span class="math inline">\vec y</span> such that <span class="math inline">{\vec y}^T \begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 1 &amp; 2 \end{bmatrix}_{\set{2, 3}} = \begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix}_{\set{2, 3}}</span>. In other words, <span class="math inline">y_1 0 + y_2 1 = 0, y_1 1 + y_2 1 = 2</span>. Solving this system, we get <span class="math inline">\vec y = \begin{bmatrix} 2 \\ 0 \end{bmatrix}</span>.</p>
<p>Now <span class="math inline">\begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} \vec x = \left(\begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} - {\vec y}^T \begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 1 &amp; 2 \end{bmatrix}\right) \vec x + {\vec y}^T \begin{bmatrix} 1 \\ 2 \end{bmatrix}</span> becomes <span class="math inline">\begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} \vec x = \left(\begin{bmatrix} 0 &amp; 0 &amp; 2 &amp; 4 \end{bmatrix} - \begin{bmatrix} 2 &amp; 0 &amp; 2 &amp; -2 \end{bmatrix}\right) \vec x + 2 = \begin{bmatrix} -2 &amp; 0 &amp; 0 &amp; 6 \end{bmatrix} \vec x + 2</span>. So for feasible solutions, the objective function is exactly equal to <span class="math inline">\begin{bmatrix} -2 &amp; 0 &amp; 0 &amp; 6 \end{bmatrix} \vec x + 2</span>.</p>
<p>In general, we take an arbitrary linear combination of the constraints <span class="math inline">{\vec y}^T A \vec x = {\vec y} \vec b</span>, and then add the objective function to both sides to get <span class="math inline">{\vec c}^T \vec x + {\vec y}^T A \vec x = {\vec c}^T \vec x + {\vec y} \vec b</span>, and rearrange to get <span class="math inline">{\vec c}^T \vec x = \left({\vec c}^T - {\vec y}^T A\right) \vec x + {\vec y} \vec b</span>.</p>
<p>Then, we solve the linear system <span class="math inline">{\vec c}_B - {\vec y}^T A_B = {\vec 0}^T</span> for <span class="math inline">\vec y</span>. We can transpose both sides to write the formula as <span class="math inline">A_B^T \vec y = {\vec c}_B</span>, then multiply both sides by <span class="math inline">(A_B^{-1})^T</span> to get <span class="math inline">\vec y = (A_B^{-1})^T {\vec c}_B</span> (this is equivalent because <span class="math inline">A_B</span> is guaranteed to be non-singular). Then, we subsitute that value of <span class="math inline">\vec y</span> back into <span class="math inline">{\vec c}^T \vec x = \left({\vec c}^T - {\vec y}^T A\right) \vec x + {\vec y} \vec b</span> to get another way to write the objective function for feasible values of <span class="math inline">\vec x</span>.</p>
<p>So in general, given the LP in SEF &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;, the corresponding LP in canonical form for a basis <span class="math inline">B</span> can be computed as follows:</p>
<ol type="1">
<li>Let <span class="math inline">A&#39; = A_B^{-1} A</span> and <span class="math inline">\vec b&#39; = A_B^{-1} \vec b</span>.</li>
<li>Let <span class="math inline">\vec c&#39; = \left({\vec c}^T - \vec y^T A\right) \vec x</span> and <span class="math inline">z&#39; = \vec y^T \vec b</span> where <span class="math inline">\vec y = (A_B^{-1})^T {\vec c}_B</span>.</li>
<li>The new LP is &quot;maximize <span class="math inline">{\vec c&#39;}^T \vec x + z&#39;</span> subject to <span class="math inline">A&#39; \vec x = \vec b&#39;</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;.</li>
</ol>
<p>Aside: sometimes in this course we'll use the notation <span class="math inline">A^{-T}</span>, it represents inverse of transpose (<span class="math inline">(M^T)^{-1}</span>) or transpose of inverse (<span class="math inline">(M^{-1})^T</span>), which are equivalent to each other.</p>
<h2 id="simplex-algorithm">Simplex Algorithm</h2>
<p>Suppose we have an LP &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot; in canonical form for a basis <span class="math inline">B</span>, and a basic feasible solution <span class="math inline">\vec x</span>. The simplex algorithm requires us to find a better feasible solution from this, but how do we do that?</p>
<p>Essentially, to get a better feasible solution from an LP:</p>
<ol type="1">
<li>Pick a non-basic variable <span class="math inline">x_k \in \overline B</span> with a positive coefficient in the objective function (<span class="math inline">c_k &gt; 0</span>).
<ul>
<li>If there are no non-basic variables with a positive coefficient in the objective function, we've found the optimal solution! This is because the basic solution already has non-basic variables set to 0 (the smallest possible value). Since the LP is in canonical form, <span class="math inline">{\vec c}_B = \vec 0</span>, and <span class="math inline">{\vec c}_{\overline B} \le 0</span>, and <span class="math inline">\vec x \ge 0</span>, the objective function <span class="math inline">\vec c \cdot \vec x + z = {\vec c}_{\overline B} \cdot {\vec x}_{\overline B} + z</span> must be maximized at <span class="math inline">{\vec x}_{\overline B} = \vec 0</span>.</li>
</ul></li>
<li>Find the largest value of <span class="math inline">x_k</span> that keeps <span class="math inline">\vec x</span> within the feasible region (i.e., satisfying <span class="math inline">\vec x \ge 0</span>), by changing <span class="math inline">x_k</span> and the basic variables, while keeping all the non-basic variables other than <span class="math inline">x_k</span> at 0. Let <span class="math inline">x_k&#39;</span> be that value of <span class="math inline">x_k</span> and <span class="math inline">x_{b_1}&#39;, \ldots, x_{b_k}&#39;</span> be the values of the basic variables that allow that feasible solution.
<ul>
<li>Since the columns in the basis form an identity matrix, <span class="math inline">A_B {\vec x}_B = {\vec x}_B</span>. Since the other non-basic variables have 0 coefficients, <span class="math inline">A \vec x = \vec b</span> is just <span class="math inline">{\vec x}_B + x_k A_k = \vec b</span>, or <span class="math inline">{\vec x}_B = \vec b - x_k A_k</span>.</li>
<li>So to keep <span class="math inline">\vec x</span> feasible, we just need to find a value such that <span class="math inline">\vec x \ge \vec 0</span>. Since <span class="math inline">\vec x</span> was already a solution, we only need to ensure that condition holds for the variables we changed - the basic variables and <span class="math inline">x_k</span>: <span class="math inline">{\vec x}_B \ge 0, x_k \ge 0</span>.</li>
<li>This can be written as <span class="math inline">\vec b - x_k A_k \ge \vec 0, x_k \ge 0</span>. If we solve for <span class="math inline">x_k</span>, we get <span class="math inline">x_k = \min\set{\frac{b_i}{A_{i, k}} : 1 \le i \le n, A_{i, k} &gt; 0}</span>.</li>
<li>If the maximum is infinite, then the LP is unbounded. To prove this, we let <span class="math inline">\vec x(t)</span> be a function that outputs solutions to the LP, where <span class="math inline">{\vec x(t)}_B = \vec b - t A_k</span> and <span class="math inline">{\vec t}_{\overline B} = \vec 0</span>, and show that <span class="math inline">{\vec c}^t \vec x(t) \to \infty</span> as <span class="math inline">t \to \infty</span>. The certificate of unboundedness would then be <span class="math inline">\tup{B, A_k}</span>.</li>
<li>Also, the maximum is infinite exactly when <span class="math inline">A_k \le \vec 0</span>, so <strong>if all of the coefficients for <span class="math inline">x_k</span> are negative, the LP is unbounded</strong>. This is because if any element <span class="math inline">A_{i, k}</span> was positive, eventually <span class="math inline">x_k A_{i, k}</span> exceeds <span class="math inline">b_i</span> for a finitely large values of <span class="math inline">x_k</span>, which is an upper bound for <span class="math inline">x_k</span>.</li>
</ul></li>
<li>Now we have a new feasible solution <span class="math inline">\vec x&#39;</span> where <span class="math inline">x_i&#39; = \begin{cases} x_k&#39; &amp;\text{ if } i = k \\ x_i&#39; &amp;\text{ if } i \in B \\ x_i &amp;\text{ otherwise} \end{cases}</span>. In other words, the solution where we maximized <span class="math inline">x_k</span> and changed the basic variables starting from <span class="math inline">\vec x</span>. Additionally, this new feasible solution has a greater or equal objective function value.
<ul>
<li>Note that <strong>this new feasible solution is also a basic feasible solution</strong>!</li>
<li>The new feasible solution is basic because when we maximized <span class="math inline">x_k</span>, it was no longer 0, so it becomes part of the basis for the new feasible solution. At the same time, when we maximize <span class="math inline">x_k</span>, <strong>at least one of the basic variables now has value 0</strong> (if the basic variables ended up all positive, then <span class="math inline">x_k</span> could have been increased more by decreasing them, so <span class="math inline">x_k</span> wouldn't have been maximized - a contradiction!) - one of the basic variables that are now 0 are not part of the new feasible solution's basis.</li>
<li>Here's why the new feasible solution's basis is in fact a basis: first, we removed one of the existing columns in favor of column <span class="math inline">k</span>, so the number of columns hasn't changed. Second, the new column must be linearly independent of the other columns in the basis, because the basic variable that was excluded from the new basis was originally non-zero, so it was necessary to form a linear combination of columns equal to <span class="math inline">x_k</span>'s column.</li>
</ul></li>
</ol>
<p>So, we started with an LP in canonical form for a feasible basis, and used it to obtain a better feasible basis (or a proof of unboundedness). We can then rewrite the LP in canonical form again and repeat this process until we either find an optimal solution or prove that it's unbounded. This is the <strong>simplex algorithm</strong>.</p>
<p>To summarize the procedure of finding an improved feasible basis given an existing feasible basis for an LP in canonical form:</p>
<ol type="1">
<li>Rewrite the LP &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot; in canonical form for a feasible basis <span class="math inline">B</span>. Clearly, canonical-form LPs can be written as &quot;maximize <span class="math inline">{\vec c}_N^T {\vec x}_N</span> subject to <span class="math inline">{\vec x}_B A_N {\vec x}_N = \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;.
<ol type="1">
<li>Let <span class="math inline">A&#39; = A_B^{-1} A</span> and <span class="math inline">\vec b&#39; = A_B^{-1} \vec b</span>.</li>
<li>Let <span class="math inline">\vec c&#39; = \left({\vec c}^T - A_B^{-1} {\vec c}_B A\right) \vec x</span> and <span class="math inline">z&#39; = A_B^{-1} {\vec c}_B \vec b</span>.</li>
<li>The new LP is &quot;maximize <span class="math inline">{\vec c&#39;}^T \vec x + z&#39;</span> subject to <span class="math inline">A&#39; \vec x = \vec b&#39;</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;.</li>
</ol></li>
<li>Compute <span class="math inline">\vec x</span> where <span class="math inline">{\vec x}_B = {\vec b}_B</span> and <span class="math inline">{\vec x}_{\overline B} = \vec 0</span> - the basic solution for our basis <span class="math inline">B</span>, which must be feasible since <span class="math inline">B</span> is a feasible basis.</li>
<li>If <span class="math inline">{\vec c}_N \le 0</span>, stop and output <span class="math inline">\vec x</span> as the optimal solution and <span class="math inline">B</span> as a proof of optimality. Note that <strong>the optimal solution output by this algorithm is always a basic feasible solution</strong>!</li>
<li>Choose a <span class="math inline">k \in \overline B</span> such that <span class="math inline">c_k &gt; 0</span> - a non-basic variable with a positive coefficient in the objective function.</li>
<li>If <span class="math inline">A_k \le 0</span>, stop and output a certificate of unboundedness <span class="math inline">\tup{B, A_k}</span>.</li>
<li>Let <span class="math inline">x_k&#39; = \min\set{\frac{b_i}{A_{i, k}} : 1 \le i \le n, A_{i, k} &gt; 0}</span> and <span class="math inline">{\vec x}_B&#39; = \vec b - x_k A_k</span> and <span class="math inline">{\vec x}_{\overline B - \set{k}}&#39; = \vec 0</span>.</li>
<li>Choose one of the basic variables <span class="math inline">r \in B</span> such that <span class="math inline">x_r&#39; = 0</span> and <span class="math inline">c_r &gt; 0</span>. Let <span class="math inline">B&#39; = (B \cup \set{k}) - \set{r}</span> be the new basis, formed by removing the basic variable that was forced to 0 and adding the non-basic variable we chose with a positive coefficient in the objective function.</li>
<li>Repeat starting from step 1 until the algorithm terminates, with <span class="math inline">B&#39;</span> instead of <span class="math inline">B</span> and <span class="math inline">\vec x&#39;</span> instead of <span class="math inline">\vec x</span>.</li>
</ol>
<p>This is essentially the entire simplex algorithm - it takes in an LP in SEF and a feasible basis, and outputs an optimal solution or proof that the LP is unbounded. To actually use this to solve arbitrary LPs though, we need to find a feasible basis first. This will be the next topic.</p>
<p>The only thing left to do is to ensure that the simplex algorithm terminates - how do we know it won't get stuck in a cycle of bases? To do this, we can use <strong>Bland's Rule</strong>, where whenever we need to choose a variable the leftmost variable in each case (the variable <span class="math inline">x_i</span> with the smallest possible index <span class="math inline">i</span>). This affects which variable we choose in step 4 and 7 above.</p>
<p>;wip: Why does Bland's rule work? proof outlined in exercise 10, page 69 of textbook</p>
<p>One of the interesting results we found is that the optimal solution given by the simplex algorithm is always a basic feasible solution, and that the simplex algorithm, with Bland's rule always gives us the optimal solution if there is one. LPs can have infinite feasible solutions, but the number of bases is finite, and so there are a finite number of basic feasible solutions.</p>
<p>This tells us that it's actually possible to find optimal solutions LPs by just enumerating every basis, finding the basic solution for each, and choosing the one that's both feasible and has the highest objective function value. However, this would be really inefficient - the number of possible bases goes up exponentially with respect to the number of constraints. That said, the simplex algorithm can also display exponential behaviour for LPs like the Klee-Minty cube, though it's a lot more efficient on real-world LPs.</p>
<h1 id="section-8">11/2/17</h1>
<h2 id="finding-a-feasible-basis-for-an-arbitrary-lp">Finding a feasible basis for an arbitrary LP</h2>
<p>One of the first steps before the simplex algorithm is, given an LP in SEF, to find a feasible basis, or detect that there is none. How do we find a basic feasible solution for an arbitrary LP in SEF? In other words, how do we find an <span class="math inline">\vec x \ge 0</span> such that <span class="math inline">A \vec x = \vec b</span> (the objective function doesn't matter since we're just trying to find a basic feasible solution)?</p>
<p>Now we'll construct an <strong>auxilary problem</strong> - an LP that has a known feasible basis, whose solutions can be converted into a feasible basic solution for the original LP. We can then solve the auxilary problem using the simplex algorithm (since we have the auxilary LP and a feasible basis for that auxilary LP), and then convert the optimal solution to that auxilary LP into a basic feasible solution for our original LP.</p>
<p>The auxilary LP for an LP in SEF &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot; (where <span class="math inline">A</span> is an <span class="math inline">n</span>-row-<span class="math inline">m</span>-column matrix) can be constructed as follows:</p>
<ol type="1">
<li>Flip the signs of every constraint that has a negative constant value (a negative value in <span class="math inline">\vec b</span>), so that <span class="math inline">\vec b \ge 0</span>. Let the new, sometimes-flipped constraints be given as <span class="math inline">A&#39; \vec x = \vec b&#39;</span>.
<ul>
<li>For example, <span class="math inline">x_1 + 2x_3 - 3x_5 = -4</span> should become <span class="math inline">-x_1 - 2x_3 + 3x_5 = 4</span>, while <span class="math inline">x_1 + 2x_3 - 3x_5 = 8</span> should stay the same.</li>
<li>This is necessary in order to ensure that the basic solution for the basis we'll choose later is feasible.</li>
</ul></li>
<li>Let <span class="math inline">A&#39;&#39; = A&#39; \| I</span> and <span class="math inline">\vec c&#39;</span> be a vector such that <span class="math inline">c_i&#39; = \begin{cases} 0 &amp;\text{if } 1 \le i \le m \\ 1 &amp;\text{if } m + 1 \le i \le m + n \end{cases}</span> (i.e., <span class="math inline">\vec c&#39; \cdot \vec x = x_{m + 1} + \ldots + x_{m + n}</span>).
<ul>
<li><span class="math inline">A&#39;&#39;</span> is basically <span class="math inline">A&#39;</span> with an <span class="math inline">n</span> by <span class="math inline">n</span> identity matrix appended on the right. In other words, for each constraint <span class="math inline">1 \le i \le n</span> of the form <span class="math inline">A_{i, 1}&#39; x_1 + \ldots + A_{i, m}&#39; x_m = b_i</span>, we add a new variable <span class="math inline">x_{m + i}</span> to it to get <span class="math inline">A_{i, 1}&#39; x_1 + \ldots + A_{i, m}&#39; x_m + x_{m + i} = b_i</span>.</li>
<li>We can think of the newly introduced variables <span class="math inline">x_{m + 1}, \ldots, x_{m + n}</span> as &quot;error&quot; variables - extra values that are needed to satisfy the constraint. When all of these are 0, we just get the original constraints back.</li>
<li><span class="math inline">c&#39;</span> basically means that our objective function is the sum of those new variables.</li>
</ul></li>
<li>Let the auxilary LP be &quot;minimize <span class="math inline">{\vec c&#39;}^T \vec x</span> subject to <span class="math inline">A&#39;&#39; \vec x = \vec b&#39;</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;. Alternatively, to make sure the auxilary LP is in SEF, we can write it as &quot;maximize <span class="math inline">{-\vec c&#39;}^T \vec x</span> subject to <span class="math inline">A&#39;&#39; \vec x = \vec b&#39;</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;.
<ul>
<li>Note that this LP obviously has the basis <span class="math inline">B = \set{m + 1, \ldots, m + n}</span> (i.e., the basis formed by the new variables introduced for each constraint). This is a basis because there are <span class="math inline">n</span> such new variables, and because the entries form an identity matrix in <span class="math inline">A&#39;&#39;</span>, which means <span class="math inline">A_B&#39;&#39; = I</span>, which by definition has linearly independent columns.</li>
<li>The corresponding basic solution is clearly <span class="math inline">\vec x</span> such that <span class="math inline">{\vec x}_B = \vec b&#39;</span> and <span class="math inline">{\vec x}_{\overline B} = \vec 0</span>. This is always feasible because <span class="math inline">\vec b&#39; \ge 0</span> and it always satisfies <span class="math inline">A&#39;&#39; \vec x = \vec b&#39;</span>, since that's equivalent to <span class="math inline">A_B&#39;&#39; {\vec x}_B = I {\vec x}_B = {\vec x}_B = \vec b</span>.</li>
</ul></li>
</ol>
<p>Now we have the auxilary LP and a feasible basis for the auxilary LP <span class="math inline">B = \set{m + 1, \ldots, m + n}</span>, so we can find an optimal solution using the simplex algorithm. Clearly, this LP is bounded, because it's a minimization problem where the objective function has all positive coefficients. Therefore, since we know that the LP isn't infeasible (since we have a feasible solution already), and the LP isn't unbounded, it must have an optimal solution!</p>
<p>The optimal solution to the auxilary LP gives us a feasible solution to the original LP, or tells us the original LP is infeasible. If any of the error variables <span class="math inline">x_{m + 1}, \ldots, x_{m + n}</span> are non-zero, that means the original LP is infeasible, since if the original LP was feasible, it could've satisfied the constraints with all of the error variables set to 0, which would result in a smaller objective function value than we got.</p>
<p>Likewise, if all of the error variables are zero, then we satisfied the constraints without using any of the error variables, so <span class="math inline">\begin{bmatrix} x_1 \\ \vdots \\ x_m \end{bmatrix}</span> is a feasible solution for the original LP. Additionally, since it's the output of the simplex algorithm, it's also a feasible basic solution, so we can construct a feasible basis from <span class="math inline">\set{i : x_i &gt; 0, 1 \le i \le n}</span>. This isn't guaranteed to give us <span class="math inline">n</span> columns, but we can add in other column indices from the original LP until we do get a basis, checking them for linear independence each time.</p>
<p>Therefore, we can solve an arbitrary LP as follows:</p>
<ol type="1">
<li>Convert the LP into SEF, and solve its auxilary LP using the simplex algorithm to find a feasible basic solution and a feasible basis for the LP.</li>
<li>Use the simplex algorithm to solve the original LP with the feasible basis found in step 1.</li>
</ol>
<p>This is called the <strong>two-phase algorithm</strong>.</p>
<p>Now we can actually prove the fundamental theorem of LPs using the simplex algorithm! Since we proved without using that theorem that the simplex algorithm works, and the simplex algorithm outputs either an optimal solution, proof of unboundedness, or proof of infeasibility, we've proved that an arbitrary LP must fall into one of those three categories.</p>
<h2 id="half-spaces-and-convexity">Half-spaces and convexity</h2>
<p>In the geometric interpretation of LPs, the feasible region is the space of all possible solutions, <span class="math inline">\mb{R}^m</span> where <span class="math inline">m</span> is the number of variables in the LP.</p>
<p>A <strong>polyhedron</strong> <span class="math inline">P</span> is a set of vectors that can be defined by <span class="math inline">P = \set{\vec x : A \vec x \le \vec b}</span>, where <span class="math inline">A</span> is a matrix and <span class="math inline">\vec b</span> is a vector. Think of it as a solid n-dimensional shape - a bounded area of the <span class="math inline">n</span>-dimensional space.</p>
<p>The feasible region of an LP is always a polyhedron. Given an LP &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;, we can write its feasible region as <span class="math inline">\set{\vec x: \begin{bmatrix} A \\ -A \\ -I \end{bmatrix} \le \begin{bmatrix} \vec b \\ -\vec b \\ \vec 0 \end{bmatrix}}</span>. Basically, this is just saying <span class="math inline">A \vec x \le \vec b</span>, <span class="math inline">A \vec x \ge \vec b</span>, and <span class="math inline">\vec x \ge 0</span>.</p>
<p>A <strong>hyperplane</strong> is a set of vectors that can be defined by <span class="math inline">H = \set{\vec x : \vec a \cdot \vec x = \beta}</span>, where <span class="math inline">\vec a</span> is a non-zero vector and <span class="math inline">\beta \in \mb{R}</span>. Think of it as an n-dimensional plane - an <span class="math inline">n - 1</span>-dimensional space within the <span class="math inline">n</span>-dimensional space. This is by definition the solution to a linear equation.</p>
<p>A <strong>halfspace</strong> is a set of vectors that can be defined by <span class="math inline">F = \set{\vec x : \vec a \cdot \vec x \le \beta}</span>, much like a hyperplane. Think of it as the space on one side of a hyperplane, or half of the n-dimensional space. This is by definition the solution to a linear inequality.</p>
<p>A polyhedron can be thought of as an <strong>intersection of a finite number of halfspaces</strong> - each linear constraint can be thought of as a halfspace where points in the halfspace are those that satisfy that particular constraint, and points outside don't.</p>
<p>Recall that <span class="math inline">\vec x \cdot \vec y = \magn{x} \magn{y} \cos(\theta)</span>, where <span class="math inline">\theta</span> is the minimum angle between <span class="math inline">\vec x</span> and <span class="math inline">\vec y</span>.</p>
<p>The hyperplane <span class="math inline">H = \set{\vec x : \vec a \cdot \vec x = 0}</span> is <strong>the set of all vectors that are orthogonal to <span class="math inline">\vec a</span></strong> - the ones for which <span class="math inline">\theta = 90 \deg</span> so <span class="math inline">\cos \theta = 0</span>. In the same way, the halfspace <span class="math inline">F = \set{\vec x : \vec a \cdot \vec x \le 0}</span> is <strong>the set of all vectors that are on the side of <span class="math inline">H</span> that doesn't contain <span class="math inline">\vec a</span></strong> - the ones for which <span class="math inline">\theta \ge 90 \deg</span> so <span class="math inline">\cos \theta \le 0</span>.</p>
<p>The <strong>translate</strong> of a set of vectors <span class="math inline">S</span> for some vector <span class="math inline">\vec p</span> is the set <span class="math inline">\set{\vec x + \vec p : \vec x \in S}</span>.</p>
<p>The hyperplane <span class="math inline">\set{\vec x : \vec a \cdot \vec x = \beta}</span> is a translate of the hyperplane <span class="math inline">\set{\vec x : \vec a \cdot \vec x = 0}</span>, by any vector <span class="math inline">\vec p</span> such that <span class="math inline">\vec a \cdot \vec p = \beta</span>.</p>
<p>The <strong>dimension of a hyperplane</strong> <span class="math inline">\set{\vec x : \vec a \cdot \vec x = \beta}</span> is simply the dimension of <span class="math inline">\set{\vec x : \vec a \cdot \vec x = 0}</span>, which is a vector space - its dimension is <span class="math inline">n - \mathrm{rank}(\vec a) = n - 1</span>.</p>
<p>A <strong>line through two vectors</strong> <span class="math inline">\vec x, \vec y</span> is defined as <span class="math inline">\set{\vec x + k(\vec y - \vec x), k \in \mb{R}}</span>. A <strong>line segment</strong> is a subset of that, defined as <span class="math inline">\set{\vec x + k(\vec y - \vec x), 0 \le k \le 1}</span>.</p>
<p>A set <span class="math inline">S \subseteq \mb{R}^n</span> is <strong>convex</strong> if and only if, for all <span class="math inline">\vec x, \vec y \in S</span>, the line segment between <span class="math inline">\vec x</span> and <span class="math inline">\vec y</span> is a subset of <span class="math inline">S</span> (i.e., <span class="math inline">\forall x \in S, \forall y \in S, \set{\vec x + k(\vec y - \vec x), k \in \mb{R}} \subseteq S</span>).</p>
<p>The union of two convex sets <span class="math inline">S_1 \cup S_2</span> is not necessarily convex - consider <span class="math inline">S_1 = \set{0}, S_2 = \set{1}</span>, for example. However, <strong>the intersection of two convex sets <span class="math inline">S_1 \cap S_2</span> is convex</strong>. This is easily proved: any two points <span class="math inline">\vec x, \vec y</span> in <span class="math inline">S_1 \cap S_2</span> is in both <span class="math inline">S_1</span> and <span class="math inline">S_2</span>, by definition. Therefore, the line segment between them is a subset of both <span class="math inline">S_1</span> and <span class="math inline">S_2</span>, and so the line segment is a subset of <span class="math inline">S_1 \cap S_2</span>, as required.</p>
<p>All halfspaces are convex. This is also easy to prove:</p>
<blockquote>
<p>Let <span class="math inline">F = \set{\vec x : \vec a \cdot \vec x \le \beta}</span> be a halfspace.<br />
Let <span class="math inline">\vec x_1, \vec x_2 \in F</span>, and <span class="math inline">\vec v \in \set{\vec x_1 + k(\vec x_2 - \vec x_1), 0 \le k \le 1}</span> be an arbitrary point on the line segment between <span class="math inline">\vec x_1</span> and <span class="math inline">\vec x_2</span>.<br />
So <span class="math inline">\vec a \cdot \vec v = \vec a \cdot \vec x_1 + \vec a \cdot k(\vec x_2 - \vec x_1) = (1 - k) \vec a \cdot \vec x_1 + k \vec a \cdot \vec x_2</span> for some <span class="math inline">0 \le k \le 1</span>.<br />
Since <span class="math inline">\vec x_1</span> and <span class="math inline">\vec x_2</span> are in the halfspace, <span class="math inline">\vec a \cdot \vec x_2 \le \beta</span> and <span class="math inline">\vec a \cdot \vec x_2 \le \beta \le \beta</span>.<br />
So <span class="math inline">\vec a \cdot \vec v = (1 - k) \vec a \cdot \vec x_1 + k \vec a \cdot \vec x_2 \le (1 - k) \beta + k \beta = \beta</span>.<br />
Therefore, <span class="math inline">\vec v \in F</span>, and since <span class="math inline">\vec v</span> is an arbitrary element of the line segment, the line segment must be a subset of <span class="math inline">F</span>, which means that <span class="math inline">F</span> is convex.</p>
</blockquote>
<p>As mentioned earlier, a polyhedron is an intersection of a finite number of halfspaces. Since halfspaces are convex, and intersections of convex sets are convex, <strong>all polyhedra are convex</strong>. Since the feasible region of an LP is a polyhedron, it must also be convex - this is actually why solving LPs is relatively easy!</p>
<h2 id="extreme-points">Extreme points</h2>
<p>A point <span class="math inline">\vec v</span> is <strong>properly contained</strong> in a line segment <span class="math inline">L = \set{\vec x + k(\vec y - \vec x), 0 \le k \le 1}</span> if and only if <span class="math inline">\vec v \in L - \set{\vec x_1, \vec x_2}</span> - when it's part of the line segment but isn't an endpoint.</p>
<p>Suppose we have a convex set <span class="math inline">S</span>. A point <span class="math inline">\vec v \in S</span> is an <strong>extreme point</strong> if and only if there is no line segment <span class="math inline">L \subseteq S</span> that properly contains <span class="math inline">\vec v</span> - if <strong>the point has to be one of the endpoints of any line segment in <span class="math inline">S</span> that contains it</strong>.</p>
<p>Intuitively, an extreme point is one that's on a &quot;curve&quot; on the surface of the set. For a convex set that looks like a 2D square, the extreme points at the four corners. For a circle, every point is an extreme point - a convex set doesn't necessarily have a finite number of extreme points! A halfspace actually has no extreme points.</p>
<p>Suppose we have an LP with the constraints <span class="math inline">x_1 \le 3, x_2 \le 2</span> and <span class="math inline">x_1, x_2 \ge 0</span>. The solution space is actually 2D for this LP, so each constraint forms a 2D halfspace (a hemiplane). If we plot the feasible region of this LP, we actually get a 3 by 2 square where the bottom left corner is the origin. Here, the extreme points are <span class="math inline">\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 3, 0 \end{bmatrix}, \begin{bmatrix} 3 \\ 2 \end{bmatrix}, \begin{bmatrix} 2 \\ 0 \end{bmatrix}</span>.</p>
<p>What's interesting is that all of these points, and only these points, satisfy two different constraints with equality at the same time. For example, for <span class="math inline">\begin{bmatrix} 3 \\ 2 \end{bmatrix}</span>, the constraints <span class="math inline">x_1 \le 2</span> and <span class="math inline">x_2 \le 2</span> are satisfied with equality, so <span class="math inline">x_1 = 2</span> and <span class="math inline">x_2 = 2</span>. In fact, this generalizes into multiple variables.</p>
<p>For an LP, given a constraint <span class="math inline">\vec p \cdot \vec x \le k</span> and a solution <span class="math inline">\vec x</span>, the constraint is <strong>tight</strong> if and only if it is satisfied with equality by <span class="math inline">\vec x</span> - when <span class="math inline">\vec p \cdot x = k</span>.</p>
<p>For an LP with constraints <span class="math inline">A \vec x \le \vec b</span>, the <strong>tight constraints</strong> for a solution <span class="math inline">\vec x</span> are denoted <span class="math inline">\overline A \vec x \le \overline{\vec b}</span>, where <span class="math inline">\overline A</span> and <span class="math inline">\overline{\vec b}</span> are the rows of <span class="math inline">A</span> and the entries of <span class="math inline">\vec b</span> corresponding to constraints that are tight for <span class="math inline">\vec x</span>.</p>
<p>Now we have the tools to define what an extreme point of a polyhedron is in a better way: given a point <span class="math inline">\vec x</span> in a polyhedron <span class="math inline">\set{\vec x \in \mb{R}^m : A \vec x \le \vec b}</span>, <span class="math inline">\vec x</span> is an extreme point if and only if <span class="math inline">\mathrm{rank}(\overline A) = m</span>. In other words, there's a theorem that says that <strong>an extreme point for an <span class="math inline">m</span>-dimensional polyhedron is a point in the polyhedron that satisfies <span class="math inline">m</span> linearly independent constraints with equality</strong>.</p>
<p>Now we'll prove the above:</p>
<blockquote>
<p>Assume <span class="math inline">\mathrm{rank}(\overline A) = m</span>. Suppose we have an arbitrary point <span class="math inline">\vec x</span> in an arbitrary polyhedron <span class="math inline">P = \set{\vec x \in \mb{R}^m : A \vec x \le \vec b}</span>.<br />
Suppose <span class="math inline">\vec x</span> is not an extreme point. Then <span class="math inline">\vec x</span> is properly contained by a line segment <span class="math inline">L = \set{\vec x + k(\vec y - \vec x), 0 \le k \le 1}</span> such that <span class="math inline">L \subseteq P</span>, with some endpoints <span class="math inline">\vec v_1, \vec v_2</span>. So there exists a <span class="math inline">0 &lt; k &lt; 1</span> such that <span class="math inline">\vec x = \vec v_1 + k(\vec v_2 - \vec v_1) = k\vec v_2 + (1 - k)\vec v_1</span>.<br />
Clearly, the tight constraints <span class="math inline">\overline{\vec b} = \overline A \vec x = \overline A (k\vec v_2 + (1 - k)\vec v_1) = k \overline A \vec v_2 + (1 - k) \overline A \vec v_1</span>.<br />
Since <span class="math inline">L \subseteq P</span>, <span class="math inline">\vec v_1 \in P</span> and <span class="math inline">\vec v_2 \in P</span>, <span class="math inline">\overline A \vec v_2 \le \overline{\vec b}</span> and <span class="math inline">\overline A \vec v_1 \le \overline{\vec b}</span>.<br />
For any vectors <span class="math inline">\vec a, \vec b, \vec b</span>, if <span class="math inline">\vec a = k \vec b + (1 - k) \vec c</span> and <span class="math inline">\vec b \le \vec a</span> and <span class="math inline">\vec c \le \vec a</span>, then it must be that <span class="math inline">\vec a = \vec b = \vec c</span> (if the weighted average of two numbers is greater or equal to both numbers, it must be equal to those numbers). This is easily proven by showing that <span class="math inline">\vec a = k\vec b + (1 - k)\vec c \le k\vec a + (1 - k)\vec a = \vec a</span>, so <span class="math inline">k\vec b + (1 - k)\vec c = k\vec a + (1 - k)\vec a</span>, so <span class="math inline">\vec b = \vec a</span> and <span class="math inline">\vec c = \vec a</span>.<br />
Therefore, <span class="math inline">\overline{\vec b} = \overline A \vec v_1 = \overline A \vec v_2</span>.<br />
Since <span class="math inline">\mathrm{rank}(\overline A) = m</span>, <span class="math inline">\overline A</span> is invertible. Since <span class="math inline">\overline{\vec b} = \overline A \vec v_1 = \overline A \vec v_2</span>, <span class="math inline">\vec v_1 = \vec v_2</span>.<br />
This is a contradiction, because then <span class="math inline">\vec x</span> can't possibly be contained in <span class="math inline">L</span>, if the line segment only has its endpoints. Therefore, if <span class="math inline">\mathrm{rank}(\overline A) = m</span>, then <span class="math inline">\vec x</span> must be an extreme point. Basically, we showed that if <span class="math inline">m</span> independent constraints are satisfied by a point, then any line segment containing that point will only contain that point as both endpoints.<br />
Assume <span class="math inline">\mathrm{rank}(\overline A) &lt; m</span>. So there must exist a vector <span class="math inline">\vec d</span> such that <span class="math inline">\overline A \vec d = \vec 0</span>.<br />
Let <span class="math inline">\epsilon &gt; 0</span>. Let <span class="math inline">L</span> be the line segment with endpoints <span class="math inline">\vec x - \epsilon \vec d</span> and <span class="math inline">\vec x + \epsilon \vec d</span>. Clearly, <span class="math inline">\vec x</span> is properly contained by <span class="math inline">L</span>, so we just need to show that <span class="math inline">L \subseteq P</span> to prove that <span class="math inline">\vec x</span> is not an extreme point.<br />
Clearly, for the tight constraints <span class="math inline">\overline A</span>, <span class="math inline">\overline A (\vec x - \epsilon \vec d) = \overline A \vec x - \epsilon \overline A \vec d</span>. Since <span class="math inline">\overline A \vec d = \vec 0</span>, <span class="math inline">\overline A \vec x - \epsilon \overline A \vec d = \overline A \vec x = \overline{\vec b}</span>. Therefore, <span class="math inline">\vec x - \epsilon \vec d</span> satisfies the tight constraints. The same argument shows that <span class="math inline">\vec x + \epsilon \vec d</span> also satisfies the tight constraints.<br />
Clearly, for any non-tight constraint <span class="math inline">\vec a \cdot \vec x \le \beta</span>, <span class="math inline">\vec a \cdot (\vec x - \epsilon \vec d) = \vec a \cdot \vec x - \epsilon \vec a \cdot \vec d</span>. Since <span class="math inline">\vec x \in P</span>, we know that <span class="math inline">\vec a \cdot \vec x &lt; \beta</span> (the constraint is non-tight, so it isn't satisfied by equality, so we can use strict inequalities), but <span class="math inline">\vec a \cdot \vec d</span> could be anything.<br />
However, since <span class="math inline">\vec a \cdot \vec x &lt; \beta</span>, there must exist an <span class="math inline">\epsilon &gt; 0</span> such that <span class="math inline">\vec a \cdot \vec x - \epsilon \vec a \cdot \vec d &lt; \beta</span>. Therefore, <span class="math inline">\vec x - \epsilon \vec d</span> satisfies an arbitrary non-tight constraints, and by the same argument, so does <span class="math inline">\vec x + \epsilon \vec d</span>.<br />
Since all the tight constraints and arbitrary non-tight constraints are satisfied by <span class="math inline">\vec x - \epsilon \vec d</span> and <span class="math inline">\vec x + \epsilon \vec d</span>, so both are in <span class="math inline">P</span>. Since <span class="math inline">P</span> is convex and the endpoints are in <span class="math inline">P</span>, <span class="math inline">L \subseteq P</span>, so we have a line in <span class="math inline">P</span> that properly contains <span class="math inline">\vec x</span>.<br />
Therefore, <span class="math inline">\vec x</span> is not an extreme point if <span class="math inline">\mathrm{rank}(\overline A) &lt; m</span>.</p>
</blockquote>
<p>Suppose we now have the feasible region of an LP <span class="math inline">P = \set{\vec x : \begin{bmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; 3 \end{bmatrix} \vec x = \begin{bmatrix} 2 \\ 4 \end{bmatrix}, \vec x \ge 0}</span>. Recall that the feasible region of an LP is always a polyhedron. How do we check if <span class="math inline">\vec v = \begin{bmatrix} 2 \\ 4 \\ 0 \end{bmatrix}</span> is an extreme point?</p>
<p>First, we can rewrite <span class="math inline">P</span> in the form <span class="math inline">\set{\vec x : A \vec x = \vec b}</span>: <span class="math inline">\set{\vec x : \begin{bmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; 3 \\ -1 &amp; 0 &amp; 1 \\ 0 &amp; -1 &amp; -3 \\ -1 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; -1 \end{bmatrix} \vec x = \begin{bmatrix} 2 \\ 4 \\ -2 \\ -4 \\ 0 \\ 0 \\ 0 \end{bmatrix}}</span>.</p>
<p>Now we take the constraints that are satified with equality by <span class="math inline">\vec v</span> - namely, constraints 1, 2, 3, 4, and 7. So <span class="math inline">\overline A = \begin{bmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; 3 \\ -1 &amp; 0 &amp; 1 \\ 0 &amp; -1 &amp; -3 \\ 0 &amp; 0 &amp; -1 \end{bmatrix}</span>. Clearly, <span class="math inline">\mathrm{rank}(\overline A) = 3</span>, and the LP has 3 variables, so <span class="math inline">\vec v</span> must be an extreme point.</p>
<p>An interesting consequence of the above theorem is that if we have the feasible region of an LP in SEF <span class="math inline">P = \set{\vec x : A \vec x = \vec b, \vec x \ge 0}</span>, then <span class="math inline">\vec x \in P</span> is an extreme point if and only if it's a basic feasible solution for that LP. In other words, <strong>the basic feasible solutions for an LP are the extreme points in its feasible region</strong>. This is easily proven from the previous theorem and the definition of a basic feasible solution.</p>
<p>Because the simplex algorithm moves between different bases until it reaches the optimal one, it's actually moving between extreme points in <span class="math inline">n</span>-dimensional space. That means we could enumerate all the extreme points in the feasible region by enumerating all the basic feasible solutions.</p>
<h1 id="section-9">1/3/17</h1>
<p>Previously we looked at the shortest-path problem formulated as an IP - given a weighted graph <span class="math inline">G</span> and <span class="math inline">s, t \in V(G)</span>, find the path from <span class="math inline">s</span> to <span class="math inline">t</span> that minimizes the total weight. Given a shortest-path problem and an <span class="math inline">s, t</span>-path <span class="math inline">P</span>, how do we prove if <span class="math inline">P</span> is optimal? How do we find an optimal <span class="math inline">P</span>, anyways?</p>
<p>The <strong>cardinality special case</strong> is the shortest path problem where all edge weights are 1 - we're trying to find the <span class="math inline">s, t</span>-path <span class="math inline">P</span> with the fewest edges. How do we show that <span class="math inline">P</span> is an optimal solution, if it is?</p>
<p>Recall that any <span class="math inline">s, t</span>-cut must contain one of the edges of <span class="math inline">P</span> - if it didn't, then we could remove the edges in the cut and <span class="math inline">P</span> would still connect <span class="math inline">s</span> and <span class="math inline">t</span>, which is a contradiction because removing the edges of an <span class="math inline">s, t</span>-cut must disconnect <span class="math inline">s</span> and <span class="math inline">t</span>. As a result, if <span class="math inline">S \subseteq E(G)</span> has an edge from every <span class="math inline">s, t</span>-cut, then <span class="math inline">S</span> contains an <span class="math inline">s, t</span>-path.</p>
<p>If we can construct <span class="math inline">s, t</span>-cuts <span class="math inline">\delta(U_1), \ldots, \delta(U_k)</span> such that each one is disjoint from the other, then since an <span class="math inline">s, t</span>-path must contain an edge from every <span class="math inline">s, t</span>-cut, an <span class="math inline">s, t</span>-cut must contain at least <span class="math inline">k</span> edges. This allows us to lower bound the length of the shortest path, so if we find a path of length <span class="math inline">k</span>, we know for sure that it is optimal. In other words, to prove that an <span class="math inline">s, t</span>-path of length <span class="math inline">k</span> is optimal, we find <span class="math inline">k</span> pairwise disjoint <span class="math inline">s, t</span>-cuts.</p>
<p>When we're looking at the general case (i.e., not the cardinality special case), we can do something similar. We construct a mapping between <span class="math inline">s, t</span>-cuts and arbitrary non-negative values called <strong>cut widths</strong>: <span class="math inline">\overline y: \delta(U) \to \mb{R}_{\ge 0}</span>. A <strong>feasible cut width assignment</strong> <span class="math inline">\overline y</span> is such a mapping that, for every edge <span class="math inline">e</span>, the sum of the widths of <span class="math inline">s, t</span>-cuts containing <span class="math inline">e</span> is less or equal to the weight of <span class="math inline">e</span>. In other words, the cut widths summed up by edge shouldn't exceed the lengths of any edge. Formally, <span class="math inline">\forall e \in E(G), \sum_{\text{every s-t cut } U \text{ such that } e \in \delta(U)} \overline y_U \le c_e</span> if and only if <span class="math inline">\overline y</span> is feasible.</p>
<p>If we generalize the result of the cardinality special case, we find that if <span class="math inline">\overline y</span> is a feasible cut width assignment, then every <span class="math inline">s, t</span>-path must have length <span class="math inline">\sum_{\text{every s-t cut } U} \overline y_U</span> or greater - the sum of the <span class="math inline">s, t</span>-cut widths is a lower bound for the length of the shortest path! So if we find an <span class="math inline">, st</span> path with that length, we know it's a shortest path.</p>
<p>Proof:</p>
<blockquote>
<p>Let <span class="math inline">P</span> be an <span class="math inline">s, t</span>-path and <span class="math inline">\overline y</span> be a feasible cut width assignment.<br />
Clearly, the length of <span class="math inline">P</span> is <span class="math inline">c(P) = \sum_{e \in P} c_e \ge \sum_{e \in P} \left(\sum_{\text{every s-t cut } \delta(U) \text{ such that } e \in \delta(U)} \overline y_U\right)</span>.<br />
Since <span class="math inline">P</span> is an <span class="math inline">s, t</span>-path, <span class="math inline">P</span> contains at least one edge from any <span class="math inline">\delta(U)</span> (where <span class="math inline">U</span> is an <span class="math inline">s, t</span>-cut). So the condition for the inner sum will be satisfied, at one point or another, by every single <span class="math inline">s, t</span>-cut.<br />
So <span class="math inline">c(P) \ge \sum_{\text{every s-t cut } U} \overline y_U</span>, giving us a lower bound for the length of <span class="math inline">P</span>.</p>
</blockquote>
<p>How do we find these cut width assignments, and do they always exist such that the total cut width is equal to the length of a shortest <span class="math inline">s, t</span>-path? We will answer this using LPs.</p>
<p>Just as a feasible cut width assignment lower bounds the length of a shortest <span class="math inline">s, t</span>-path, a feasible solution upper bounds the objective value of a minimization LP. Can we find a lower bound?</p>
<p>Suppose we have an LP &quot;minimize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x \ge \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;. Clearly, any feasible solution <span class="math inline">\vec x</span> must satisfy <span class="math inline">A \vec x \ge \vec b</span>, so it must also satisfy <span class="math inline">{\vec k}^T A \vec x \ge {\vec k}^T \vec b</span> for any <span class="math inline">\vec k \ge \vec 0</span> - we can construct any new constraint out of linear combinations of existing constraints, and <span class="math inline">\vec x</span> will satisfy it.</p>
<p>Since <span class="math inline">{\vec c}^T \vec x \ge {\vec c}^T \vec x</span> and <span class="math inline">(\vec k)^T A \vec x \ge (\vec k)^T \vec b</span>, <span class="math inline">{\vec c}^T \vec x + (\vec k)^T A \vec x \ge {\vec c}^T \vec x + (\vec k)^T \vec b</span>, so <span class="math inline">{\vec c}^T \vec x \ge (\vec k)^T \vec b + \left({\vec c}^T - (\vec k)^T A\right) \vec x</span>.</p>
<p>Since we're trying to find a lower bound, we want to write the objective function value in the form <span class="math inline">z + \vec m \cdot \vec x</span>, where <span class="math inline">\vec m \cdot \vec x \ge 0</span> - this means that <span class="math inline">z</span> is a lower bound for the objective function value. To ensure <span class="math inline">(\vec k)^T \vec b + \left({\vec c}^T - (\vec k)^T A\right) \vec x</span> is in this form, we want <span class="math inline">{\vec c}^T - (\vec k)^T A \ge \vec 0</span>.</p>
<p>That means we're trying to choose <span class="math inline">\vec k</span> such that <span class="math inline">{\vec c}^T \ge (\vec k)^T A</span>. If we do find such a <span class="math inline">\vec k</span>, then since <span class="math inline">\vec x \ge \vec 0</span>, <span class="math inline">\left({\vec c}^T - (\vec k)^T A\right) \vec x \ge 0</span>, so <span class="math inline">{\vec c}^T \vec x \ge {\vec c}^T \vec x \ge (\vec k)^T \vec b</span>, and <span class="math inline">(\vec k)^T \vec b</span> is a lower bound for the objective function.</p>
<p>We want the largest possible lower bound, to ensure that the actual minimum value isn't higher than our lower bound. To maximize this lower bound, we want to maximize <span class="math inline">(\vec k)^T \vec b</span> subject to <span class="math inline">{\vec c}^T \ge (\vec k)^T A</span> where <span class="math inline">\vec k \ge \vec 0</span>, which is an LP such that <strong>the maximum objective function value is the minimum objective function value of the original LP</strong>. This new LP is the dual of the original LP. Since <span class="math inline">{\vec a}^T M = {M^T \vec a}^T</span> for any vector <span class="math inline">\vec a</span> and any matrix <span class="math inline">M</span>, we can transpose both sides of the constraints to get &quot;maximize <span class="math inline">{\vec b}^T \vec k</span> subject to <span class="math inline">\vec c \ge A^T \vec k</span> and <span class="math inline">\vec k \ge \vec 0</span>&quot;.</p>
<p>In other words, &quot;maximize <span class="math inline">{\vec b}^T \vec k</span> subject to <span class="math inline">A^T \vec k \le \vec c</span> and <span class="math inline">\vec k \ge \vec 0</span>&quot; is the <strong>dual LP</strong> for the <strong>primal LP</strong> &quot;minimize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x \ge \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;, and vice versa. Basically, we transposed <span class="math inline">A</span>, swapped <span class="math inline">\vec b</span> and <span class="math inline">\vec c</span>, and swapped the <span class="math inline">\ge</span> and <span class="math inline">\le</span> for all constraints except the non-negativity constraints.</p>
<p>Also, we can do the same thing to an LP in SEF to obtain its dual: &quot;minimize <span class="math inline">{\vec b}^T \vec k</span> subject to <span class="math inline">A^T \vec k \le \vec c</span>&quot; is the dual of &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;.</p>
<p>The <strong>Weak Duality theorem</strong> says that if <span class="math inline">\vec x_1</span> is feasible for the primal maximization LP and <span class="math inline">\vec x_2</span> is feasible for the dual minimization LP, then <span class="math inline">\vec c \cdot \vec x_2 \le \vec b \cdot \vec x_1</span>. This is because <span class="math inline">{\vec b}^T \vec x_2 = {\vec x_2}^T \vec b</span>, and since <span class="math inline">\vec b \le A \vec x_1</span>, <span class="math inline">{\vec b}^T \vec x_2 \le {\vec x_2}^T (A \vec x_1) = ({\vec x_2}^T A) \vec x_1 = (A^T \vec x_2)^T \vec x_1</span>. Since <span class="math inline">A^T \vec x_2 \le \vec c</span>, <span class="math inline">{\vec b}^T \vec x_2 \le {\vec c}^T \vec x_1</span>, as required.</p>
<p>In other words, the objective function value for any feasible solution of the maximization LP is upper bounded by the objective function value for any feasible solution of the LP's dual, which is a minimizatoin problem. The main consequence of this is that if the objective function values are equal, both feasible solutions are optimal for their respective LPs.</p>
<p>As a result, the weak duality theorem also says that if <span class="math inline">\vec b \cdot \vec x_1 = \vec c \cdot \vec x_2</span> (the objective functions are exactly equal), then <span class="math inline">\vec x_1</span> is optimal for the primal LP and <span class="math inline">x_2</span> is optimal for the dual LP. This is because the dual's objective function bounds the primal's objective function, and vice versa, so if they're equal, they must be at their bounds.</p>
<p>The <strong>LP relaxation</strong> of an IP is just the IP with integer constraints removed.</p>
<p>Consider the shortest-path problem &quot;minimize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x \ge \vec 1</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;. The IP rows of <span class="math inline">A</span> are <span class="math inline">s, t</span>-cuts and columns are edges, and values of <span class="math inline">A</span> are 1 or 0 depending on whether the corresponding edges are in the corresponding <span class="math inline">\delta(U)</span> values for the <span class="math inline">s, t</span>-cuts. Clearly, the solution <span class="math inline">\vec x</span> for is a vector of integers 1 or 0, representing whether that given edge is a part of the shortest <span class="math inline">s, t</span>-path, and we're trying to minimize the sum of weights of those edges.</p>
<p>Clearly, the objective function value is the length of the shortest <span class="math inline">s, t</span>-path. Then the LP relaxation of the shortest-path IP must have an optimal value that's at most the optimal value for the IP, since removing constraints can only expand the feasible region.</p>
<p>Also note that <strong>the solution to the dual of the LP relaxation of the shortest-path IP is always a valid cut width assignment</strong>! This is because the dual, &quot;maximize <span class="math inline">\vec 1 \cdot \vec y</span> subject to <span class="math inline">A^T \vec y \le \vec c</span> and <span class="math inline">\vec y \ge \vec 0</span>&quot;, is maximizing the number of cuts while each constraint in <span class="math inline">A^T \vec y = \vec b</span> ensures that cut weights summed for a given edge can't exceed the edge's weight. Each value of <span class="math inline">\vec y</span> is a cut width, and each column of <span class="math inline">A^T</span> is an <span class="math inline">s, t</span>-cut. In other words, <span class="math inline">A[U, e]</span> is 1 whenever <span class="math inline">e \in \delta(U)</span> and 0 otherwise, where <span class="math inline">U</span> is an <span class="math inline">s, t</span>-cut and <span class="math inline">e</span> is an edge.</p>
<p>From the Weak Duality theorem, the dual of the LP relaxation must have an optimal value that's less or equal to the optimal value for the LP relaxation. That means the cut width assignment <span class="math inline">\vec y</span> has total width at most the length of the shortest <span class="math inline">s, t</span>-path.</p>
<p>So if we find a feasible cut width assignment such that the total width is equal to the length of an <span class="math inline">s, t</span>-path, then the <span class="math inline">s, t</span> path must be a shortest <span class="math inline">s, t</span>-path and the feasible cut width assignment must be maximal.</p>
<p>Also, the <strong>characteristic vector</strong> of an <span class="math inline">s, t</span>-path <span class="math inline">P = sa, ab, bt</span> is the vector <span class="math inline">\vec x</span> where each element corresponds to an edge, and each element is 1 if the corresponding edge is in <span class="math inline">P</span>, or 0 otherwise.</p>
<h1 id="section-10">10/3/17</h1>
<p>Week 8.</p>
<p>We looked at duals for the shortest path problem, but how did we find these shortest paths? How did we find the duals? In other words, how do we find an <span class="math inline">s, t</span>-path <span class="math inline">P</span> and a feasible dual (cut width assignment) such that the length of the path is equal to the total width of the cut width assignment?</p>
<p>In this course we will denote directed graphs as <span class="math inline">D = \tup{V, E}</span>, and directed edges as <span class="math inline">\vec{uv}</span>. A directed <span class="math inline">s, t</span>-path might be denoted with <span class="math inline">\vec{sx}, \vec{xy}, \vec{yt}</span>.</p>
<p>The <strong>slack</strong> of an edge given a feasible cut width assignment in a shortest-path problem is the <strong>difference between the edge's weight and the total width of the cuts that contain the edge</strong>. An <strong>equality edge</strong> is an edge with zero slack.</p>
<p>Also, an <strong>active</strong> <span class="math inline">s, t</span>-cut in a feasible cut width assignment is an <span class="math inline">s, t</span>-cut with a non-zero width.</p>
<p>Formally, the slack of an edge <span class="math inline">e</span> for a feasible cut width assignment <span class="math inline">y</span> is defined as <span class="math inline">\mathrm{slack}_y(e) = c_e - \sum_{\text{every st-cut } \delta(U) \text{ such that } e \in \delta(U)} y_U</span>, where <span class="math inline">c_e</span> is the weight of <span class="math inline">e</span> and <span class="math inline">y_U</span> is the width of the <span class="math inline">s, t</span>-cut <span class="math inline">\delta(U)</span>.</p>
<p>There's actually a simple algorithm that will always find a shortest-path and a feasible cut width assignment of the same total width as the path's length (assuming non-negative edge weights):</p>
<ol type="1">
<li>Let <span class="math inline">U</span> be the trivial <span class="math inline">s, t</span>-cut <span class="math inline">\set{s}</span> (cut only containing <span class="math inline">s</span>), and <span class="math inline">y</span> be the trivially feasible cut width assignment <span class="math inline">\vec 0</span> (all cuts have weight 0).</li>
<li>Repeat while <span class="math inline">t \notin U</span>:
<ol type="1">
<li>Let <span class="math inline">ab</span> be the edge in <span class="math inline">\delta(U)</span> with the smallest value for <span class="math inline">\mathrm{slack}_y(e)</span>. Essentially, this is the biggest value by which you can grow this cut's width while still keeping <span class="math inline">y</span> a feasible cut width assignment. Without loss of generality, assume <span class="math inline">a \in U</span> and <span class="math inline">b \notin U</span>.</li>
<li>Let <span class="math inline">y_U = \mathrm{slack}_y(ab)</span>. Essentially, grow the cut width by the largest amount possible, as calculated in the previous step.</li>
<li>Change <span class="math inline">ab</span> into a directed edge <span class="math inline">\vec{ab}</span>. Keep track of each new vertex's predecessor vertex - you can use a map and insert <span class="math inline">b \to a</span> at this step.</li>
<li>Add <span class="math inline">b</span> to <span class="math inline">U</span>. Essentially, grow the <span class="math inline">s, t</span>-cut <span class="math inline">U</span> so that it once again includes all of the vertices reachable by directed edges.</li>
</ol></li>
<li>Now <span class="math inline">y_U</span> is a feasible cut width assignment of maximal width, while a minimum length <span class="math inline">s, t</span>-path can be computed from the predecessors map.</li>
</ol>
<p>Clearly, this algorithm must terminate, because every step adds a new vertex to <span class="math inline">U</span>, so eventually it must reach <span class="math inline">t</span> and terminate, assuming the graph is connected.</p>
<p>How do we know the resulting cut width assignment is of maximal width, or that the resulting <span class="math inline">s, t</span>-path is of minimal length?</p>
<p>First of all, <span class="math inline">P</span> is a shortest <span class="math inline">s, t</span>-path if all edges in <span class="math inline">P</span> are equality edges, and every active cut contains exactly one edge of <span class="math inline">P</span>. Proof:</p>
<blockquote>
<p>Assume all edges in <span class="math inline">P</span> are equality edges, and every active cut contains exactly one edge of <span class="math inline">P</span>.<br />
Clearly, the length of the path is <span class="math inline">\sum_{e \in P} c_e</span>. Since all edges are equality edges (so their slack is 0), <span class="math inline">c_e = \sum_{\text{every st-cut } \delta(U) \text{ such that } e \in \delta(U)} y_U</span> for any edge <span class="math inline">e \in P</span>.<br />
So the length of the path is <span class="math inline">\sum_{e \in P} \sum_{\text{every st-cut } \delta(U) \text{ such that } e \in \delta(U)} y_U</span>.<br />
Clearly, if we expand the summation, <span class="math inline">e \in \delta(U)</span> will occur <span class="math inline">\abs{P \cap \delta(U)}</span> times for each <span class="math inline">s, t</span>-cut <span class="math inline">\delta(U)</span>. So <span class="math inline">\sum_{e \in P} \sum_{\text{every st-cut } \delta(U) \text{ such that } e \in \delta(U)} y_U = \sum_{\text{every st-cut } \delta(U)} \abs{P \cap \delta(U)} y_U</span>.<br />
However, since every active <span class="math inline">s, t</span>-cut contains exactly one edge of <span class="math inline">P</span>, <span class="math inline">\abs{P \cap \delta(U)} = 1</span> for them, so <span class="math inline">\abs{P \cap \delta(U)} y_U = y_U</span>. For any non-active <span class="math inline">s, t</span>-cut <span class="math inline">U</span>, <span class="math inline">y_U = 0</span>, so <span class="math inline">\abs{P \cap \delta(U)} y_U = y_U</span>. Therefore, <span class="math inline">\sum_{\text{every st-cut } \delta(U)} \abs{P \cap \delta(U)} y_U = \sum_{\text{every st-cut } \delta(U)} y_U</span>.<br />
Since <span class="math inline">\sum_{e \in P} c_e = \sum_{\text{every st-cut } \delta(U)} y_U</span>, by Weak Duality, <span class="math inline">P</span> is a minimum length path and <span class="math inline">y</span> is a maximum width cut width assignment.</p>
</blockquote>
<p>Now let's use this to prove that the algorithm gives the correct result. First, we note that at the end of every iteration in step 2, the following properties hold:</p>
<ol type="1">
<li><span class="math inline">y</span> is a feasible cut width assignment.</li>
<li>All directed edges are equality edges (all directed edges have zero slack).</li>
<li>No arcs point into any <span class="math inline">s, t</span>-cuts - there are no <strong>entering arcs</strong> (for any active <span class="math inline">s, t</span>-cut <span class="math inline">\delta(T)</span>, no directed edges <span class="math inline">\vec{ab}</span> exist such that <span class="math inline">a \notin T</span> but <span class="math inline">b \in T</span>).</li>
<li>For every <span class="math inline">u \in U</span> (vertex in the current cut), there is a directed <span class="math inline">s, u</span>-path.</li>
<li>Every arc has both ends contained within <span class="math inline">U</span>.</li>
</ol>
<p>These invariants hold when the algorithm terminates. Therefore:</p>
<ul>
<li>By property 1 above, we know that <span class="math inline">y</span> is feasible cut width assignment.</li>
<li>By property 2, all arcs are equality arcs.</li>
<li>Since <span class="math inline">t \in U</span>, by property 4 above there must be a <span class="math inline">s, t</span>-path.</li>
<li>We proved earlier that <span class="math inline">P</span> must contain at least one edge from each <span class="math inline">s, t</span>-cut. Suppose there exists an active <span class="math inline">s, t</span>-cut <span class="math inline">\delta(U)</span> that contains more than one edge of <span class="math inline">P</span>. Since Then <span class="math inline">P</span> must first exit <span class="math inline">U</span> through <span class="math inline">\delta(U)</span>, and then enter it again, which would be impossible by property 3. Therefore, any active <span class="math inline">s, t</span>-cut must contain exactly one edge from <span class="math inline">P</span>.</li>
</ul>
<p>Since all edges in <span class="math inline">P</span> are equality edges, and every active cut contains exactly one edge of <span class="math inline">P</span>, we can use the proposition proved above to say that <span class="math inline">P</span> is a shortest <span class="math inline">s, t</span>-path. Therefore, the algorithm is always correct.</p>
<p>Note that if all edge weights are integers, then in the algorithm output, all cut widths are also all integers.</p>
<h1 id="section-11">17/3/17</h1>
<p>Week 9.</p>
<p>Previously, we looked at duality for the shortest-path problem. now we'll look at duality in general.</p>
<p>We can write an arbitrary LP as &quot;maximize/minimize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x ? b</span> and <span class="math inline">\vec x ? \vec 0</span>&quot;. Here <span class="math inline">A \vec x ? b</span> represents <span class="math inline">n</span> individual constraints <span class="math inline">\mathrm{row}_i(A) \cdot \vec x \le b_i</span>, <span class="math inline">\vec a_i \cdot \vec x \ge b_i</span>, or <span class="math inline">\vec a_i \cdot \vec x = b_i</span>. Likewise, <span class="math inline">\vec x ? \vec 0</span> represents <span class="math inline">n</span> variable definitions <span class="math inline">x_i \ge 0</span>, <span class="math inline">x_i \le 0</span>, or <span class="math inline">x_i \text{ free}</span>.</p>
<p>The dual has a variable for each constraint in the primal LP, and a constraint for each variable in the primal LP.</p>
<p>Recall that the dual of an LP &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x \ge b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot; is &quot;minimize <span class="math inline">{\vec b}^T \vec y</span> subject to <span class="math inline">A^T \vec y \le c</span> and <span class="math inline">\vec y \ge \vec 0</span>&quot;. This only works for LPs in a certain form, but it's easy to change LPs into this form:</p>
<ol type="1">
<li>If the LP is a minimization problem, invert the objective function and replace &quot;minimize&quot; with &quot;maximize&quot; to turn it into a maximization LP.</li>
<li>Turn constraints of the form <span class="math inline">\vec a \cdot \vec x \le b</span> into <span class="math inline">-\vec a \cdot \vec x \ge -b</span>.</li>
<li>Turn constraints of the form <span class="math inline">\vec a \cdot \vec x = b</span> into <span class="math inline">-\vec a \cdot \vec x \ge -b</span> and <span class="math inline">\vec a \cdot \vec x \ge b</span>.</li>
<li>Replace variables <span class="math inline">x \le 0</span> with <span class="math inline">x&#39; \ge 0</span> where <span class="math inline">x = -x&#39;</span>, or variables <span class="math inline">x \text{ free}</span> with <span class="math inline">x&#39; \ge 0, x&#39;&#39; \ge 0</span> where <span class="math inline">x = x&#39; - x&#39;&#39;</span>.</li>
</ol>
<p>Alternatively, a more mechanical way:</p>
<ol type="1">
<li>If the LP is a minimization problem, invert the objective function and replace &quot;minimize&quot; with &quot;maximize&quot; to turn it into a maximization LP.</li>
<li>For each constraint <span class="math inline">\mathrm{row}_i(A) \cdot \vec x = b_i</span>, define a variable <span class="math inline">y \text{ free}</span>; for each constraint <span class="math inline">\mathrm{row}_i(A) \cdot \vec x \ge b_i</span>, define a variable <span class="math inline">y \ge 0</span>; for each constraint <span class="math inline">\mathrm{row}_i(A) \cdot \vec x \le b_i</span>, define a variable <span class="math inline">y_i \le 0</span>.</li>
<li>For each variable <span class="math inline">x_i \text{ free}</span>, define a constraint <span class="math inline">\mathrm{column}_i(A) \cdot \vec y = c_i</span>; for each variable <span class="math inline">x_i \ge 0</span>, define a constraint <span class="math inline">\mathrm{column}_i(A) \cdot \vec y \ge c_i</span>; For each variable <span class="math inline">x_i \le 0</span>, define a constraint <span class="math inline">\mathrm{column}_i(A) \cdot \vec y \le c_i</span>.</li>
</ol>
<p>A good way to memorize maximization LP dual conversion is &quot;convert constraints to variables (flipping inequalities in the process), convert variables to constraints, change maximize to minimize&quot;. A good way to memorize minimization LP dual conversion is &quot;convert constraints to variables, convert variables to constraints (flipping inequalities in the process), change minimize to maximize&quot;.</p>
<p>We can <strong>generalize the weak duality theorem to these arbitrary LPs</strong>: if <span class="math inline">\vec x_1</span> is feasible for the primal maximization LP and <span class="math inline">\vec x_2</span> is feasible for the dual minimization LP, then <span class="math inline">\vec c \cdot \vec x_2 \le \vec b \cdot \vec x_1</span>. Proof:</p>
<blockquote>
<p>Clearly, all inequality constraints can be converted into equality constraints using slack variables (e.g., <span class="math inline">\vec a \cdot \vec x \ge b</span> becomes <span class="math inline">\vec a \cdot \vec b + s = b</span> with the slack variable <span class="math inline">s \le 0</span>, and <span class="math inline">\vec a \cdot \vec x \le b</span> becomes <span class="math inline">\vec a \cdot \vec b + s = b</span> with the slack variable <span class="math inline">s \ge 0</span>).<br />
So all constraints in the primal LP can be written as <span class="math inline">A\vec x + \vec s = \vec b</span>, with the slack variables represented with <span class="math inline">\vec s</span>.<br />
If we take the dual of this, we get the constraints <span class="math inline">A^t \vec y + \vec w = \vec c</span> in the dual LP, where <span class="math inline">\vec w</span> represents the slack variables.<br />
Let <span class="math inline">\overline x</span> be a feasible solution for the primal LP, and let <span class="math inline">\overline y</span> be a feasible solution for the dual LP.<br />
Let <span class="math inline">\overline s = \vec b - A \overline x</span> represent the slack variable values in the primal LP, and let <span class="math inline">\overline w = \vec c - A^t \vec y</span> represent the slack variable values in the dual LP.<br />
Clearly, <span class="math inline">{\overline y}^T \vec b = {\overline y}^T (A \overline x + \overline s) = ({\overline y}^T A) \overline x + {\overline y}^T \overline s</span>, since <span class="math inline">A \overline x = \overline b</span>.<br />
Clearly, <span class="math inline">({\overline y}^T A) \overline x + {\overline y}^T \overline s = (\vec c - \overline w)^T \overline x + {\overline y}^T \overline s</span>, since <span class="math inline">{\overline y}^T A = (A^T \overline y)^T</span> and <span class="math inline">A^T \overline y + \overline w = \vec c</span>, so <span class="math inline">{A^T \overline y}^T = (\vec c - \overline w)^T</span>.<br />
Clearly, <span class="math inline">(\vec c - \overline w)^T \overline x + {\overline y}^T \overline s = {\vec c}^T \overline x - {\overline w}^T \overline x + {\overline y}^T \overline s</span>.<br />
We know that <span class="math inline">{\overline w}^T \overline x \le 0</span> and <span class="math inline">{\overline y}^T \overline s \ge 0</span> (we won't prove this in this course, but it follows from the way we defined slack variables initially).<br />
Therefore, <span class="math inline">{\overline y}^T \vec b \ge {\vec c}^T \overline x</span>, as required.</p>
</blockquote>
<p>This tells us the following:</p>
<ul>
<li>If an LP is unbounded, its dual is infeasible (if it wasn't, then the LP would have a bound).</li>
<li>If both an LP and its dual are feasible, they must both have optimal solutions (because they're not unbounded, and they're not infeasible, so this is true by the fundamental theorem of LPs).</li>
</ul>
<p>The <strong>Strong Duality Theorem</strong> is similar to the weak duality, but it deals with optimal solutions rather than feasible solutions: if <span class="math inline">\vec x_1</span> is an optimal solution for a primal LP, then there exists a <span class="math inline">\vec x_2</span> that's an optimal solution for its dual LP, such that <span class="math inline">\vec c \cdot \vec x_2 = \vec b \cdot \vec x_1</span>. Proof:</p>
<blockquote>
<p>Assume our LP is in SEF, so it's of the form &quot;maximize <span class="math inline">{\vec c}^T \vec x</span> subject to <span class="math inline">A \vec x = \vec b</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;. Since any LP can be converted into SEF, this assumption is without loss of generality.<br />
Then the dual must be &quot;minimize <span class="math inline">{\vec b}^T \vec y</span> subject to <span class="math inline">A^T \vec y \ge \vec c</span>&quot;. Assume that the primal LP has an optimal solution <span class="math inline">\overline x</span>.<br />
Then the 2-phase simplex algorithm must terminate with an optimal basis <span class="math inline">B</span>, so we can write the primal LP in canonical form for <span class="math inline">B</span> and multiply both sides of the constraints equation by <span class="math inline">A^{-1}</span>: &quot;maximize <span class="math inline">z = {\overline y}^T \vec b - {\overline c}^T \vec x</span> subject to <span class="math inline">\vec x_B = A_B^{-1} A_{\overline B} \vec x_{\overline B}</span> and <span class="math inline">\vec x \ge \vec 0</span>&quot;. Here, <span class="math inline">{\overline c}^T = {\vec c}^T - {\overline y}^T A</span>.<br />
So <span class="math inline">\overline x_B = A_B^{-1} \vec b</span> and <span class="math inline">\overline x_{\overline B} = \vec 0</span>. Note that the LP in canonical form is equivalent to the original LP in SEF - and <span class="math inline">\overline x</span> has the same objective value in both.<br />
Therefore, <span class="math inline">{\vec c}^T \overline x = {\overline y}^T \vec b = {\overline y}^T \vec b + {\vec c}^T \overline x</span>.<br />
Since <span class="math inline">\vec c</span> has 0 for all of the basic components, <span class="math inline">{\vec c_B}^T \overline x_B = 0</span>. Likewise, since <span class="math inline">\overline x_{\overline B} = \vec 0</span>, <span class="math inline">{\vec c_{\overline B}}^T = 0</span>. So <span class="math inline">{\vec c}^T \overline x = {\overline y}^T \vec b = \vec b \cdot \overline y</span>.<br />
Since <span class="math inline">B</span> is an optimal basis for the , we know from the Simplex algorithm that <span class="math inline">\overline c \le \vec 0</span> in the canonical form objective function, so <span class="math inline">{\vec c}^T - {\overline y}^T A \le 0</span>.<br />
So <span class="math inline">{\vec c}^T \le {\overline y}^T A</span>, which means <span class="math inline">\vec c \le A \overline y</span>, which means that <span class="math inline">\overline y</span> is feasible for the dual LP.<br />
Since <span class="math inline">\overline y</span> is a feasible solution whose objective function value is equal to that of a feasible solution of the primal LP, we've found an optimal solution to the dual LP that has the same objective function value, as required.</p>
</blockquote>
<p>The strong duality theorem tells us that if a primal LP and its dual are both feasible, then they can neither be infeasible nor unbounded, so they must have optimal solutions that have equal value.</p>
<p>This gives us the slightly stronger version of the strong duality theorem: if a primal LP and its dual are both feasible, then both have optimal solutions with the same objective function value. Otherwise, one must be unbounded, and the other must be infeasible.</p>
<p>Recall the proof for the weak duality theorem, where we wrote out our LP as &quot;maximize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">A \vec x + \vec s = \vec b</span> and <span class="math inline">\vec s \ge \vec 0</span>&quot;, with the dual &quot;minimize <span class="math inline">\vec b \cdot \vec y</span> subject to <span class="math inline">A^T \vec y = \vec c</span> and <span class="math inline">\vec y \ge 0</span>&quot;. In the process, we showed that <span class="math inline">\overline y \cdot \vec b = \overline y \cdot (A \overline x + \overline s) = {\overline y}^T A \overline x + {\overline y}^T \overline s = (A^T \overline y)^T \overline x + {\overline y}^T \overline s = {\vec c}^T \overline x + {\overline y}^T \overline s</span>.</p>
<p>According to the strong duality theorem, if <span class="math inline">\overline x, \overline y</span> are optimal for their respective LPs, then <span class="math inline">{\vec c}^T \overline x = {\overline y}^T \vec b</span>. So if <span class="math inline">\overline x, \overline y</span> are optimal for their respective LPs and <span class="math inline">\overline y \cdot \vec b = {\vec c}^T \overline x + {\overline y}^T \overline s</span> (<span class="math inline">\overline s</span> represents the slack variables), then <span class="math inline">{\overline y}^T \overline s = 0</span>.</p>
<p>Since <span class="math inline">\overline x, \overline y</span> are feasible solutions, <span class="math inline">\overline x \ge 0</span> and <span class="math inline">\overline y \ge 0</span>. Likewise, <span class="math inline">\overline s \ge 0</span> by definition. So if <span class="math inline">{\overline y}^T \overline s = 0</span>, then either <span class="math inline">\overline y_i = 0</span> or <span class="math inline">\overline s_i = 0</span> for all <span class="math inline">1 \le i \le n</span>. In other words, either <span class="math inline">\overline y_i = 0</span>, or constraint <span class="math inline">i</span> in the primal LP is tight (satisfied with equality).</p>
<p>This gives us the <strong>complementary slackness special case</strong>: if <span class="math inline">\overline x</span> is a feasible solution for a primal LP of the form &quot;maximize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">A \vec x \le \vec b</span>&quot; and <span class="math inline">\overline y</span> is a feasible solution of its dual &quot;minimize <span class="math inline">\vec b \cdot \vec y</span> subject to <span class="math inline">A^T \vec y = \vec c</span> and <span class="math inline">\vec y \ge 0</span>&quot;, <span class="math inline">\overline x</span> and <span class="math inline">\overline y</span> are optimal for their respective LPs if and only if for each <span class="math inline">1 \le i \le n</span>, either <span class="math inline">\overline y_i = 0</span>, or constraint <span class="math inline">i</span> of the primal LP is tight.</p>
<p>The <strong>general complementary slackness theorem</strong> is the general version of the complementary slackness special case. It says that given a feasible solution <span class="math inline">\overline x</span> of a primal LP and a feasible solution <span class="math inline">\overline y</span> of its dual LP, <span class="math inline">\overline x</span> and <span class="math inline">\overline y</span> are optimal exactly when they satisfy the <strong>complementary slackness conditions</strong>:</p>
<ol type="1">
<li>For each <span class="math inline">1 \le i \le m</span>, either <span class="math inline">\overline x_i = 0</span> or constraint <span class="math inline">i</span> of the dual LP is satisfied with equality (or both are true), and</li>
<li>For each <span class="math inline">1 \le j \le n</span>, either <span class="math inline">\overline y_j = 0</span> or constraint <span class="math inline">j</span> of the primal LP is satisfied with equality (or both are true).</li>
</ol>
<h2 id="geometric-interpretations-of-complementary-slackness">Geometric Interpretations of Complementary Slackness</h2>
<p>Given <span class="math inline">\vec a_1, \ldots, \vec a_k \in \mb{R}^n</span>, the <strong>cone generated by <span class="math inline">\vec a_1, \ldots, \vec a_k</span></strong> is <span class="math inline">C = \set{\lambda_1 \vec a_1 + \ldots + \lambda_k \vec a_k : \vec \lambda \ge \vec 0}</span>. Essentially, it's the set of all points that can be generated by linear combinations of a set of vectors using non-negative coefficients.</p>
<p>The <strong>cone of tight constraints</strong> for an LP and a feasible solution <span class="math inline">\overline x</span> is the cone generated by those rows of <span class="math inline">A</span> that correspond to tight constraints for <span class="math inline">A \overline x = \vec b</span>.</p>
<p>Interestingly, a feasible solution <span class="math inline">\overline x</span> is an optimal solution if and only if <span class="math inline">\vec c</span> is in the cone of tight constraints for <span class="math inline">\overline x</span>. This follows from the general complementary slackness theorem, and is useful for geometrically interpreting what an optimal solution is.</p>
<p>Intuitively, we can think of <span class="math inline">\vec c</span> as the &quot;direction to optimize in&quot;. We're basically trying to move <span class="math inline">\overline x</span> toward <span class="math inline">\vec c</span> as far as possible. When <span class="math inline">\vec c</span> is in the cone of tight constraints, <span class="math inline">\overline x</span> must have been moved until it reached a polyhedron vertex, unable to move further past that vertex into the cone, which would make it optimal.</p>
<h1 id="section-12">24/3/17</h1>
<h2 id="integer-and-linear-programs">Integer And Linear Programs</h2>
<p>LPs are nice because we have ways of efficiently solving huge LP instances (millions of variables/constraints). Additionally, it's easy to construct short certificates for optimality (Strong Duality), feasibility (Farka's Lemma), and unboundedness. Plus, the fundamental theorem of LPs tells us there can only be three possible outcomes for any given LP.</p>
<p>In contrast, IPs don't have any known efficient solver algorithms, and we don't know of any way to generate short certificates for the solver outcomes. Plus, IPs have a lot more possible outcomes. On the other hand, IPs can be used to formulate many more types of practical problems, and certain special cases can easily be solved in practice.</p>
<p>For example, here's an IP that is feasible, bounded, and doesn't have an optimal solution: &quot;maximize <span class="math inline">x_1 - \sqrt 2 x_2</span> subject to <span class="math inline">x_1 \le \sqrt 2 x_2</span>, <span class="math inline">x_1 \ge 1</span>, <span class="math inline">x_2 \ge 1</span>, and <span class="math inline">x_1, x_2 \text{ integer}</span>&quot;. This is because <span class="math inline">\sqrt 2</span> is irrational, so cannot be represented as a ratio. However, the IP tries to approximate <span class="math inline">\sqrt 2</span> as <span class="math inline">\frac{x_1}{x_2}</span>, and the approximation can get arbitrarily better with larger integers <span class="math inline">x_1</span> and <span class="math inline">x_2</span>. Therefore, no finite values for <span class="math inline">x_1, x_2</span> can be optimal. Formally:</p>
<blockquote>
<p>Suppose <span class="math inline">x_1, x_2</span> is an optimal solution to the LP.<br />
Let <span class="math inline">x_1&#39; = 2x_1 + 2x_2, x_2&#39; = x_1 + 2x_2</span>. Clearly, <span class="math inline">x_1&#39;, x_2&#39;</span> satisfies constraint 2 if <span class="math inline">x_1, x_2</span> did.<br />
Clearly, <span class="math inline">x_1&#39; \le \sqrt 2 x_2&#39; \iff 2x_1 + 2x_2 \le \sqrt 2 x_1 + \sqrt 2 2x_2 \iff (2 - \sqrt 2)x_1 \le \sqrt 2 2x_2 - 2 x_2 \iff (2 - \sqrt 2)x_1 \le (2 \sqrt 2 - 2) x_2 \iff x_1 \le \frac{2 \sqrt 2 - 2}{2 - \sqrt 2} x_2 = \sqrt 2 x_2</span>.<br />
Since <span class="math inline">x_1 \le \sqrt 2 x_2</span>, <span class="math inline">x_1&#39; \le \sqrt 2 x_2&#39;</span>, so <span class="math inline">x_1&#39;, x_2&#39;</span> is a feasible solution.<br />
Clearly, <span class="math inline">x_1&#39; - \sqrt 2 x_2&#39; &gt; x_1 - \sqrt 2 x_2 \iff (2x_1 + 2x_2) - \sqrt 2(x_1 + 2x_2) &gt; x_1 - \sqrt 2 x_2 \iff x_1 &lt; \frac{2 - \sqrt 2}{\sqrt 2 - 1} x_2 = \sqrt 2 x_2</span>.<br />
Clearly, <span class="math inline">x_1 &lt; \sqrt 2 x_2</span>, because if <span class="math inline">x_1 = \sqrt 2 x_2</span>, then <span class="math inline">\frac{x_1}{x_2} = \sqrt 2</span>, which is impossible since <span class="math inline">x_1, x_2</span> are integers and <span class="math inline">\sqrt 2</span> is irrational. So <span class="math inline">x_1&#39; - \sqrt 2 x_2&#39; &gt; x_1 - \sqrt 2 x_2</span>.<br />
So <span class="math inline">x_1, x_2</span> can't be optimal solutions to the LP, a contradiction. So the LP has no optimal solution.</p>
</blockquote>
<p>In theory, IPs can be reduced to LPs, the LPs can be solved, and the solutions can be turned back into solutions for the IPs. Though this is procedure is itself no more efficient than existing ways to solve IPs, it tells us a lot about the relationship between IPs and LPs.</p>
<p>The <strong>convex hull of a subset <span class="math inline">C</span> of <span class="math inline">\mb{R}^n</span></strong> is the smallest convex set that contains <span class="math inline">C</span>. Intuitively, it's the shape formed by tightly wrapping the region in cling film - all gaps and concavities are filled in to form a convex region.</p>
<p>Also, it turns out that every subset <span class="math inline">C</span> of <span class="math inline">\mb{R}^n</span> has exactly one possible convex hull. This is because if we suppose there were two or more possible convex hulls for <span class="math inline">C</span>, their set intersection is also a convex hull for <span class="math inline">C</span> (because both sets being intersected are convex and contain <span class="math inline">C</span>), but it would be smaller than at least one of the convex hulls, which contradicts the earlier fact that the two convex hulls are convex sets containing <span class="math inline">C</span> of minimum size.</p>
<p><strong>Meyer's Theorem</strong>: given the polyhedron <span class="math inline">P = \set{\vec x : A \vec x \le b}</span> where all values in <span class="math inline">A</span> and <span class="math inline">b</span> are rational, the convex hull of all integer points in <span class="math inline">P</span> is a polyhedron. The values must be rational because of cases like the one we saw above, where the IP's polyhedron is <span class="math inline">P = \set{\vec x : x_1 \le \sqrt 2 x_2, x_1 \ge 1, x_2 \ge 1}</span>. Here, the convex hull of all integer points is not a polyhedron - if you try to construct one, it'll take infinitey many halfspaces.</p>
<p>Meyer's theorem means that solving IPs can be reduced to solving LPs. Suppose we have an IP &quot;maximize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">A \vec x \le \vec b</span> and <span class="math inline">\vec x \text{ integer}</span>&quot;, where all values in <span class="math inline">A, \vec b</span> are rational. Clearly, the convex hull for the feasible solutions of the IP is a polyhedron <span class="math inline">A&#39; \vec x \le \vec b&#39;</span>, by Meyer's theorem.</p>
<p>Now consider the LP &quot;maximize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">A&#39; \vec x \le \vec b&#39;</span>&quot;. This LP is infeasible exactly when the IP is infeasible, and is unbounded exactly when the IP is unbounded. Furthermore, an optimal solution to the IP is also an optimal solution to the LP, and an optimal solution to the LP that is also an extreme point is an optimal solution to the IP.</p>
<p>So to solve the IP, we could find <span class="math inline">A&#39;</span> and <span class="math inline">\vec b&#39;</span>, use the Simplex algorithm to find an extreme optimal solution to the LP formed by <span class="math inline">A&#39;</span> and <span class="math inline">\vec b&#39;</span>, and then use those as solutions as solutions to the IP. However, this is not a practical way of solving IPs, because the size of <span class="math inline">A&#39;</span> and <span class="math inline">\vec b&#39;</span> can grow exponentially with respect to the size of <span class="math inline">A</span> and <span class="math inline">\vec b</span>. One common real-world technique for solving IPs is to approximate the convex hull for the integer points.</p>
<h2 id="solving-ips">Solving IPs</h2>
<p>First, we'll start by finding an optimal solution <span class="math inline">\overline x</span> for the LP relaxation of the IP first (the LP relaxation is the IP with the integrality constraints removed). This is easy to do using the simplex algorithm, but the solution we get is not always an integral solution.</p>
<p>Now we'll add another constraint <span class="math inline">\vec \alpha \cdot \vec x \le \beta</span> to the LP relaxation, such that the constraint is satisfied for all feasible solutions to the IP, but not for <span class="math inline">\overline x</span>. Such a constraint is known as a <strong>cutting plane</strong>.</p>
<p>If we add a cutting plane constraint to our LP relaxation, and then find an optimal solution <span class="math inline">x&#39;</span>, we note that the new optimal solution is now closer to at least one of the feasible solutions for the IP. By repeatedly adding cutting plane constraints and finding optimal solutions, we eventually run into an integer solution.</p>
<p>This process is called the <strong>cutting plane algorithm</strong>. Given the IP &quot;maximize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">A \vec x \le \vec b</span> and <span class="math inline">x \text{ integer}</span>&quot;:</p>
<ol type="1">
<li>Let P be the LP relaxation of the IP: &quot;maximize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">A \vec x \le \vec b</span>&quot;.</li>
<li>If P is infeasible, STOP and output that the IP is also infeasible.</li>
<li>Let <span class="math inline">\overline x</span> be an optimal solution to P, found using the Simplex algorithm.</li>
<li>If <span class="math inline">\overline x</span> is integral, STOP and output the optimal IP solution.</li>
<li>Find a cutting plane <span class="math inline">\vec \alpha \cdot \vec x \le \beta</span>.</li>
<li>Add the cutting plane constraint to P and go back to step 2.</li>
</ol>
<p>It turns out the Simplex algorithm already finds cutting planes - take the final canonical form of the LP, then ;wip: 05b slides.</p>
<h1 id="section-13">31/3/17</h1>
<p>Recall that NLPs are problems of the form &quot;maximize <span class="math inline">f(\vec x)</span> subject to <span class="math inline">g_i(\vec x) \le 0</span> for all <span class="math inline">1 \le i \le k</span>&quot;. NLP feasible regions don't need to be convex, or even connected. This is what makes solving them hard.</p>
<p>We can also write this as &quot;maximize <span class="math inline">\lambda</span> subject to <span class="math inline">\lambda - f(\vec x) \le 0</span> and <span class="math inline">g_i(\vec x) \le 0</span> for all <span class="math inline">1 \le i \le k</span>&quot;. At an optimal solution, it is always true that <span class="math inline">\lambda = f(\vec x)</span>. Because <span class="math inline">\lambda</span> is a linear function (of itself), <strong>we can always write any NLP such that it has a linear objective function</strong>. For the rest of this course, we'll assume that all NLPs we look at have linear objective functions.</p>
<p>NLPs generalize LPs and IPs. As we saw earlier, <span class="math inline">x_i = k</span> can be written as <span class="math inline">x_i \le k</span> and <span class="math inline">k \le x_i</span>, <span class="math inline">x_i \text{ integer}</span> can be written as <span class="math inline">\sin(\pi x_i) = 0</span>, and <span class="math inline">0 \le x_i \le 1, x_i \text{ integer}</span> can be written as <span class="math inline">x_i(x_i - 1) = 0</span>.</p>
<p>For our purposes, a feasible solution <span class="math inline">\vec x</span> to a minimization problem is a <strong>local optimum</strong> if and only if there exists a <span class="math inline">\delta &gt; 0</span> such that for any <span class="math inline">\vec x&#39;</span> such that <span class="math inline">\magn{\vec x&#39; - \vec x} \le \delta</span>, <span class="math inline">f(\vec x) &lt; f(\vec x&#39;)</span>. For a maximization problem, it's the same thing, but with <span class="math inline">f(\vec x) &gt; f(\vec x&#39;)</span> instead. Geometrically, local optima are feasible solutions for which there are no better solutions within some distance of it.</p>
<p>It turns out that if the feasible region is convex, all local optima are also global optima. Proof:</p>
<blockquote>
<p>Let <span class="math inline">S</span> be a convex feasible region for a minimization problem and <span class="math inline">\vec x \in S</span> be local optimum. Suppose <span class="math inline">\vec x</span> is not a global optimum. Let <span class="math inline">\vec x&#39; \ne \vec x</span> be a global optimum.<br />
Since <span class="math inline">\vec x</span> is a local optimum, for some <span class="math inline">\delta &gt; 0</span>, for any <span class="math inline">\vec z \in S</span> such that <span class="math inline">\magn{\vec z - \vec x} \le \delta</span>, <span class="math inline">\vec c \cdot \vec x \le \vec c \cdot \vec z</span>.<br />
Let <span class="math inline">\vec y = \lambda\vec x&#39; + (1 - \lambda)\vec x</span>. Since <span class="math inline">\vec x \in S</span> and <span class="math inline">\vec x&#39; \in S</span> and <span class="math inline">S</span> is convex, <span class="math inline">\vec y \in S</span>.<br />
Clearly, for <span class="math inline">\lambda = \delta</span>, <span class="math inline">\magn{\vec y - \vec x} \le \delta</span>. So <span class="math inline">\vec c \cdot \vec x \le \vec c \cdot \vec y</span>.<br />
However, <span class="math inline">\vec c \cdot \vec y = \vec c \cdot \left(\lambda\vec x&#39; + (1 - \lambda)\vec x\right) = \lambda \vec c \cdot \vec x&#39; + (1 - \lambda) \vec c \cdot \vec x</span>.<br />
Since <span class="math inline">\vec x&#39;</span> is a global optimum and <span class="math inline">\vec x</span> isn't, <span class="math inline">\vec c \cdot \vec x&#39; &lt; \vec c \cdot \vec x</span>. So <span class="math inline">\lambda \vec c \cdot \vec x&#39; + (1 - \lambda) \vec c \cdot \vec x &lt; \lambda \vec c \cdot \vec x + (1 - \lambda) \vec c \cdot \vec x = \vec c \cdot \vec x</span>.<br />
So, <span class="math inline">\vec c \cdot \vec y &lt; \vec c \cdot \vec x</span> and <span class="math inline">\vec c \cdot \vec x \le \vec c \cdot \vec y</span>, a contradiction! Therefore, <span class="math inline">\vec x</span> must be a global optimum.</p>
</blockquote>
<p>Our strategy so far for finding globally optimal solutions to optimization problems has been to find a feasible solution, and then repeatedly refine it until we find one we know is locally optimal. For convex problems, locally optimal solutions are always globally optimal solutions, so this works well. However, since NLPs can have non-convex feasible regions, there can be locally optimal solutions that aren't globally optimal.</p>
<p>A <strong>convex function</strong> is a function <span class="math inline">f(\vec x)</span> such that for all <span class="math inline">\vec a, \vec b, 0 \le k \le 1</span>, <span class="math inline">f(k\vec a + (1 - k)\vec b) \le kf(\vec a) + (1 - k)f(\vec b)</span>. Basically, a convex function is one where the function's value at the interpolation of any two points is always less or equal to the interpolation of the function's value at those two points. For example, 1D convex functions like <span class="math inline">f(x) = x^2</span> are always flat or open upward. A common way of proving convexity is to show that a function's second derivative with respect to <span class="math inline">k</span> is always positive.</p>
<p>For a convex function <span class="math inline">f(\vec x)</span> and constant <span class="math inline">\beta</span>, <span class="math inline">S = \set{\vec x \in \mb{R}^n : f(\vec x) \le \beta}</span> is a convex set. Proof:</p>
<blockquote>
<p>Let <span class="math inline">f(\vec x)</span> be a convex function. Let <span class="math inline">\beta</span> be a constant. Clearly, <span class="math inline">\vec x \in S</span> if and only if <span class="math inline">f(\vec x) \le \beta</span>.<br />
Let <span class="math inline">\vec a, \vec b \in S</span>, so <span class="math inline">f(\vec a) \le \beta</span> and <span class="math inline">f(\vec b) \le \beta</span>. Let <span class="math inline">\vec y = k\vec a + (1 - k)\vec b</span>.<br />
Since <span class="math inline">f(\vec x)</span> is a convex function, <span class="math inline">f(\vec y) \le kf(\vec a) + (1 - k)f(\vec b)</span>. Clearly, <span class="math inline">kf(\vec a) + (1 - k)f(\vec b) \le k\beta + (1 - k)\beta = \beta</span>.<br />
Since <span class="math inline">\vec y \le \beta</span>, <span class="math inline">S</span> is a convex set.</p>
</blockquote>
<p>The <strong>epigraph</strong> of a function <span class="math inline">f: \mb{R}^n \to \mb{R}</span> is defined by <span class="math inline">\mathrm{epi}(f) = \set{\begin{bmatrix} y \\ \vec x \end{bmatrix} : y \ge f(\vec x), \vec x \in \mb{R}^n}</span>. For 1D functions, it's the area above the curve; for 2D functions, it's the volume above the surface; and so on. The epigraph is a useful concept, because it's convex if and only if <span class="math inline">f(\vec x)</span> is convex.</p>
<p>Suppose we have an NLP &quot;maximize <span class="math inline">f(\vec x)</span> subject to <span class="math inline">g_1(\vec x) \le 0 \land \ldots \land g_k(\vec x) \le 0</span>&quot;. Let <span class="math inline">S_i = \set{\vec x \in \mb{R}^n : g_i(\vec x) \le 0}</span> for all <span class="math inline">1 \le i \le k</span>. Clearly, the feasible region of this NLP is <span class="math inline">S_1 \cap \ldots \cap S_k</span> - the intersection of all the values that satisfy each constraint.</p>
<p>If each <span class="math inline">g_i</span> is convex, then so is each <span class="math inline">S_i</span>, as we proved above. Since the intersection of convex sets is also convex, if each <span class="math inline">g_i</span> is convex, so is the feasible region of the NLP.</p>
<h2 id="the-kkt-theorem">The KKT Theorem</h2>
<p>The feasible region of an NLP is a region of <span class="math inline">\mb{R}^n</span>, where <span class="math inline">n</span> is the number of variables.</p>
<p>Suppose we have the NLP &quot;minimize <span class="math inline">-x_1 - x_2</span> subject to <span class="math inline">-x_2 + x_1^2 \le 0</span> and <span class="math inline">-x_1 + x_2^2 \le 0</span> and <span class="math inline">-x_1 + \frac 1 2 \le 0</span>&quot;. How do we prove that <span class="math inline">\overline x = \begin{bmatrix} 1 \\ 1 \end{bmatrix}</span> is an optimal solution?</p>
<p>We can get a relaxation of the NLP by arbitrariy removing some constraints: &quot;minimize <span class="math inline">-x_1 - x_2</span> subject to <span class="math inline">-x_2 + x_1^2 \le 0</span> and <span class="math inline">-x_1 + x_2^2 \le 0</span>&quot;.</p>
<p>We can further relax it by replacing the <span class="math inline">-x_2 = x_1^2 \le 0</span> constraint with <span class="math inline">2x_1 - x_2 \le 1</span>, which is always satisfied when <span class="math inline">-x_2 = x_1^2 \le 0</span> is satisfied, and is satisfied by equality at <span class="math inline">\overline x</span>.</p>
<p>We can do the same thing by replacing <span class="math inline">-x_1 + x_2^2 \le 0</span> with <span class="math inline">-x_1 + 2x_2 \le 1</span>, which is also satisfied when <span class="math inline">-x_1 + x_2^2 \le 0</span> and satisfied by equality at <span class="math inline">\overline x</span>.</p>
<p>The NLP then becomes &quot;minimize <span class="math inline">-x_1 - x_2</span> subject to <span class="math inline">2x_1 - x_2 \le 1</span> and <span class="math inline">-x_1 + 2x_2 \le 1</span>&quot;, which is just an LP. Clearly, <span class="math inline">\overline x</span> is an optimal solution to the LP relaxation, because the objective function coefficients are in the cone of tight constraints (we could also show this using strong duality, if we could find an optimal solution to the dual).</p>
<p>Since <span class="math inline">\overline x</span> is an optimal solution to the LP relaxation, and is also a feasible solution to the NLP, it must also be an optimal solution to the NLP, since the LP's feasible region is a superset of the NLP's feasible region - each NLP feasible solution is an LP relaxation feasible solution, so the best of all the LP relaxation feasible solutions is also the best NLP feasible solution, if it is an NLP feasible solution.</p>
<p>We can apply this technique for showing that a feasible NLP solution is optimal to any NLP.</p>
<p>A <strong>subgradient</strong> of a convex function <span class="math inline">f: \mb{R}^n \to \mb{R}</span> at a vector <span class="math inline">\overline x</span> is a vector <span class="math inline">\vec s \in \mb{R}^n</span> such that <span class="math inline">h(\vec x) \le f(\vec x)</span> for all <span class="math inline">\vec x \in \mb{R}^n</span> where <span class="math inline">h(\vec x) = f(\overline x) + \vec s \cdot (\vec x - \overline x)</span>.</p>
<p>Given a subgradient <span class="math inline">s</span>, <span class="math inline">h(\vec x)</span> is a linear function of <span class="math inline">\vec x</span>, <span class="math inline">h(\overline x) = f(\overline x)</span>, and <span class="math inline">h(\vec x)</span> is by definition always a lower bound for <span class="math inline">f(x)</span>. In other words, <span class="math inline">h(\vec x)</span> is a linear lower bound for a convex function <span class="math inline">f(\vec x)</span>, and <span class="math inline">\vec s</span> is the slope of <span class="math inline">h(\vec x)</span>.</p>
<p>Note that the subgradient is not unique - consider the subgradients possible at the extreme points of a polyhedron.</p>
<p>A halfspace <span class="math inline">F = \set{\vec x : \vec s \cdot \vec x \le \beta}</span> is <strong>supporting</strong> a convex set <span class="math inline">C</span> if and only if <span class="math inline">C \subseteq F</span> (the halfspace contains the convex set) and <span class="math inline">\vec s \cdot \vec x = \beta</span> (the halfspace is touching the convex set).</p>
<p>Given a convex function <span class="math inline">g(\vec x)</span> and a vector <span class="math inline">\overline x</span> such that <span class="math inline">g(\overline x) = 0</span> and a subgradient <span class="math inline">s</span> of <span class="math inline">g</span> at <span class="math inline">\overline x</span>, <span class="math inline">F = \set{\vec x : h(\vec x) \le 0}</span> is supporting <span class="math inline">C = \set{\vec x : g(\vec x) \le 0}</span> where <span class="math inline">h(x) = g(\overline x) + \vec s \cdot (\vec x - \overline x)</span>.</p>
<p>Proof:</p>
<blockquote>
<p>Let <span class="math inline">g(\vec x)</span> be a convex function and <span class="math inline">\overline x</span> be a value such that <span class="math inline">g(\overline x) = 0</span>.<br />
Let <span class="math inline">s</span> be a subgradient of <span class="math inline">g</span> at <span class="math inline">\overline x</span>.<br />
Since <span class="math inline">g(\vec x)</span> is a convex function, <span class="math inline">C = \set{\vec x : g(\vec x) \le 0}</span> is a convex set.<br />
Since <span class="math inline">h(\vec x)</span> is a linear function of <span class="math inline">\vec x</span>, <span class="math inline">F = \set{\vec x : h(\vec x) \le 0}</span> is a halfspace.<br />
Since <span class="math inline">h(\overline x) = g(\overline x) = 0 = \beta</span>, <span class="math inline">F</span> is on the boundary of <span class="math inline">C</span>.<br />
Since <span class="math inline">h(\vec x) \le g(\vec x) \le 0</span>, any <span class="math inline">\vec x \in F</span>, so <span class="math inline">C \subseteq F</span>.<br />
So <span class="math inline">C</span> is supporting <span class="math inline">F</span>.</p>
</blockquote>
<p>The above is useful because it allows us to construct LP relaxations of NLPs. Suppose we have the NLP &quot;maximize <span class="math inline">f(\vec x)</span> subject to <span class="math inline">g_1(\vec x) \le 0 \land \ldots \land g_k(\vec x) \le 0</span>&quot;. If <span class="math inline">\overline x</span> is a feasible solution of the NLP such that <span class="math inline">g_i(\overline x) = 0</span>, <span class="math inline">g_i</span> is convex, and <span class="math inline">\vec s</span> is a subgradient of <span class="math inline">g_i</span> at <span class="math inline">\overline x</span>, then we can replace the constraint <span class="math inline">g_i(\vec x) \le 0</span> with <span class="math inline">h(\vec x) \le 0</span> to get a linear version of that constraint.</p>
<p>So given an NLP for which all <span class="math inline">g_i</span> are convex, <span class="math inline">\overline x</span> is a feasible solution such that <span class="math inline">g_i(\overline x) = 0</span> for all tight constraints <span class="math inline">i \in I</span>, and <span class="math inline">\vec s_i</span> is a subgradient for <span class="math inline">g_i(\vec x)</span> at <span class="math inline">\overline x</span>, <span class="math inline">\overline x</span> is optimal <span class="math inline">-\vec c \in \mathrm{cone} \set{s_i : i \in I}</span> (the negative objective function is in the cone of the tight constraints).</p>
<p>To get an LP relaxation of the NLP for a feasible solution <span class="math inline">\overline x</span>, we can replace <span class="math inline">g_i(\vec x)</span> with <span class="math inline">h_i(\vec x)</span> for all tight constraints, and then discard the rest of the constraints.</p>
<p>Clearly, if the gradient <span class="math inline">\nabla f(\vec x)</span> of a convex function <span class="math inline">f(\vec x)</span> exists at <span class="math inline">\overline x</span>, then it's a subgradient of <span class="math inline">f(\vec x)</span> at <span class="math inline">\overline x</span>. We compute the gradient of a function of a vector as <span class="math inline">\nabla f(\vec x) = \begin{bmatrix} \frac{\dee f(\vec x)}{\dee x_1} \\ \vdots \\ \frac{\dee f(\vec x)}{\dee x_n} \end{bmatrix}</span>. Finding the gradient is a common way of finding a subgradient of a convex function at a given point.</p>
<p>A <strong>Slater point</strong> is a feasible solution <span class="math inline">\overline x</span> of an NLP &quot;minimize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">g_i(\vec x) \le 0</span> for all <span class="math inline">1 \le i \le k</span>&quot; such that for all <span class="math inline">1 \le i \le k</span>, <span class="math inline">g_i(\overline x) &lt; 0</span> (a feasible solution that isn't on the boundary of the feasible region).</p>
<p>The <strong>Karush-Kuhn-Tucker theorem</strong> (KKT theorem) says that given an NLP &quot;minimize <span class="math inline">\vec c \cdot \vec x</span> subject to <span class="math inline">g_i(\vec x) \le 0</span> for all <span class="math inline">1 \le i \le k</span>&quot; such that:</p>
<ul>
<li><span class="math inline">g_i(\vec x)</span> is convex for all <span class="math inline">1 \le i \le k</span>.</li>
<li>There exists a Slater point - a point within the feasible region.</li>
<li>There exists a feasible solution <span class="math inline">\overline x</span>.</li>
<li><span class="math inline">I</span> is the set of indices of tight constraints - the indices for which <span class="math inline">g_i(\overline x) = 0</span>.</li>
<li>For all <span class="math inline">i \in I</span>, there exists a gradient <span class="math inline">\nabla g_i(\overline x)</span> of <span class="math inline">g_i(\vec x)</span> at <span class="math inline">\overline x</span>.</li>
</ul>
<p>If this is the case, then <span class="math inline">\overline x</span> is optimal if and only if <span class="math inline">-\vec c \in \mathrm{cone}\set{\nabla g_i(\overline x) : i \in I}</span>.</p>
<p>The <span class="math inline">p</span>-norm of a vector <span class="math inline">\vec x</span> is defined as <span class="math inline">\magn{x}_p = \left(\sum \abs{x_i}^p\right)^{\frac 1 p}</span>.</p>
<p>The infinity-norm of a vector <span class="math inline">\vec x</span> is defined as <span class="math inline">\magn{x}_\infty = \max \set{\abs{x_1}, \ldots, \abs{x_n}}</span>.</p>
<div class="status-banner" style="display: none; position: fixed; bottom: 0; left: 0; right: 0; text-align: center;">
    <div style="display: inline-block; padding: 0.8em 2em 0.5em 2em; background: black; color: white; font-size: 2em;">
        Rendering <svg xmlns="http://www.w3.org/2000/svg" height="1.4em" viewbox="0 0 1200 500" style="vertical-align: text-bottom"><title>LaTeX logo</title><g transform="matrix(45 0 0 45 40 40)" fill="white"><path d="M5.5 4.4C5.5 4.4 5.2 4.4 5.2 4.4 5.1 5.4 5 6.7 3.2 6.7 3.2 6.7 2.4 6.7 2.4 6.7 1.9 6.7 1.9 6.6 1.9 6.3 1.9 6.3 1.9 1 1.9 1 1.9 0.6 1.9 0.5 2.9 0.5 2.9 0.5 3.2 0.5 3.2 0.5 3.2 0.5 3.2 0.2 3.2 0.2 2.8 0.2 1.9 0.2 1.5 0.2 1.1 0.2 0.3 0.2 0 0.2 0 0.2 0 0.5 0 0.5 0 0.5 0.2 0.5 0.2 0.5 1 0.5 1 0.6 1 0.9 1 0.9 1 6.2 1 6.2 1 6.6 1 6.7 0.2 6.7 0.2 6.7 0 6.7 0 6.7 0 6.7 0 7 0 7 0 7 5.2 7 5.2 7 5.2 7 5.5 4.4 5.5 4.4z"/><path d="M5.3 0.2C5.3 0 5.2 0 5.1 0 5 0 4.9 0 4.9 0.2 4.9 0.2 3.3 4.2 3.3 4.2 3.2 4.4 3.1 4.7 2.5 4.7 2.5 4.7 2.5 5 2.5 5 2.5 5 4 5 4 5 4 5 4 4.7 4 4.7 3.7 4.7 3.5 4.6 3.5 4.4 3.5 4.3 3.5 4.3 3.6 4.2 3.6 4.2 3.9 3.4 3.9 3.4 3.9 3.4 5.9 3.4 5.9 3.4 5.9 3.4 6.3 4.4 6.3 4.4 6.3 4.4 6.3 4.5 6.3 4.5 6.3 4.7 5.9 4.7 5.8 4.7 5.8 4.7 5.8 5 5.8 5 5.8 5 7.7 5 7.7 5 7.7 5 7.7 4.7 7.7 4.7 7.7 4.7 7.6 4.7 7.6 4.7 7.1 4.7 7.1 4.7 7 4.5 7 4.5 5.3 0.2 5.3 0.2zM4.9 0.9C4.9 0.9 5.8 3.1 5.8 3.1 5.8 3.1 4 3.1 4 3.1 4 3.1 4.9 0.9 4.9 0.9z"/><path d="M13.3 0.2C13.3 0.2 7.2 0.2 7.2 0.2 7.2 0.2 7 2.5 7 2.5 7 2.5 7.3 2.5 7.3 2.5 7.4 0.9 7.6 0.5 9.1 0.5 9.3 0.5 9.5 0.5 9.6 0.6 9.8 0.6 9.8 0.7 9.8 0.9 9.8 0.9 9.8 6.2 9.8 6.2 9.8 6.5 9.8 6.7 8.8 6.7 8.8 6.7 8.4 6.7 8.4 6.7 8.4 6.7 8.4 7 8.4 7 8.8 6.9 9.8 6.9 10.3 6.9 10.7 6.9 11.7 6.9 12.2 7 12.2 7 12.2 6.7 12.2 6.7 12.2 6.7 11.8 6.7 11.8 6.7 10.7 6.7 10.7 6.5 10.7 6.2 10.7 6.2 10.7 0.9 10.7 0.9 10.7 0.7 10.7 0.6 10.9 0.6 11 0.5 11.3 0.5 11.5 0.5 13 0.5 13.1 0.9 13.2 2.5 13.2 2.5 13.5 2.5 13.5 2.5 13.5 2.5 13.3 0.2 13.3 0.2z"/><path d="M18.7 6.7C18.7 6.7 18.4 6.7 18.4 6.7 18.2 8.2 17.9 8.9 16.2 8.9 16.2 8.9 14.9 8.9 14.9 8.9 14.4 8.9 14.4 8.8 14.4 8.5 14.4 8.5 14.4 5.9 14.4 5.9 14.4 5.9 15.3 5.9 15.3 5.9 16.3 5.9 16.4 6.2 16.4 7 16.4 7 16.6 7 16.6 7 16.6 7 16.6 4.4 16.6 4.4 16.6 4.4 16.4 4.4 16.4 4.4 16.4 5.2 16.3 5.5 15.3 5.5 15.3 5.5 14.4 5.5 14.4 5.5 14.4 5.5 14.4 3.2 14.4 3.2 14.4 2.8 14.4 2.8 14.9 2.8 14.9 2.8 16.2 2.8 16.2 2.8 17.7 2.8 18 3.3 18.1 4.7 18.1 4.7 18.4 4.7 18.4 4.7 18.4 4.7 18.1 2.5 18.1 2.5 18.1 2.5 12.5 2.5 12.5 2.5 12.5 2.5 12.5 2.8 12.5 2.8 12.5 2.8 12.7 2.8 12.7 2.8 13.5 2.8 13.5 2.9 13.5 3.2 13.5 3.2 13.5 8.4 13.5 8.4 13.5 8.8 13.5 8.9 12.7 8.9 12.7 8.9 12.5 8.9 12.5 8.9 12.5 8.9 12.5 9.2 12.5 9.2 12.5 9.2 18.2 9.2 18.2 9.2 18.2 9.2 18.7 6.7 18.7 6.7z"/><path d="M21.7 3.1C21.7 3.1 23 1.1 23 1.1 23.3 0.8 23.6 0.5 24.5 0.5 24.5 0.5 24.5 0.2 24.5 0.2 24.5 0.2 22.1 0.2 22.1 0.2 22.1 0.2 22.1 0.5 22.1 0.5 22.5 0.5 22.7 0.7 22.7 0.9 22.7 1 22.7 1.1 22.6 1.2 22.6 1.2 21.5 2.8 21.5 2.8 21.5 2.8 20.2 0.9 20.2 0.9 20.2 0.9 20.1 0.8 20.1 0.8 20.1 0.7 20.4 0.5 20.8 0.5 20.8 0.5 20.8 0.2 20.8 0.2 20.4 0.2 19.7 0.2 19.3 0.2 19 0.2 18.4 0.2 18 0.2 18 0.2 18 0.5 18 0.5 18 0.5 18.2 0.5 18.2 0.5 18.8 0.5 19 0.5 19.2 0.8 19.2 0.8 21 3.6 21 3.6 21 3.6 19.4 6 19.4 6 19.2 6.2 18.9 6.7 17.9 6.7 17.9 6.7 17.9 7 17.9 7 17.9 7 20.3 7 20.3 7 20.3 7 20.3 6.7 20.3 6.7 19.8 6.7 19.7 6.4 19.7 6.2 19.7 6.1 19.7 6.1 19.8 6 19.8 6 21.2 3.9 21.2 3.9 21.2 3.9 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.4 22.8 6.5 22.6 6.7 22.2 6.7 22.2 6.7 22.2 7 22.2 7 22.5 6.9 23.2 6.9 23.6 6.9 24 6.9 24.5 7 24.9 7 24.9 7 24.9 6.7 24.9 6.7 24.9 6.7 24.7 6.7 24.7 6.7 24.2 6.7 24 6.6 23.8 6.3 23.8 6.3 21.7 3.1 21.7 3.1z"/></g></svg> math...
    </div>
</div>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Anthony Zhang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2017 Anthony Zhang.
</div>
</body>
</html>
