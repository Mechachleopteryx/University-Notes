<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>MATH138 | Anthony Zhang</title>
  <link rel="stylesheet" href="../css/base.css" type="text/css">
  <link rel="stylesheet" href="../css/note.css" type="text/css">
  <link rel="stylesheet" href="../highlight/styles/default.css">
  <link rel="stylesheet" href="../highlight/styles/paraiso-light.css">
  <script src="../highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script src="../katex/katex.min.js" type="text/javascript"></script>
  <link rel="stylesheet" href="../katex/katex.min.css" />
  <script type="text/javascript">
  window.onload = function() {
    document.getElementsByClassName("status-banner")[0].style.display = "block";
    setTimeout(function() {
      renderMathElements(document.getElementsByClassName("math"));
      document.getElementsByClassName("status-banner")[0].style.display = "none";
    }, 50); // delay to allow status banner to show
  }

  function renderMathElements(mathElements) {
    var mathOptions = {
      macros: {
        "\\set": "\\left\\{ #1 \\right\\}",
        "\\tup": "\\left\\langle #1 \\right\\rangle",
        "\\abs": "\\left\\lvert #1 \\right\\rvert",
        "\\floor": "\\left\\lfloor #1 \\right\\rfloor",
        "\\ceil": "\\left\\lceil#1 \\right\\rceil",
        "\\mb": "\\mathbb{#1}",
        "\\rem": "\\operatorname{rem}",
        "\\ord": "\\operatorname{ord}",
        "\\sign": "\\operatorname{sign}",
        "\\imag": "\\bm{i}",
        "\\dee": "\\mathop{}\\!\\mathrm{d}",
        "\\lH": "\\overset{\\text{l'H}}{=}",
        "\\evalat": "\\left.\\left(#1\\right)\\right|",
        "\\sech": "\\operatorname{sech}",
        "\\spn": "\\operatorname{Span}",
        "\\proj": "\\operatorname{proj}",
        "\\prp": "\\operatorname{perp}",
        "\\refl": "\\operatorname{refl}",
        "\\magn": "\\left\\lVert #1 \\right\\rVert",
        "\\rank": "\\operatorname{rank}",
        "\\trace": "\\operatorname{trace}",
        "\\sys": "\\left[ #1 \\mid #2\\space \\right]",
        "\\range": "\\operatorname{Range}",
        "\\adj": "\\operatorname{adj}",
        "\\cof": "\\operatorname{cof}",
        "\\coord": "{\\left\\lbrack #1 \\right\\rbrack}_{#2}",
        "\\diag": "\\operatorname{diag}",
        "\\formlp": "\\operatorname{Form}(\\mathcal{L}^P)",
        "\\argmin": "\\operatorname{argmin}",
        "\\argmax": "\\operatorname{argmax}",
        "\\sgn": "\\operatorname{sgn}",

        // not yet available in KaTeX
        "\\bm": "\\mathbf", //wip: should be italic, but isn't
      },
    };
    for (var i=0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      try {
        katex.render(texText.data, mathElements[i], mathOptions);
      } catch (e) {
        console.error(e);
        console.log(mathElements[i]);
      }
    }
  }
  </script>
</head>
<body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68271407-1', 'auto');
    ga('send', 'pageview');

  </script>
  <h1>Lecture Notes by <a href="/">Anthony Zhang</a>.</h1>
  <ul class="site_links">
    <li><a href="/blog/" class="page">blog</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.github.io/University-Notes" class="page">notes</a></li>
    <span class="divider"></span>
    <li><a href="/resume.pdf" class="page">résumé</a></li>
    <span class="divider"></span>
    <li><a href="https://github.com/Uberi" class="contact">github</a></li>
    <span class="divider"></span>
    <li><a href="https://www.linkedin.com/in/uberi/" class="contact">linkedin</a></li>
    <span class="divider"></span>
    <li><a href="mailto:me@anthonyz.ca" class="contact">email</a></li>
    <span class="divider"></span>
    <li><a href="https://www.facebook.com/anthony.zhang.user" class="contact">facebook</a></li>
    <span class="divider"></span>
    <li><a href="https://twitter.com/anthony926535" class="contact">twitter</a></li>
    <span class="divider"></span>
    <li><a href="https://keybase.io/uberi" class="info">public key</a></li>
  </ul>
<h1 id="math138">MATH138</h1>
<p>Calculus II</p>
<pre><code>Instructor: Matthew Scott
Section 002
Email: mscott@uwaterloo.ca
Office: MC 6114
Office hours: Mondays 11:30am-12:15pm, 3:00pm-3:30pm
Tutorial: Wednesdays 3:30pm in MC 2035, starting Jan. 15</code></pre>
<h1 id="section">6/1/14</h1>
<p>Assignments are due every Friday at 3:30pm. They are posted on LEARN.</p>
<p>My own drop box is box 5, slot 12</p>
<p>Midterm is Feb. 24, 7-9pm.</p>
<p>Lecture notes are on the <a href="http://www.math.uwaterloo.ca/~mscott/euler.htm">course website</a>, posted every week. The password to the website is &quot;euler&quot;. ;wip: get these every week</p>
<p>Course outline:</p>
<ul>
<li>Techniques of integration and applications.</li>
<li>Extensions of single variable calculus - differential equations, vector calculus, etc.</li>
<li>Taylor polynomials</li>
</ul>
<p>Sequence: <span class="math inline">1, 2, 3, \ldots</span> Series: <span class="math inline">1 + 2 + 3 + \ldots</span></p>
<p>Taylor polynomials are series of functions, which allow us to represent almost any function as a polynomial. This is the most powerful technique in applied mathematics - science and mathematics.</p>
<p>By the way, <span class="math inline">\dee x</span> is called an <strong>infinitesmal</strong>.</p>
<h2 id="techniques-of-integration">Techniques of Integration</h2>
<p>Techniques of integration rewrite functions in forms that we can't integrate into forms that we can integrate, or simpler forms that we might be able to apply other techniques on.</p>
<h3 id="method-of-substitution">Method of substitution</h3>
<p>The method of substitution is based on choosing a subexpression <span class="math inline">u</span>, and then integrating with respect to it. If <span class="math inline">u</span> is chosen carefully, it is occasionally possible to simplify the integral.</p>
<p>This method works best when a <strong>function and its derivative appear in the integrand</strong>.</p>
<p>This works with expressions of the form <span class="math inline">\int f(x) \frac{\dee f}{\dee x} \dee x</span>.</p>
<p>Let <span class="math inline">u = f(x)</span>. Since <span class="math inline">\frac{\dee u}{\dee x} = \frac{\dee u}{\dee x}</span>, <span class="math inline">\dee u = \frac{\dee u}{\dee x} \dee x</span> (multiply both sides by <span class="math inline">\dee x</span>). This is possible because of infinismals, which work in wierd and wonderful ways. So <span class="math inline">\dee x = \frac{1}{\frac{\dee u}{\dee x}} \dee u</span>.</p>
<p>So <span class="math inline">\int f(x) \frac{\dee}{\dee x} f(x) \dee x = \int u \frac{\dee u}{\dee x} \dee x = \int u \frac{\dee u}{\dee x} \frac{1}{\frac{\dee u}{\dee x}} \dee u = \int u \dee u = \frac{u^2}{2} + c = \frac{f(x)^2}{2} + c</span>.</p>
<p>Even if we can't simplify it far enough to get an antiderivative, integration by substitution can still considerably simplify an integrand into something more manageable.</p>
<p>What about definite integrals? We need to be aware of the limits of integration when doing the variable switch:</p>
<p>We are given <span class="math inline">\int_a^b f(x) \frac{\dee}{\dee x} f(x) \dee x</span>.</p>
<p>Let <span class="math inline">u = f(x)</span>. We know that <span class="math inline">\dee x = \frac{1}{\frac{\dee u}{\dee x}} \dee u</span>.</p>
<p>So <span class="math inline">\int_a^b f(x) \frac{\dee}{\dee x} f(x) \dee x = \int_{u(a)}^{u(b)} u \frac{\dee u}{\dee x} \dee x = \int_{u(a)}^{u(b)} u \frac{\dee u}{\dee x} \frac{1}{\frac{\dee u}{\dee x}} \dee u = \int_{u(a)}^{u(b)} u \dee u = \evalat{\frac{u^2}{2}}_{u(a)}^{u(b)} + c = \evalat{\frac{f(x)^2}{2}}_a^b + c</span>.</p>
<p>Basically, if we can find a factor of the integrand <span class="math inline">u</span> such that its derivative also appears in the integrand, the method of substitution can get rid of the derivative.</p>
<p>Evaluate <span class="math inline">\int \cos x \sin x \dee x</span></p>
<blockquote>
<p>Let <span class="math inline">u = \sin x</span>. So <span class="math inline">\dee u = \cos x \dee x</span>.<br />
So <span class="math inline">\int \cos x \sin x \dee x = \int \sin x \dee u = -\int u \dee u</span>.<br />
Clearly, <span class="math inline">\int u \dee u = \frac{u^2}{2} + c = \frac{\sin^2 x}{2} + c</span>.</p>
</blockquote>
<p>Substitution is useful when we can figure out what a useful substitution would be.</p>
<p>One clue that the substitution is a good choice is if the derivative of the substitution appears in the numerator of the function.</p>
<p>How do we prove that <span class="math inline">\int_1^x \frac{1}{t} = \ln x</span>? How do we know that both have the same properties:</p>
<ul>
<li>Property 1 - multiplication rule: <span class="math inline">\ln ab = \ln a + \ln b</span></li>
<li>Property 2 - power rule: <span class="math inline">\ln a^r = r \ln a</span>)</li>
</ul>
<p>We want to prove property 1:</p>
<blockquote>
<p>Select some <span class="math inline">a</span> and <span class="math inline">b</span>.<br />
We want to prove that <span class="math inline">\int_1^{ab} \frac{1}{t} \dee t = \int_1^a \frac{1}{t} \dee t + \int_1^b \frac{1}{t} \dee t</span>.<br />
By linearity of integrals, <span class="math inline">\int_1^{ab} \frac{1}{t} \dee t = \int_1^a \frac{1}{t} \dee t + \int_a^{ab} \frac{1}{t} \dee t</span>.<br />
Let <span class="math inline">u = \frac{t}{a}</span>, so <span class="math inline">t = ua</span>. Then <span class="math inline">\dee t = \frac{\dee t}{\dee u} \dee u = a \dee u</span>.<br />
So <span class="math inline">\int_a^{ab} \frac{1}{t} \dee t = \int_\frac{a}{a}^\frac{ab}{a} \frac{1}{ua} a \dee u = \int_1^b \frac{1}{u} \dee u</span>.<br />
So <span class="math inline">\int_1^{ab} \frac{1}{t} \dee t = \int_1^a \frac{1}{t} \dee t + \int_a^{ab} \frac{1}{t} \dee t = \int_1^a \frac{1}{t} \dee t + \int_1^b \frac{1}{u} \dee u</span>.</p>
</blockquote>
<p>Dummy variables can be swapped for any value, even functions like <span class="math inline">f(t)</span>.</p>
<h1 id="section-1">8/1/14</h1>
<p>To prove property 2, we need to show that <span class="math inline">\int_1^{a^r} \frac{1}{u} \dee u = r \int_1^a \frac{1}{t} \dee t</span>. To do this, we find a substitution that results in the desired limits of integration.</p>
<p>To prove property 2:</p>
<blockquote>
<p>Select some <span class="math inline">u</span>.<br />
We want to prove that <span class="math inline">\int_1^{a^r} \frac{1}{t} \dee t = r \int_1^a \frac{1}{t} \dee t</span>.<br />
Let <span class="math inline">u = t^\frac{1}{r}</span>, so <span class="math inline">t = u^r</span>. Then <span class="math inline">\dee t = \frac{\dee t}{\dee u} \dee u = \frac{\dee}{\dee u} u^r \dee u = ru^{r - 1} \dee u</span>.<br />
So <span class="math inline">\int_1^{a^r} \frac{1}{t} \dee t = \int_{1^\frac{1}{r}}^{{a^r}^\frac{1}{r}} \frac{1}{u^r} ru^{r - 1} \dee u = \int_1^a \frac{1}{u} r \dee u = r \int_1^a \frac{1}{u} \dee u</span>.</p>
</blockquote>
<h3 id="differentiating-with-respect-to-functions">Differentiating with respect to functions</h3>
<p>As an aside, we can actually differentiate things with respect to functions.</p>
<p>The important property is that <span class="math inline">\frac{\dee x}{\dee b(x)} = \frac{1}{\frac{\dee b(x)}{\dee x}}</span>.</p>
<p>Note that <span class="math inline">\frac{\dee a(x)}{\dee b(x)} = \frac{\dee a(x)}{\dee x} \frac{\dee x}{\dee b(x)} = \frac{\dee a(x)}{\dee x} \frac{1}{\frac{\dee b(x)}{\dee x}}</span>.</p>
<p>So <span class="math inline">\frac{\dee a(x)}{\dee b(x)} = \frac{\frac{\dee a(x)}{\dee x}}{\frac{\dee b(x)}{\dee x}} = \frac{a&#39;(x)}{b&#39;(x)}</span>.</p>
<h3 id="integration-by-parts">Integration by Parts</h3>
<p>We often have integrands that are products. For example, <span class="math inline">\int x \sin x \dee x</span></p>
<p>It would be nice to be able to differentiate or integrate just one of the factors rather than having to do the whole thing.</p>
<p>Recall the product rule: <span class="math inline">\frac{\dee}{\dee x} (a(x) b(x)) = (\frac{\dee}{\dee x} a(x)) b(x) + a(x) \frac{\dee}{\dee x} b(x)</span>.</p>
<p>Move the terms around: <span class="math inline">(\frac{\dee}{\dee x} a(x)) b(x) = \frac{\dee}{\dee x} (a(x) b(x)) - a(x) \frac{\dee}{\dee x} b(x)</span>.</p>
<p>If we integrate both sides with respect to <span class="math inline">x</span>, we get: <span class="math inline">\int (\frac{\dee}{\dee x} a(x)) b(x) = \int \frac{\dee}{\dee x} a(x) b(x) - \int a(x) \frac{\dee}{\dee x} b(x)</span>.</p>
<p>By FTC2, <span class="math inline">\int (\frac{\dee}{\dee x} a(x)) b(x) = a(x) b(x) + c - \int a(x) \frac{\dee}{\dee x} b(x)</span>.</p>
<p>Since there would also be a <span class="math inline">c</span> term from the second integral, we don't need to write it. So <span class="math inline">\int (\frac{\dee}{\dee x} a(x)) b(x) \dee x = a(x) b(x) - \int a(x) \frac{\dee}{\dee x} b(x) \dee x</span>.</p>
<p>This is the <strong>integration by parts rule</strong>.</p>
<p>Using the same idea, we find that <span class="math inline">\int_a^b (\frac{\dee}{\dee x} a(x)) b(x) = \evalat{a(x) b(x)}_{x = a}^{x = b} - \int_a^b a(x) \frac{\dee}{\dee x} b(x)</span>.</p>
<p>When we use the rule, we want to identify two parts of the product such that one of the parts (b) is the factor that becomes <strong>simpler when differentiated</strong>, and the other part (a) is chosen as the <strong>integral of the factor</strong>.</p>
<p>Simplify <span class="math inline">\int x \sin x \dee x</span>:</p>
<blockquote>
<p><span class="math inline">x</span> is much simpler when differentiated. Let <span class="math inline">b(x) = x</span>.<br />
<span class="math inline">\sin x</span> is integrable. Let <span class="math inline">a(x) = \int \sin x = -\cos x</span>.<br />
So <span class="math inline">\int x \sin x = \int x \frac{\dee}{\dee x} (-\cos x) = -x \cos x - \int (-\cos x) 1 \dee x</span>, by integration by parts.<br />
So <span class="math inline">-x \cos x - \int (-\cos x) 1 \dee x = -x \cos x + \sin x + c</span>.</p>
</blockquote>
<p>We can check the answer by differentiating: <span class="math inline">\frac{\dee}{\dee x} (-x \cos x + \sin x + c) = x \sin x</span>.</p>
<p>When we use integration by parts, we differentiate one factor, and integrate the other. Then, we can apply the integration by parts formula and obtain a possibly simpler version.</p>
<p>Simplify <span class="math inline">\int_0^1 x e^{-x} \dee x</span>:</p>
<blockquote>
<p><span class="math display">\displaystyle 
\begin{aligned}
\int_0^1 x e^{-x} \dee x &amp;= \int_0^1 x \frac{\dee}{\dee x} (-e^{-x}) \dee x \\
&amp;= \evalat{x (-e^{-x})}_0^1 - \int_0^1 \left(\frac{\dee}{\dee x} x\right) (-e^{-x}) \dee x \\
&amp;= \evalat{x (-e^{-x})}_0^1 + \int_0^1 e^{-x} \dee x \\
&amp;= -\frac{2}{e}
\end{aligned}
</span></p>
</blockquote>
<p>Simplify <span class="math inline">\int_0^1 x^n (\ln x)^n \dee x</span>:</p>
<blockquote>
<p>;wip</p>
</blockquote>
<p>We often write the integration by parts formula in different forms: <span class="math inline">\int a \dee b = ab - \int b \dee a</span>, or <span class="math inline">\int f&#39;(x) g(x) \dee x = f(x) g(x) - \int f(x) g&#39;(x) \dee x</span>.</p>
<p>An interesting trick is that we can use integration by parts to integrate anything, since everything is a product of itself and 1.</p>
<p>For example, consider <span class="math inline">\int \arcsin x \dee x</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\int 1 \cdot \arcsin x \dee x = \int (\frac{\dee}{\dee x} x) \arcsin x \dee x</span>.<br />
Using integration by parts, with <span class="math inline">a(x) = x, b(x) = \arcsin x</span>, <span class="math inline">\int (\frac{\dee}{\dee x} x) \arcsin x \dee x = x \arcsin x - \int \frac{x}{\sqrt{1 - x^2}} \dee x</span>.<br />
We can now use integration by substitution with <span class="math inline">u = 1 - x^2</span> to simplify <span class="math inline">\int \frac{x}{\sqrt{1 - x^2}} \dee x</span>.<br />
Clearly, <span class="math inline">\dee x = -\frac{1}{2x} \dee x</span> and <span class="math inline">\int \frac{1}{\sqrt{1 - x^2}} \dee x = -\frac{1}{2} \int \frac{1}{\sqrt{u}} \dee u = -\frac{1}{2} \int u^{-\frac{1}{2}} \dee u = -\frac{1}{2} 2 \sqrt{u} + c = -\sqrt{1 - x^2} + c</span>.<br />
So <span class="math inline">\int \arcsin x \dee x = x \arcsin x - \int \frac{x}{\sqrt{1 - x^2}} \dee x = x \arcsin x + \sqrt{1 - x^2} + c</span>.</p>
</blockquote>
<p>Simplify <span class="math inline">\int \arccos x \dee x</span>:</p>
<blockquote>
<p>Using integration by parts, with <span class="math inline">a(x) = x, b(x) = \arccos x</span>, <span class="math inline">\int (\frac{\dee}{\dee x} x) \arccos x \dee x = x \arccos x - \int \frac{x}{\sqrt{1 - x^2}} \dee x</span>.<br />
From the previous question, we know that <span class="math inline">\int \frac{x}{\sqrt{1 - x^2}} \dee x = -\sqrt{1 - x^2} + c</span>.<br />
So <span class="math inline">\int (\frac{\dee}{\dee x} x) \arccos x \dee x = x \arccos x - \int \frac{x}{\sqrt{1 - x^2}} \dee x = x \arccos x + \sqrt{1 - x^2} + c</span>.</p>
</blockquote>
<p>Simplify <span class="math inline">\int \ln x \dee x</span>:</p>
<blockquote>
<p>Using integration by parts, with <span class="math inline">a(x) = x, b(x) = \arccos x</span>. <span class="math inline">\int (\frac{\dee}{\dee x} x) \ln x \dee x = x \ln x - \int \frac{x}{x} \dee x = x \ln x - x</span>.</p>
</blockquote>
<h1 id="section-2">10/1/14</h1>
<p>The integration by parts rule is also written as <span class="math inline">\int v \dee u = uv - \int u \dee v</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\dee a = \frac{\dee a}{\dee x} \dee x</span> and <span class="math inline">\dee b = \frac{\dee b}{\dee x} \dee x</span>.<br />
We know that <span class="math inline">\int (\frac{\dee}{\dee x} a(x)) b(x) \dee x = a(x) b(x) - \int a(x) \frac{\dee}{\dee x} b(x) \dee x</span> and so <span class="math inline">\int \frac{\dee a}{\dee x} b(x) \dee x = a(x) b(x) - \int a(x) \frac{\dee b}{\dee x} \dee x</span>.<br />
So <span class="math inline">\int b(x) \dee a = a(x) b(x) - \int a(x) \dee b</span>.</p>
</blockquote>
<p>We can also write it as <span class="math inline">\int f(x) g(x) \dee x = \int f(x) \dee x g(x) - \int \int f(x) \dee x \frac{\dee g}{\dee x} \dee x</span>.</p>
<h3 id="getting-back-what-we-started-with">Getting Back What We Started With</h3>
<p>Consider <span class="math inline">I = \int e^{-x} \sin x</span>:</p>
<blockquote>
<p>We choose <span class="math inline">\frac{\dee}{\dee x} e^{-x} = -e^{-x}</span> and <span class="math inline">\int \sin x \dee x = -\cos x</span>.<br />
So <span class="math inline">I = \int e^{-x} \frac{\dee}{\dee x} (-\cos x) \dee x = e^{-x} (-\cos x) - \int e^{-x} \cos x</span>.<br />
We choose <span class="math inline">\frac{\dee}{\dee x} (-e^{-x}) = e^{-x}</span> and <span class="math inline">\int \cos x \dee x = \sin x</span>.<br />
Clearly, <span class="math inline">\int e^{-x} \cos x = \int e^{-x} \frac{\dee}{\dee x} \sin x = e^{-x} \sin x - \int (-e^{-x}) \sin x = e^{-x} \sin x + I</span>.<br />
So <span class="math inline">I = -e^{-x} \cos x - \int e^{-x} \cos x = -e^{-x} \cos x - e^{-x} \sin x - I</span>.<br />
So <span class="math inline">2I = -e^{-x} (\cos x + \sin x)</span> and <span class="math inline">I = -\frac{1}{2}e^{-x} (\cos x + \sin x)</span>.</p>
</blockquote>
<p>Basically, we used integration by parts to rewrite the expression, then used integration by parts again to simplify the remaining integral. In doing so we obtained a result that contained the original expression, which we substituted and solved algebraically.</p>
<p>This technique is only really useful for problems of the form <span class="math inline">\int e^{ax} \sin bx \dee x</span> or <span class="math inline">\int e^{ax} \cos bx \dee x</span>.</p>
<p>Simplify <span class="math inline">\int_0^1 (-\ln x)^n \dee x, n \in \mb{N}</span>:</p>
<blockquote>
<p>We will try it for the first few values of <span class="math inline">n</span>.<br />
For <span class="math inline">n = 1</span>, <span class="math inline">\int_0^1 (-\ln x)^n \dee x = -\int_0^1 1 \ln x \dee x = -\int_0^1 \ln x \frac{\dee}{\dee x} x = -\evalat{x \ln x}_0^1 + \int_0^1 x \frac{1}{x} = -1 \ln 1 + 0 \ln 0 + 1</span> (indeterminate form <span class="math inline">0 \cdot -\infty</span>).<br />
This is a thing known as an improper integral (covered later in the course).<br />
We can solve it because what we really want is <span class="math inline">\lim_{x \to 0} x \ln x = \lim_{x \to 0} \frac{\ln x}{\frac{1}{x}} \lH \lim_{x \to 0} \frac{\frac{1}{x}}{-\frac{1}{x^2}} = \lim_{x \to 0} (-x) = 0</span> rather than the value <span class="math inline">0 \ln 0</span>.<br />
So <span class="math inline">-\int_0^1 \ln x \dee x = -1 \ln 1 + 0 + 1 = 1</span>.<br />
If we repeat this for <span class="math inline">n = 2, 3, \ldots</span>, we find that <span class="math inline">\int_0^1 (-\ln x)^n \dee x = n!, n \in \mb{N}</span>, yet it also works for fractional values of <span class="math inline">n</span> - this is the generalized factorial over positive real numbers!<br />
;wip: use induction</p>
</blockquote>
<h1 id="section-3">13/1/14</h1>
<h2 id="trigonometric-substitution">Trigonometric Substitution</h2>
<p>This is integration by substitution with the substitution using trignonometric functions.</p>
<p>We use trigonometric functions in our substitutions and use trigonometric identities to simplify the integrand.</p>
<p>We will need to know:</p>
<ul>
<li>Pythagorean theorem: <span class="math inline">\cos^2 \theta + \sin^2 \theta = 1</span></li>
<li>Half angle cosine formula: <span class="math inline">\cos^2 \theta = \frac{1}{2}(1 + \cos 2\theta)</span></li>
<li>Half angle sine formula: <span class="math inline">\sin^2 \theta = \frac{1}{2}(1 - \cos 2\theta)</span></li>
<li>Pythagorean theorem divided by <span class="math inline">\cos^2 \theta</span>: <span class="math inline">1 + \tan^2 \theta = \sec^2 \theta</span></li>
</ul>
<p>We usually need this method when we have a square root of a quadratic expression.</p>
<p>Common substitutions:</p>
<ul>
<li>Use <span class="math inline">1 - \sin^2 \theta = \cos^2 \theta</span> to use <span class="math inline">\sqrt{1 - x^2} = \sqrt{\cos^2 \theta} = \cos \theta</span> via <span class="math inline">x = \sin \theta</span>.</li>
<li>Use <span class="math inline">1 + \tan^2 \theta = \sec^2 \theta</span> to use <span class="math inline">\sqrt{1 + x^2} = \sqrt{\sec^2 \theta} = \sec \theta</span> via <span class="math inline">x = \tan \theta</span>.</li>
<li>Use <span class="math inline">\sec^2 \theta - 1 = \tan^2 \theta</span> to use <span class="math inline">\sqrt{x^2 - 1} = \sqrt{\tan^2 \theta} = \tan \theta</span> via <span class="math inline">x = \sec \theta</span>.</li>
</ul>
<p>Using this technique, we can replace <span class="math inline">\sqrt{\pm a^2 \pm x^2}</span> with trigonometric functions, and then use trigonometric identities on them. Afterwards, we might simplify by changing the trigonometric functions back into square roots.</p>
<p>Derivatives:</p>
<ul>
<li><span class="math inline">\cos&#39; \theta = -\sin \theta</span> where <span class="math inline">-\frac{\pi}{2} \le \theta &lt; \frac{\pi}{2}</span></li>
<li><span class="math inline">\sin&#39; \theta = \cos \theta</span> where <span class="math inline">-\frac{\pi}{2} \le \theta &lt; \frac{\pi}{2}</span></li>
<li><span class="math inline">\tan&#39; \theta = \sec^2 \theta</span> where <span class="math inline">0 \le \theta &lt; \frac{\pi}{2}</span></li>
</ul>
<p>Consider <span class="math inline">\int \frac{1}{x^2 \sqrt{x^2 + 4}} \dee x</span>:</p>
<blockquote>
<p>We can draw a triangle with hypotenuse <span class="math inline">\sqrt{x^2 + 4}</span>, opposite side <span class="math inline">x</span>, and adjacent side <span class="math inline">2</span> representing this value.<br />
Let <span class="math inline">\theta</span> represent the angle between the adjacent side and the hypotenuse. By the Pythagorean theorem. Then <span class="math inline">x = 2 \tan \theta</span>. Then <span class="math inline">\dee x = 2 \sec^2 \theta \dee \theta</span>.<br />
Clearly, <span class="math inline">\int \frac{1}{x^2 \sqrt{x^2 + 4}} \dee x = \int \frac{1}{4 \tan^2 \theta \sqrt{4 \tan^2 \theta + 4}} 2 \sec^2 \theta \dee \theta = \int \frac{1}{4 \tan^2 \theta \sqrt{4 (\tan^2 \theta + 1)}} 2 \sec^2 \theta \dee \theta = \int \frac{1}{4 \tan^2 \theta 2 \sec \theta} 2 \sec^2 \theta \dee \theta = \frac{1}{4} \int \frac{\sec \theta}{\tan^2 \theta} \dee \theta = \frac{1}{4} \int \frac{\cos \theta}{\sin^2 \theta} \dee \theta</span>.<br />
Let <span class="math inline">u = \sin \theta</span>. Then <span class="math inline">\dee x = \frac{1}{\cos \theta} \dee \theta</span>.<br />
So <span class="math inline">\frac{1}{4} \int \frac{\cos \theta}{\sin^2 \theta} \dee \theta = \frac{1}{4} \int \frac{\cos \theta}{u^2} \frac{1}{\cos \theta} \dee u = \frac{1}{4} \int \frac{1}{u^2} \dee u = -\frac{1}{4u} + c = -\frac{1}{4 \sin \theta} + c</span>.<br />
Since <span class="math inline">x = 2 \tan \theta</span>, <span class="math inline">\theta = \arctan \frac{x}{2}</span>.<br />
;wip: rewrite in terms of x using the triangle again So <span class="math inline">\int \frac{1}{x^2 \sqrt{x^2 + 4}} \dee x = -\frac{1}{4} \frac{\sqrt{4 + x^2}}{x} + c</span>.</p>
</blockquote>
<p>This works because <span class="math inline">\cos \theta</span> is always positive or 0 in the domain we are considering.</p>
<p>;wip: improve this day's notes so they actually make sense</p>
<h1 id="section-4">15/1/14</h1>
<p>We do substitution by choosing a <span class="math inline">u = f(x)</span>, then doing <span class="math inline">\frac{\dee u}{\dee x} = f&#39;(x)</span>, so <span class="math inline">\dee u = f&#39;(x) \dee x</span>, so <span class="math inline">\dee x = \frac{1}{f&#39;(x)} \dee x</span>.</p>
<p>Evaluate <span class="math inline">\int \frac{x}{\sqrt{3 - 2x - x^2}}</span>:</p>
<pre><code>          /|
       2 / |
        /  | $u$
       /___|
$\theta$ $\sqrt{4 - u^2}$</code></pre>
<blockquote>
<p>We want to use trigonometric substitution to solve this, but it isn't in the right form.<br />
We want to write <span class="math inline">3 - 2x - x^2</span> in the form of <span class="math inline">a^2 + (x + b)^2</span> (completing the square).<br />
Clearly, <span class="math inline">3 - 2x - x^2 = 3 - (2x + x^2) = 3 - (2x + x^2 + 1) + 1</span> (make the term into a perfect square trinomial by adding <span class="math inline">\frac{b}{2}</span> in a way that cancels out).<br />
So <span class="math inline">3 - 2x - x^2 = 4 - (x + 1)^2</span> and <span class="math inline">\int \frac{x}{\sqrt{3 - 2x - x^2}} = \int \frac{x}{\sqrt{4 - (x + 1)^2}}</span>.<br />
Let <span class="math inline">u = x + 1</span>. Then <span class="math inline">\dee u = \dee x</span>.<br />
We can draw a triangle with the hypotenuse being 2, the opposite side <span class="math inline">u</span>, and adjacent side <span class="math inline">\sqrt{4 - u^2}</span>.<br />
From the triangle, we know that <span class="math inline">u = 2\sin \theta</span> (<span class="math inline">x = 2\sin \theta - 1</span>) and <span class="math inline">\sqrt{4 - u^2} = 2 \cos \theta</span>, so <span class="math inline">\dee u = 2 \cos \theta \dee \theta</span>.<br />
So <span class="math inline">\int \frac{x}{\sqrt{4 - (x + 1)^2}} = \int \frac{2\sin \theta - 1}{2 \cos \theta} 2\cos \theta \dee \theta = \int 2\sin \theta - 1 \dee \theta = -2 \cos \theta - \theta + c</span>.<br />
From the triangle, we can tell that <span class="math inline">\cos \theta = \frac{\sqrt{4 - u^2}}{2}</span>, since the cosine is the adjacent over the hypotenuse.<br />
Clearly, <span class="math inline">\theta = \arcsin \frac{u}{2}</span> So <span class="math inline">\int \frac{x}{\sqrt{3 - 2x - x^2}} = -2 \cos \theta - \theta + c = -2 \frac{\sqrt{4 - (x + 1)^2}}{2} - \arcsin \frac{x + 1}{2} + c</span>.</p>
</blockquote>
<h2 id="partial-fraction-decomposition">Partial Fraction Decomposition</h2>
<p>Consider <span class="math inline">\frac{1}{2} + \frac{1}{3} = \frac{3 + 2}{2 \cdot 3} = \frac{5}{6}</span>.</p>
<p>What if we went the opposite way? We go from <span class="math inline">\frac{5}{6}</span> to <span class="math inline">\frac{A}{2} + \frac{B}{3}</span> by factoring <span class="math inline">6</span>, and then solve for possible solutions for <span class="math inline">3A + 2B = 5</span> and pick <span class="math inline">A = 1, B = 1</span>. Now we have <span class="math inline">\frac{1}{2} + \frac{1}{3}</span>, as required.</p>
<p>This can also be done with polynomials. Using this technique, we can integrate <strong>rational functions of polynomials</strong>.</p>
<p>Consider <span class="math inline">\int \frac{P(x)}{Q(x)} \dee x</span>. We can always factor polynomials into a set of linear factors <span class="math inline">Q(x) = (x + c_1) \cdot \ldots \cdot (x + c_n)</span>.</p>
<p>So <span class="math inline">\int \frac{P(x)}{Q(x)} \dee x = \int \frac{P(x)}{(x + c_1) \cdot \ldots \cdot (x + c_n)} \dee x = \int \frac{A_1}{x + c_1} \dee x + \ldots + \int \frac{A_n}{x + c_n} \dee x</span>.</p>
<p>Now we have a bunch of integrals of constants over <span class="math inline">x</span> with offsets. This is easily integrated into logarithms.</p>
<p>We can solve for <span class="math inline">A_1, \ldots, A_n</span> by cross multiplying: <span class="math inline">\frac{P(x)}{Q(x)} = \frac{A_1 ((x + c_2) \cdot \ldots \cdot (x + c_n)) + \ldots + A_n ((x + c_1) \cdot \ldots \cdot (x + c_{n - 1}))}{(x + c_1) \cdot \ldots \cdot (x + c_n)}</span>. So <span class="math inline">P(x) = A_1 ((x + c_2) \cdot \ldots \cdot (x + c_n)) + \ldots + A_n ((x + c_1) \cdot \ldots \cdot (x + c_{n - 1}))</span>.</p>
<p>For now, assume that the order of <span class="math inline">P</span> is less than that of <span class="math inline">Q</span>.</p>
<p>We can find <span class="math inline">A</span> and <span class="math inline">B</span> using the <strong>cover up method</strong>: if we choose values of <span class="math inline">x = -c_i, 1 \le i \le n</span>, then there is a 0 factor in every term on the right side except the one containing <span class="math inline">A_i</span>. It is then trivial to solve for <span class="math inline">A_i</span>. Repeat this for each <span class="math inline">i</span> and we can find <span class="math inline">A_1, \ldots, A_n</span>.</p>
<p>We can also find <span class="math inline">A</span> and <span class="math inline">B</span> by setting up a system of equations. Clearly, <span class="math inline">x + 1 = A(x + 3) + B(x + 2) = (A + B)x + (3A + 2B)</span>. Since <span class="math inline">(A + B)x = x</span> and <span class="math inline">(3A + 2B) = 1</span>, <span class="math inline">A + B = 1</span> and <span class="math inline">3A + 2B = 1</span>, so we solve for the two linear equations to find <span class="math inline">A</span> and <span class="math inline">B</span>.</p>
<p>Evaluate <span class="math inline">\int \frac{x - 1}{x^2 + 5x + 6} \dee x</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\int \frac{x - 1}{x^2 + 5x + 6} \dee x = \int \frac{x - 1}{(x + 2)(x + 3)} \dee x = \int \frac{A}{x + 2} \dee x + \int \frac{B}{x + 3} \dee x</span> for some <span class="math inline">A</span> and <span class="math inline">B</span>.<br />
Now we need to find <span class="math inline">A</span> and <span class="math inline">B</span>. We do this by solving <span class="math inline">x + 1 = A(x + 3) + B(x + 2)</span>.<br />
Note that <span class="math inline">A</span> and <span class="math inline">B</span> must work for any <span class="math inline">x</span>. We now solve using the cover up method.<br />
Choose <span class="math inline">x = -3</span> (because <span class="math inline">A(x + 3) = 0</span>). Then <span class="math inline">-3 + 1 = A(-3 + 3) + B(-3 + 2) = -2 = -B</span>. Then <span class="math inline">B = 2</span>.<br />
Choose <span class="math inline">x = -2</span> (because <span class="math inline">B(x + 2) = 0</span>). Then <span class="math inline">-2 + 1 = A(-2 + 3) + B(-2 + 2) = -1 = B</span>. Then <span class="math inline">A = -1</span>.<br />
Then <span class="math inline">\int \frac{x - 1}{x^2 + 5x + 6} \dee x = -\int \frac{1}{x + 2} \dee x + \int \frac{2}{x + 3} \dee x = -\ln(x + 2) + 2\ln(x + 3) + c</span>.</p>
</blockquote>
<h1 id="section-5">17/1/14</h1>
<p>Note that partial fraction decomposition only works for factorable polynomials.</p>
<p>What if the numerator has a higher or equal degree than the denominator? We can use long division to make it lower again to apply partial fraction decomposition. When we do long division, we get a normal polynomial as the quotient and a rational function with the degree of the numerator lower than that of the denominator.</p>
<p>Evaluate <span class="math inline">\int \frac{x^3 + 4x^2 + 2x - 5}{x^2 + 5x + 6} \dee x</span>:</p>
<pre><code>                             x - 1
              ____________________
x^2 + 5x + 6 | x^3 + 4x^2 + 2x - 5
               x^3 + 5x^2 + 6x
               -------------------
                     -x^2 - 4x - 5
                     -x^2 - 5x - 6
                     -------------
                             x + 1</code></pre>
<blockquote>
<p>Clearly, <span class="math inline">\int \frac{x^3 + 4x^2 + 2x - 5}{x^2 + 5x + 6} \dee x = \int (x - 1) \dee x + \int \frac{x + 1}{x^2 + 5x + 6} \dee x = \frac{x^2}{2} - x + \int \frac{x + 1}{(x + 2)(x + 3)} \dee x</span>.<br />
;wip</p>
</blockquote>
<p>What if there are repeated factors? We can keep the repeated factors as part of the group to use this technique.</p>
<p>Consider <span class="math inline">\int \frac{x + 1}{(x + 2)^2 (x + 3)}</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\frac{x + 1}{(x + 2)^2 (x + 3)} = \frac{A}{(x + 2)^2 (x + 3)} + \frac{B}{(x + 2) (x + 3)} + \frac{C}{(x + 2)^2}</span> ;wip</p>
</blockquote>
<p>For each factor <span class="math inline">(ax + b)^n</span>, include <span class="math inline">n</span> terms in the form <span class="math inline">\frac{A_1}{(ax + b)} + \ldots + \frac{A_n}{(ax + b)^n}</span>.</p>
<p>What if the denominator is not factorable into linear factors of real numbers (factors contain irreducable quadratics)? For example, <span class="math inline">\frac{x}{x^2 + x + 1}</span>.</p>
<p>We want to avoid imaginary numbers when doing this. Therefore, each irreducable quadratic of the form <span class="math inline">x^2 + x + 1</span>, we get a term of the form <span class="math inline">\frac{A + Bx}{ax^2 + bx + c}</span>.</p>
<p>Consider <span class="math inline">\int \frac{5x + 1}{(x^2 + x + 1)(x - 2)} \dee x</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\int \frac{5x + 1}{(x^2 + x + 1)(x - 2)} \dee x = \int \frac{A + Bx}{x^2 + x + 1} \dee x + \int \frac{C}{x - 2} \dee x</span>.<br />
So <span class="math inline">\int \frac{5x + 1}{(x^2 + x + 1)(x - 2)} \dee x = \int \frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} \dee x + \int \frac{\frac{11}{7}}{x - 2} \dee x</span>.<br />
So <span class="math inline">\int \frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} \dee x + \int \frac{\frac{11}{7}}{x - 2} \dee x = \int \frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} \dee x + \frac{11}{7} \ln (x - 2)</span>.<br />
How do we integrate the first term? We can use a trigonometric substitution to solve this.<br />
Clearly, <span class="math inline">\frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} = \frac{\frac{2}{7} - \frac{11}{7}x}{(x^2 + x + \frac{1}{4}) + 1 - \frac{1}{4}} = \frac{\frac{2}{7} + \frac{11}{7}x}{(x + \frac{1}{2})^2 + \frac{3}{4}}</span>, by completing the square.<br />
Let <span class="math inline">u = x + \frac{1}{2}</span>. Then <span class="math inline">\dee x = \dee u</span>.<br />
Clearly, <span class="math inline">\int \frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} \dee x = \frac{1}{7} \int \frac{2 - 11x}{(x + \frac{1}{2})^2 + \frac{3}{4}} \dee x = \frac{1}{7} \int \frac{-11u + \frac{15}{2}}{u^2 + \frac{3}{4}} \dee x</span>.<br />
Let <span class="math inline">u = \frac{\sqrt{3}}{2} \tan \theta</span>. Then $  x =   x =   x =  4^2 (-11+ ) x =  4^2 (-11) x +  ^2 x ;wip: use substitution with <span class="math inline">s = \frac{\sqrt{3}}{2} \tan \theta</span></p>
</blockquote>
<p>Completing the square: we want the resulting polynomial to have repeated roots. In the quadratic formula, this is when the discriminant <span class="math inline">b^2 - 4ac = 0</span>, so <span class="math inline">c = \frac{b^2}{4a}</span>.</p>
<p>When we have an irreducible quadratic, we always get an <span class="math inline">\arctan</span> and a <span class="math inline">\ln \abs{ax^2 + bx + c}</span>. ;wip: do we always need the arctan? maybe we can subsitutute back to get a knarly expression with sqrt</p>
<h1 id="section-6">20/1/14</h1>
<p>The techniques of integration so far can be summarized as follows:</p>
<ol type="1">
<li>Expression in the numerator of the integrand would be simplified by the derivative of a substitution: use integration by subsitution.</li>
<li>Integrand is a product, integrand would be simplified by differentiating one and integrating another: use integration by parts.</li>
<li>There is a sum of difference of squares (<span class="math inline">\pm a^2 \pm x^2</span>): use trigonometric substitution.</li>
<li>Integrand contains a rational function (quotient of polynomials): use partial fraction decomposition.</li>
</ol>
<p>;wip: do some textbook questions for once</p>
<p>The two other common methods of integration are infinite series expansion and another that uses complex numbers.</p>
<h2 id="volumes-of-solids">Volumes of Solids</h2>
<p>Recall that a single-variable integral can be geometrically interpreted as the area underneath the curve.</p>
<p>In the Riemann integral, that would be represented as <span class="math inline">\int_a^b f(x) \dee x = \lim_{n \to \infty} \sum_{i = 1}^n \Delta x_i f(x_i)</span>. Here, <span class="math inline">\Delta x_i</span> is the base, and <span class="math inline">f(x_i)</span> is the height, and they form a rectangle.</p>
<p>The same idea can be applied to 3D, for the volume under a surface. We want to find the area under <span class="math inline">f(x, y)</span>.</p>
<p>In the Riemann integral, that would be represented as <span class="math inline">\iint f(x, y) \dee x \dee y = \lim_{n \to \infty} \sum_{i = 1}^n \sum_{j = 1}^n \Delta x_i \Delta y_i f(x_i, y_i)</span>. Here, <span class="math inline">\Delta x_i \Delta y_i</span> is the base, and <span class="math inline">f(x_i, y_i)</span>, and they form a rectangle.</p>
<p>In general, the volume of an arbitrary solid requires a multi-variable/multi-dimensional integral (a calculus III topic). However, there are cases where symmetry allows us to use a single variable integral.</p>
<p>Main axes:</p>
<pre><code>   y
   |
   |
   |_____ x
  /
 /
z</code></pre>
<p>Find the volume of a square prism with dimensions <span class="math inline">b \times b \times h</span>:</p>
<blockquote>
<p>The area of the base slice stays the same as we go along the z-axis - as we vary <span class="math inline">h</span>, the slice is still <span class="math inline">b \times b</span>.<br />
So the volume is <span class="math inline">\int_0^h b^2 \dee x = b^2 \int_0^h 1 \dee x = b^2 h</span>.</p>
</blockquote>
<p>The basic idea is that we take the solid, slice the shape along one axis, then integrate the area as a function of the extent along the axis that we sliced along. This works because of the symmetry of some shapes that allows us to avoid considering some dimensions.</p>
<p><span class="math inline">V = \int_a^b A(x) \dee x</span>, where <span class="math inline">V</span> is the volume, <span class="math inline">A(x)</span> is the area of a slice at extent <span class="math inline">x</span> (though other axes can be used too depending on the problem), and <span class="math inline">\dee x</span> is the width of the slice.</p>
<p>Find the area of the cone with base radius 1 unit and height 1 pointing along the x-axis:</p>
<blockquote>
<p>This is the same as the line <span class="math inline">y = 1 - x</span> rotated about the x-axis.<br />
The area of any slice of the cone along the x-axis is <span class="math inline">A(x) = \pi (1 - x)^2</span>, because the slice is a circle.<br />
The thickness of this slice is <span class="math inline">\dee x</span>, and the cone is defined from <span class="math inline">x = 0</span> to <span class="math inline">x = 1</span>.<br />
So the volume of the cone is <span class="math inline">\int_0^1 \pi (1 - x)^2 \dee x = \pi \int_0^1 (1 - 2x + x^2) \dee x = \frac{\pi}{3}</span>.</p>
</blockquote>
<p>We can generalize this to any function rotated about a line. The resulting solids are called <strong>solids of rotation</strong>.</p>
<p>The reason this works is because the z-axis is basically redundant information that is already expressed in the y-axis.</p>
<p>Find the volume of the solid represented by rotating <span class="math inline">f(x)</span> about the x-axis:</p>
<blockquote>
<p>The area of each slice at each extent along the x-axis is the area of a circle with the radius <span class="math inline">f(x)</span>.<br />
The area function is <span class="math inline">A(x) = \pi f(x)^2</span>.<br />
So the volume is <span class="math inline">\int_a^b A(x) \dee x = \pi \int_a^b f(x)^2 \dee x</span>.</p>
</blockquote>
<h1 id="section-7">22/1/14</h1>
<p>The rotation method works whenever we can find the area function for a given slice along a certain axis.</p>
<p>Here, <span class="math inline">\Delta V = A(x) \Delta x</span>, and then we add up all these tiny volumes to get the total volume.</p>
<p>This method is called the <strong>method of disks</strong>, because we are integrating the volume of a lot of small disks along the axis of rotation.</p>
<p>There is another way to approximate the area and have it converge into an exact value. We can estimate the volume of solids of rotation by integrating the volume of a lot of nested cylinders lying along the axis of rotation - this is the <strong>method of shells</strong>.</p>
<p>Consider a hollow cylinder of thickness <span class="math inline">\dee x</span> with inner radius <span class="math inline">x</span> and height <span class="math inline">h(x)</span>. If we cut it and unroll it, then it becomes very close to a cuboid of dimensions <span class="math inline">2\pi x</span> by <span class="math inline">h(x)</span> by <span class="math inline">\dee x</span>. In other words, we assume the inner circumference is almost the same as the outer circumference, since <span class="math inline">\dee x</span> is so small.</p>
<p>So the enclosed volume of the cylinder is <span class="math inline">2\pi x h(x) \dee x</span>.</p>
<p>How do we use these shells to find the volume of a solid? If we look at the cross section of our shape, we can approximate the area of this cross section using rectangles that have a fixed width <span class="math inline">\dee x</span> perpendicular to the axis of rotation, and length <span class="math inline">h(x)</span> along the axis of rotation.</p>
<p>Then the volume of the solid is the sum of the volume of all the nested cylinders: <span class="math inline">\int_a^b 2 \pi x h(x) \dee x</span>.</p>
<p>Consider a cone extending along the x-axis represented by the equation <span class="math inline">y = 1 - x</span> from 0 to 1 rotated about the x-axis:</p>
<blockquote>
<p>We want the height of the cylinder at each point along the y-axis, an axis perpendicular to the axis of rotation.<br />
The height is <span class="math inline">x = 1 - y</span>. So the volume of the shell at any extent along the radius is <span class="math inline">2 \pi y(1 - y) \dee x</span>.<br />
So the volume is <span class="math inline">\int_0^1 2 \pi y(1 - y) \dee y</span>. Note that we only integrate from the axis of rotation to the radius, not the diameter, because the cylinders go around over to the other side.<br />
So the volume is <span class="math inline">\frac{\pi}{3}</span>.</p>
</blockquote>
<p>Finding the height of the shell is not always the same as finding the inverse. Consider the bowl-like shape formed by rotating <span class="math inline">y = \sqrt{x}</span> from 0 to 0 about the y-axis:</p>
<blockquote>
<p>We want the height of the bowl at each point along the x-axis, an axis perpendicular to the axis of rotation.<br />
The height is <span class="math inline">y = 1 - x^2</span>, since the height of each cylinder is decreasing as we move outwards.<br />
So the volume is <span class="math inline">\int_0^1 2 \pi x(1 - x^2) \dee x = \frac{\pi}{2}</span>.</p>
</blockquote>
<p>Note that this is the same as if we used <span class="math inline">x = y^2</span> (the inverse of the function). There are two possibilities for the cylinder height: either the inverse of the function, if the shape gets thinner as we move along the axis of rotation, or the maximum height minus the inverse, if the shape gets thicker as we move along the axis of rotation. Here, since the <span class="math inline">\sqrt{x}</span> shape gets thicker, we used <span class="math inline">1 - x^2</span>.</p>
<p>The method of shells works best when we know the height from the axis perpendicular to the axis of rotation, and the method of disks works when we can find the area of each slice along the axis of rotation.</p>
<h1 id="section-8">24/1/14</h1>
<p>The method of shells and the method of disks both have cases where they work better than the other. The method of disks works best for functions that extend parallel to the axis of rotation, while the method of shells, for functions that extend perpendicular to the axis of rotation.</p>
<p>The method of disks uses the formula <span class="math inline">\int_a^b A(x) \dee x</span>, where <span class="math inline">a, b</span> are the extents along the axis of rotation.</p>
<p>The method of shells uses the formula <span class="math inline">\int_a^b h(x) 2\pi x \dee x</span>, where <span class="math inline">a, b</span> are the extents perpendicular to the axis of rotation.</p>
<p>Consider <span class="math inline">y = 2x^2 - x^3 = x^2(2 - x)</span> from 0 to 2 rotated about the y-axis:</p>
<blockquote>
<p>This solid looks like the top half of a donut.<br />
The method of disks is difficult to use here, because we would need disks with holes in them. We will use the method of shells.<br />
The height of each of our cylinders is <span class="math inline">h(x) = 2x^2 - x^3</span>.<br />
The volume of each shell is <span class="math inline">\Delta V = h(x) 2\pi x \dee x = 4\pi x^3 \dee x - 2\pi x^4 \dee x</span>.<br />
So the volume of the solid is <span class="math inline">4\pi \int_0^2 x^3 \dee x - 2\pi \int_0^2 x^4 \dee x = 4\pi \evalat{\frac{x^4}{4}}_0^2 - 2\pi \evalat{\frac{x^5}{5}}_0^2 = 4\pi \frac{2^4}{4} - 2\pi \frac{2^5}{5} = \frac{16\pi}{5}</span>.</p>
</blockquote>
<p>A variation on the method is disks is the <strong>method of washers</strong>. Here, we have disks with holes in them for whatever reason, and our area, rather than simply being the area of a circle, is the area of the circle minus the area of the hole in the middle. Make sure to use <span class="math inline">\pi \int (r_o^2 - r_i^2) \dee x</span> rather than <span class="math inline">\pi \int (r_o - r_i)^2 \dee x</span>, where <span class="math inline">r_o</span> is the outer radius and <span class="math inline">r_i</span> is the inner radius.</p>
<p>For example, what is the volume enclosed by rotating the area between <span class="math inline">y = \sqrt{x}</span> and <span class="math inline">y = x</span> about the x-axis? We could use the disk method, except instead of finding the area of a disk, we find the area of a disk with a hole in it, a washer. However, in this case it would be easier to do it with the method of shells.</p>
<h1 id="section-9">27/1/14</h1>
<h2 id="improper-integrals">Improper Integrals</h2>
<p>An integral is improper if some part of it goes to <span class="math inline">\pm \infty</span> - either the integrand or the domain of integration (limits of integration).</p>
<p>The way we deal with this is to take limits of the infinite values instead of using these infinite values.</p>
<p>Improper integrals work when the domain is infinite (<span class="math inline">\int_0^\infty f(x) \dee x</span>), when the integrand is infinite at one of the endpoints (<span class="math inline">\int_0^1 \frac{1}{x}</span>), or when the integrand is infinite within the domain (<span class="math inline">\int_{-1}^1 \frac{1}{x} \dee x</span>)</p>
<p>For example, <span class="math inline">\int_a^\infty f(x) \dee x = \lim_{T \to \infty} \int_a^T f(x) \dee x</span>.</p>
<p>For example, <span class="math inline">\int_0^\infty e^{-x} \dee x = \lim_{T \to \infty} \int_0^T e^{-x} \dee x = \lim_{T \to \infty} \evalat{-e^{-x}}_0^T = \lim_{T \to \infty} (-e^{-T}) - (-e^{-0}) = 0 + 1 = 1</span>.</p>
<p>Prove that the volume obtained by rotating <span class="math inline">y = \frac{1}{x}</span> about the x-axis for <span class="math inline">x \in [1, \infty)</span> is finite:</p>
<blockquote>
<p>The volume is <span class="math inline">\int_1^\infty \pi \frac{1}{x^2} \dee x = \pi \lim_{T \to \infty} \evalat{-\frac{1}{x}}_1^T = \pi</span>, found via the method of disks. Clearly, the volume is finite.</p>
</blockquote>
<p>Sometimes, the integrand itself will diverge. Consider <span class="math inline">\int_0^1 \ln x \dee x</span>:</p>
<blockquote>
<p><span class="math inline">\ln 0 = -\infty</span>, and we cannot evaluate the antiderivative at this point.<br />
Instead, we write it as <span class="math inline">\lim_{\epsilon \to 0} \int_\epsilon^1 \ln x \dee x = \lim_{\epsilon \to 0} \evalat{x \ln x - x}_\epsilon^1 = 0 - 1 - (\lim_{\epsilon \to 0} \epsilon \ln \epsilon - \lim_{\epsilon \to 0} \epsilon) = 0 - 1 - (0 - 0) = -1</span>.</p>
</blockquote>
<p>Also, the integrand might diverge somewhere within the domain of integration. This is not always immediately obvious and must always be considered when doing integrals.</p>
<p>Consider <span class="math inline">\int_{-1}^1 \frac{1}{\sqrt{\abs{x}}} \dee x</span>:</p>
<blockquote>
<p>There is a vertical asymptote at <span class="math inline">x = 0</span>. This makes it so that we can't directly use the fundemental theorem of calculus to evaluate the integral.<br />
We can instead split the integral at the middle, and since it is an even function, we can combine the two integrals: <span class="math inline">2\int_0^1 \frac{1}{\sqrt{x}} \dee x</span>.<br />
There is an asymptote, so the integral is an improper one: <span class="math inline">2\int_0^1 \frac{1}{\sqrt{x}} \dee x = 2 \lim_{T \to 0} \int_T^1 \frac{1}{\sqrt{x}} \dee x = 2 (2 \cdot 1^\frac{1}{2} - 2\lim_{T \to 0} T^\frac{1}{2}) = 4</span>.</p>
</blockquote>
<p>Consider <span class="math inline">\int_{-1}^1 \frac{1}{2\sqrt{x}} \dee x</span>: ;wip: what was the actual example here?</p>
<blockquote>
<p>We might do <span class="math inline">\int_{-1}^1 \frac{1}{2\sqrt{x}} \dee x = \evalat{-\sqrt{\abs{x}}}_{-1}^1 = -2</span>.<br />
However, the integral <strong>does not exist</strong>. We need to be careful because the result looks just fine, and does not indicate that an error occurred.<br />
The integral does not make any sense because the integrand diverges towards <span class="math inline">\infty</span> at <span class="math inline">x = 0</span>.</p>
</blockquote>
<p>The idea behind this is that we need to figure out if an improper integral exists even without integrating it first.</p>
<p>If a function <strong>converges</strong>, that means it goes to a finite value. The opposite is if it <strong>diverges</strong>, when it goes to <span class="math inline">\pm \infty</span> or does not exist.</p>
<p>In other words, convergence means the result is a number, and divergence means the result is not a number.</p>
<p>If an improper integral converges, then the value we get by evaluating its antiderivatives at the endpoints is the correct value of the integral. However, if it diverges, then the answer could be different. We always need to check for divergence in order to catch these cases.</p>
<h3 id="comparison-theorem">Comparison Theorem</h3>
<p>Given functions <span class="math inline">f(x), g(x)</span> such that <span class="math inline">f(x) \ge g(x) \ge 0</span> for <span class="math inline">x \ge a</span>, if <span class="math inline">\int_a^b f(x) \dee x</span> converges, then <span class="math inline">\int_a^b g(x) \dee x</span> also converges.</p>
<p>The contrapositive is also useful in that if <span class="math inline">\int_a^b g(x) \dee x</span> diverges, then <span class="math inline">\int_a^b f(x) \dee x</span> also diverges.</p>
<p>Prove that <span class="math inline">\int_1^\infty \frac{1}{x^P} \dee x</span> converges if and only if <span class="math inline">P &gt; 1</span></p>
<blockquote>
<p>Clearly, if <span class="math inline">P = 1</span>, <span class="math inline">\int_1^\infty \frac{1}{x^P} \dee x = \evalat{\ln x}_1^\infty</span>, which is <span class="math inline">\infty</span>, so the integral diverges.<br />
Clearly, <span class="math inline">\int_1^\infty \frac{1}{x^P} \dee x = \evalat{\frac{x^{1 - P}}{1 - P}}_1^\infty = \frac{\infty^{1 - P}}{1 - P} - \frac{1}{1 - P}</span> if <span class="math inline">P \ne 1</span>.<br />
Clearly, if <span class="math inline">P &lt; 1</span>, <span class="math inline">\infty^{1 - P} = \infty</span>, so the integral diverges.<br />
Clearly, if <span class="math inline">P &gt; 1</span>, <span class="math inline">\infty^{1 - P} = 0</span>, so the integral converges.<br />
So the integral converges to <span class="math inline">\frac{1}{P - 1}</span> for <span class="math inline">P &gt; 1</span>.</p>
</blockquote>
<p>Interestingly, <span class="math inline">e^{-x^2}</span> doesn't have an antiderivative. Figure out if <span class="math inline">\int_0^\infty e^{-x^2} \dee x</span> converges or diverges:</p>
<blockquote>
<p>Clearly, <span class="math inline">0 \le e^{-x^2} \le e^{-x}</span> for <span class="math inline">x \ge 1</span>.<br />
Since <span class="math inline">\int_1^\infty e^{-x} \dee x</span> converges, <span class="math inline">\int_1^\infty e^{-x^2} \dee x</span> converges, by the comparison theorem.<br />
Clearly, <span class="math inline">\int_0^\infty e^{-x^2} \dee x = \int_0^1 e^{-x^2} \dee x + \int_1^\infty e^{-x^2} \dee x</span>.<br />
Clearly, <span class="math inline">e^{-x^2}</span> does not diverge for all <span class="math inline">x \in [0, 1]</span>. So <span class="math inline">\int_0^1 e^{-x^2} \dee x</span> converges.<br />
Since <span class="math inline">\int_0^1 e^{-x^2} \dee x</span> and <span class="math inline">\int_1^\infty e^{-x^2} \dee x</span> converge, <span class="math inline">\int_0^\infty e^{-x^2} \dee x</span> converges.</p>
</blockquote>
<h1 id="section-10">29/1/14</h1>
<p>Consider <span class="math inline">\int_1^\infty \frac{1 + e^{-x}}{x} \dee x</span>:</p>
<blockquote>
<p>Clearly, the function is well behaved for all <span class="math inline">x \in [1, \infty]</span>.<br />
So we do not need to worry about the integrand diverging.<br />
Clearly, <span class="math inline">\frac{1 + e^{-x}}{x} \le \frac{2}{x}</span>.<br />
Clearly, <span class="math inline">\frac{2}{x}</span> diverges.<br />
However, we can't say anything about the original function using the comparison theorem, since it could still either converge or diverge.<br />
Instead, we look for divergence. Clearly, <span class="math inline">\frac{1}{x} \le \frac{1 + e^{-x}}{x}</span>.<br />
Since <span class="math inline">\int_1^\infty \frac{1}{x} \dee x</span> diverges, <span class="math inline">\int_1^\infty \frac{1 + e^{-x}}{x} \dee x</span> also diverges.</p>
</blockquote>
<h2 id="applications-of-integration">Applications of Integration</h2>
<p>Many physical phenomena can be represented by <strong>differential equations</strong> - equations that include derivatives.</p>
<p>This comes about usually through empirical evidence/oberservation, and some by conservation principles.</p>
<h3 id="cooling">Cooling</h3>
<p>For example, Newton's Law of Cooling was discovered by Newton's measurements of hot materials in cooler surroundings.</p>
<p>The law states that the change in temperature is linearly propertional to the temperature difference with the surroundings.</p>
<p>In other words, <span class="math inline">\frac{\dee}{\dee x} T_h = -k(T_h - T_r)</span>, where <span class="math inline">T_h</span> is the temperature of the hot thing, <span class="math inline">T_r</span> is the surrounding temperature, and <span class="math inline">k</span> is the cooling coefficient.</p>
<p>Note that <span class="math inline">k</span> is non-negative and we use <span class="math inline">-k</span> because hot things cool. This cooling coefficient is influenced by the material and shape of the object.</p>
<p>From this we can tell that the object stops cooling when <span class="math inline">T_h = T_r</span>, so <span class="math inline">\frac{\dee}{\dee x} T_h = 0</span>.</p>
<p>Values of <span class="math inline">T</span> for which <span class="math inline">\frac{\dee T_h}{\dee x} = 0</span> are called <strong>equilibria</strong>.</p>
<h3 id="conservation">Conservation</h3>
<p>Most differential equations in science and engineering come from <strong>conservation principles</strong> - principles that apply universally and constrain what can happen. For example, conservation of mass/energy/charge/momentum.</p>
<p>Conservation principles are easy to represent in mathematics, though the models can be pretty elaborate. Basically, what they state is that the rate of the change of something is the rate of change of something increasing minus the rate of stuff decreasing.</p>
<p>For example, the rate of change of people of the people in the room is the rate of change of people entering minus the rate of change of people leaving.</p>
<p>The rate of something increasing is called a <strong>source</strong>. The rate of something decreasing is called a <strong>sink</strong>.</p>
<p>For example, consider a skydiver immediately after their parachute opens:</p>
<blockquote>
<p>Clearly, <span class="math inline">m\frac{\dee \vec{v}}{\dee x} = \sum \vec{F} = m \vec{g} - \vec{F}_d</span>, where <span class="math inline">\vec{F}_d</span> is the drag force.<br />
We can calculate the drag force in a lab independent of everything else, and not have to worry about the other things like the height or gravity.<br />
Typically, <span class="math inline">\vec{F}_d = k\vec{v}</span> for some constant <span class="math inline">k</span>.<br />
So <span class="math inline">\frac{\dee \vec{v}}{\dee x} = \vec{g} - \frac{k}{m} \vec{v}</span>.</p>
</blockquote>
<h1 id="section-11">31/1/14</h1>
<p>An example of a mathematical representation of conservation principles is a mixing problem.</p>
<p>A tank holds 80L of water at time <span class="math inline">t = 0</span>. A salt solution of 0.25 kg/L flows into the tank at 8L/min. Liquid drains at a rate of 12L/min from the tank. Find a differential equation for the mass of salt <span class="math inline">x(t)</span> in kg for <span class="math inline">t &gt; 0</span>, where <span class="math inline">t</span> is measures in seconds:</p>
<blockquote>
<p>We assume the salt solution instantly mixes with the water.<br />
We want to find <span class="math inline">\frac{\dee}{\dee t} x(t)</span>, which is <span class="math inline">\text{source} - \text{sink}</span>.<br />
The source is <span class="math inline">\text{salt concentration} \cdot \text{inflow rate} = 0.25 \text{kg/L} \cdot 8 \text{L/min} = 2 \text{kg/min}</span>.<br />
Clearly, <span class="math inline">\frac{\dee}{\dee x} \text{liquid level} = \text{inflow rate} - \text{outflow rate} = 8 \text{L/min} - 12 \text{L/min} = -4 \text{L/min}</span>.<br />
So the liquid level is <span class="math inline">80 + \int \frac{\dee}{\dee x} \text{liquid level} \dee t = 80 - 4t</span>.<br />
Clearly, <span class="math inline">\text{salt concentration} = \frac{\text{mass of salt}}{\text{volume of tank}} = \frac{x(t)}{80 - 4t}</span>.<br />
The sink is <span class="math inline">\text{salt concentration} \cdot \text{outflow rate} = \frac{x(t)}{80 - 4t} \cdot 12 \text{kg/L} = \frac{3x(t)}{20 - t}</span>.<br />
So <span class="math inline">\frac{\dee}{\dee t} x(t) = 2 - \frac{3x(t)}{20 - t}</span>.<br />
Note that the tank is empty when <span class="math inline">t = 20</span>, when the outflow rate is undefined.</p>
</blockquote>
<p>There are many things we can say about the function even without solving it. These are called <strong>qualitiative analyses</strong>.</p>
<p>Suppose we have <span class="math inline">\frac{\dee y}{\dee x} = f(x, y)</span>. Note that the left side is equal to the slope of the tangent line, and the right side is an expression for the slope of the tangent line for any point <span class="math inline">(x, y)</span>.</p>
<p>Basically, every point on the Cartesian plane now has an associated slope, and we can represent this roughly with arrows on the graph representing the trend in the slopes.</p>
<p>These arrows/contours are called streamlines.</p>
<p>Think of this as a stream with currents and eddies. Every possible solution is a possible path a floating object will take if dropped at a particular place in the stream and allowed to bob along with the stream. The solutions are we get if we start at a possible point and draw a curve that has the slope of the tangent always equal to the value at the flow field at the point under the curve.</p>
<p>We can also think of them as a topographical map of some terrain. If we drop a ball along a point on the map, it will trace out a certain line. If we drop it slightly off to one side, it may take a different path, which could be similar, or completely different. The slope of the tangent represents the slope of the hill at a particular point.</p>
<p>The set of all possible solutions is therefore a family of functions that look like a map of water currents.</p>
<p>An <strong>equilibrium</strong> is a place where <span class="math inline">\frac{\dee y}{\dee x} = f(x) = 0</span>. Because the slope of the tangent is 0, it must be 0 for all <span class="math inline">x</span> values. There are <strong>stable</strong> and <strong>unstable</strong> equilibria.</p>
<p>Stable equilibria are those where values that are close to them get closer to them, like dropping a ball on the side of a valley and having it eventually roll to the bottom of the valley.</p>
<p>Unstable equilibria are those where values that are close to them get farther away from them, like dropping a ball at the peak of a mountain and having it roll away from the peak. Only values that are exactly on the unstable equilibrium will stay there.</p>
<p>Consider <span class="math inline">\frac{\dee y}{\dee x} = 1 - y^2</span>:</p>
<blockquote>
<p>The slope of the tangent line is <span class="math inline">\begin{cases} \text{negative} &amp;\text{if } y &lt; -1 \\ \text{positive} &amp;\text{if } -1 &lt; y &lt; 1 \\ \text{negative} &amp;\text{if } y &gt; 1 \end{cases}</span>.<br />
We can visualize this as a flow field with three distinct sections.<br />
Note that if we start at <span class="math inline">y = -1, 1</span>, we stay at that same value regardless of the value of <span class="math inline">x</span>. This is called an equilibrium, since the value isn't changing.<br />
Note that if we start at any <span class="math inline">y &gt; -1</span>, <span class="math inline">y \to 1</span> as <span class="math inline">x \to \infty</span> (convergent), and if we start at any <span class="math inline">y &lt; -1</span>, <span class="math inline">y \to -\infty</span> as <span class="math inline">x \to \infty</span> (divergent).</p>
</blockquote>
<h1 id="section-12">3/2/14</h1>
<p>Differential equations of the form <span class="math inline">\frac{\dee y}{\dee x} = f(y)</span> are called autonomous differential equations. Note that they do not depend on the value of <span class="math inline">x</span>.</p>
<p>The equilibria of an autonomous differential equation are those <span class="math inline">y</span> values for which <span class="math inline">\frac{\dee y}{\dee x} = f(y) = 0</span>.</p>
<p>An equilibrium <span class="math inline">y = k</span> is stable if and only if <span class="math inline">f&#39;(k) &lt; 0</span> - if the change in the slope at the location is negative. Otherwise, it is unstable. This is because a negative value for the derivative means a negative feedback loop, which makes the function settle toward the equilibrium. ;wip: what? why? shouldn't the derivative be 0 at <span class="math inline">y = k</span>?</p>
<h2 id="solving-differential-equations">Solving Differential Equations</h2>
<h3 id="estimation">Estimation</h3>
<p>Consider <span class="math inline">\frac{\dee y}{\dee x} = y - x</span>, with <span class="math inline">y(0) = 2</span>.</p>
<p>This is a differential equation of the form <span class="math inline">\frac{\dee y}{\dee x} = f(x, y)</span></p>
<p>We can use the differential equation to estimate a certain solution, much like a Riemann sum.</p>
<p>First, we pick a starting point so we have a single solution to the differential equation, a member of the family of solutions. This is a curve on the Cartesian plane.</p>
<p>This starting point is called the <strong>initial condition</strong>. The initial condition often takes the form of <span class="math inline">y(x) = y(0) = 2</span> - the <span class="math inline">y</span>-value at <span class="math inline">x = 0</span> is 2 for this solution.</p>
<p>First, we break up the domain into pieces, by choosing value for <span class="math inline">x_1, \ldots, x_n</span>.</p>
<p>Then, we use <span class="math inline">\frac{\dee y}{\dee x} = f(x, y)</span> to estimate the slope of the tangent at any given <span class="math inline">x</span> value.</p>
<p>Then, we observe that <span class="math inline">\frac{\dee y}{\dee x} = f(x_{n - 1}, y_{n - 1}) \approx \frac{y_n - y_{n - 1}}{x_n - x_{n - 1}}</span> - the slope of the tangent is close to the slope of the secant.</p>
<p>So <span class="math inline">y_n(x) \approx y_{n - 1} + (x_n - x_{n - 1})f(x_{n - 1}, y_{n - 1})</span>. This is written in update form, so we can now use a table of values to calculate it.</p>
<p>Let <span class="math inline">\Delta x = x_n - x_{n - 1}</span>. Then <span class="math inline">y_n(x) \approx y_{n - 1} + f(x_{n - 1}, y_{n - 1}) \Delta x</span>.</p>
<p>We can also write this as <span class="math inline">y_{n + 1}(x) \approx y_n + f(x_n, y_n) \Delta x</span> where <span class="math inline">\Delta x = x_{n + 1} - x_n</span>.</p>
<p>Now we can write <span class="math inline">\frac{\dee y}{\dee x} = y - x</span> as <span class="math inline">y_n(x) \approx y_{n - 1} + (x_n - x_{n - 1})(x_{n - 1} - y_{n - 1})</span>.</p>
<p>We can actually approximate this function by using a table of values. Since <span class="math inline">y(0) = 2</span>, <span class="math inline">y_0 = 2</span>:</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">n</span></th>
<th><span class="math inline">x_n</span></th>
<th><span class="math inline">y_n</span></th>
<th><span class="math inline">f(x_n, y_n) \Delta x</span></th>
<th><span class="math inline">y_{n + 1} \approx y_n + f(x_n, y_n) \delta x</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.0</td>
<td>2</td>
<td><span class="math inline">(2 - 0.0)0.1 = 0.20</span></td>
<td><span class="math inline">2.2 \approx 2 + 0.2</span></td>
</tr>
<tr class="even">
<td>1</td>
<td>0.1</td>
<td>2.2</td>
<td><span class="math inline">(2 - 0.1)0.2 = 0.38</span></td>
<td><span class="math inline">2.58 \approx 2.2 + 0.38</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.2</td>
<td>2.58</td>
<td><span class="math inline">(2 - 0.2)0.3 = 0.54</span></td>
<td><span class="math inline">3.12 \approx 2.58 + 0.54</span></td>
</tr>
<tr class="even">
<td>3</td>
<td>0.3</td>
<td>3.12</td>
<td><span class="math inline">(2 - 0.3)0.4 = 0.68</span></td>
<td><span class="math inline">\ldots</span></td>
</tr>
</tbody>
</table>
<p>Now we can a table of values for the equation. We can plot this on a graph to approximate the curve.</p>
<p>The actual solution can also be found, though not through these techniques. The general solution is <span class="math inline">y = 1 + x + c^x, c \in \mb{R}</span>.</p>
<p>This is called <strong>Euler's method</strong>. It is a method for numerically solving differential equations.</p>
<h3 id="integration">Integration</h3>
<p>If we want exact solutions, we have to integrate. This is not always possible, but is in certain cases.</p>
<p><strong>Separable equations</strong> are one variety of them. They are equations of the form <span class="math inline">\frac{\dee y}{\dee x} = A(x) B(y)</span>.</p>
<p>Note that <span class="math inline">y</span> is also a function of <span class="math inline">x</span>, so <span class="math inline">B(y)</span> is another function of <span class="math inline">x</span>. We write <span class="math inline">y = y(x)</span>.</p>
<p>Clearly, <span class="math inline">\frac{\dee y}{\dee x} = A(x) B(y)</span> is the same as <span class="math inline">\frac{1}{B(y)} \frac{\dee y}{\dee x} = A(x)</span>.</p>
<p>If we integrate both sides, we get <span class="math inline">\int \frac{1}{B(y)} \frac{\dee y}{\dee x} \dee x = \int A(x) \dee x</span>.</p>
<p>Now we can &quot;cancel <span class="math inline">\dee x</span>&quot;. Let <span class="math inline">u = y(x)</span>. Then <span class="math inline">\dee u = \frac{\dee u}{\dee x} \dee x</span> and <span class="math inline">\dee x = \frac{1}{\frac{\dee u}{\dee x}} \dee u = \frac{1}{\frac{\dee y}{\dee x}} \dee u</span>. This is basically the definition of the substitution rule for integrals.</p>
<p>So <span class="math inline">\int \frac{1}{B(y)} \frac{\dee y}{\dee x} \dee x = \int \frac{1}{B(u)} \frac{\dee y}{\dee x} \frac{1}{\frac{\dee y}{\dee x}} \dee u = \int \frac{1}{B(u)} \dee u = \int \frac{1}{B(y)} \dee y</span>.</p>
<p>So <span class="math inline">\int \frac{1}{B(y)} \dee y = \int A(x) \dee x</span>.</p>
<p>We can also think of this as multiplying both sides of <span class="math inline">\frac{1}{B(y)} \frac{\dee y}{\dee x} = A(x)</span> by <span class="math inline">\dee x</span> and integrating both sides.</p>
<p>Solve <span class="math inline">\frac{\dee y}{\dee x} = \frac{x}{y}</span> for <span class="math inline">y(0) = -3</span>:</p>
<blockquote>
<p>Clearly, this is equivalent to <span class="math inline">y \frac{\dee y}{\dee x} = x</span>, or <span class="math inline">y \dee y = x \dee x</span>, or <span class="math inline">\int y \dee y = \int x \dee x</span>.<br />
Integrating both sides, we get <span class="math inline">\frac{y^2}{2} = \frac{x^2}{2} + c</span>.<br />
We want to find the value of <span class="math inline">c</span>. Since <span class="math inline">y(0) = -3</span>, <span class="math inline">\frac{(-3)^2}{2} = \frac{0^2}{2} + c</span> and <span class="math inline">c = \frac{9}{2}</span>.<br />
So the solution is <span class="math inline">y^2 = 2x^2 + 2 \cdot \frac{9}{2} = 2x^2 + 9</span>.</p>
</blockquote>
<p>;wip: try <span class="math inline">\frac{\dee}{\dee x} 2^y \sin^2 x</span> and <span class="math inline">\sqrt{x \frac{\dee x}{\dee t}} = \frac{1}{1 + t}</span></p>
<h1 id="section-13">5/2/14</h1>
<p><strong>Constant solutions</strong> are another name for equilibria. They are simply where <span class="math inline">\frac{\dee y}{\dee x} = 0</span> for <span class="math inline">\frac{\dee y}{\dee x} = f(y)</span>.</p>
<p>Solve <span class="math inline">\sqrt{x \frac{\dee x}{\dee t}} = \frac{1}{1 + t}</span> for <span class="math inline">x(t) = x(0) = 0, t \ge 0</span>:</p>
<blockquote>
<p><span class="math display">\displaystyle 
\begin{aligned}
\sqrt{x \frac{\dee x}{\dee t}} &amp;= \frac{1}{1 + t} \\
x \frac{\dee x}{\dee t} &amp;= \frac{1}{(1 + t)^2} \\
x \dee x &amp;= \frac{1}{(1 + t)^2} \dee t \\
\int x \dee x &amp;= \int \frac{1}{(1 + t)^2} \dee t \\
\frac{x^2}{2} &amp;= -\frac{1}{1 + t} + c \\
t &amp;= 0; x(0) = 0 \\
\frac{0^2}{2} &amp;= -\frac{1}{1 + 0} + c \\
c &amp;= 1 \\
\frac{x^2}{2} &amp;= -\frac{1}{1 + t} + 1 \\
x &amp;= \sqrt{2 - \frac{2}{1 + t}} = \sqrt{\frac{2(1 + t) - 2}{1 + t}} = \sqrt{\frac{2t}{1 + t}}
\end{aligned}
</span></p>
</blockquote>
<p>First we rearrange until there is only one variable on each side, then we integrate, and finally, fix the constant of integration <span class="math inline">c</span> by solving for it with the given values for the axis variables.</p>
<p>Solve <span class="math inline">\frac{\dee T}{\dee t} = -k(T - T_{ambient})</span> - Newton's law of cooling:</p>
<blockquote>
<p><span class="math display">\displaystyle 
\begin{aligned}
\frac{\dee T}{\dee t} &amp;= -k(T - T_{ambient}) \\
\frac{1}{T - T_{ambient}} \dee T &amp;= -k \dee t \\
\int \frac{1}{T - T_{ambient}} \dee T &amp;= -k \int 1 \dee t \\
\ln \abs{T - T_{ambient}} &amp;= -kt + c \\
e^{\ln \abs{T - T_{ambient}}} &amp;= e^{-kt + c} \\
\abs{T - T_{ambient}} &amp;= e^{-kt}e^c \\
T - T_{ambient} &amp;= \pm e^ce^{-kt}
\end{aligned}
</span> Let <span class="math inline">A = \pm e^c</span>. Then <span class="math inline">T - T_{ambient} = Ae^{-kt}</span>.<br />
Note that at <span class="math inline">t = 0</span>, <span class="math inline">T = T_0</span> for some fixed <span class="math inline">T_0</span>.<br />
So <span class="math inline">T_0 - T_{ambient} = Ae^{-k0}</span> and <span class="math inline">T_0 - T_{ambient} = A</span>.<br />
So <span class="math inline">T = T_{ambient} + (T_0 - T_{ambient})e^{-kt}</span>.</p>
</blockquote>
<p>Suppose we have a population of <span class="math inline">n</span> individuals. The simplest population model is <span class="math inline">\frac{\dee n}{\dee t} = kn</span> for some <span class="math inline">k \ge 0</span>. Solve for <span class="math inline">n</span>:</p>
<blockquote>
<p><span class="math display">\displaystyle 
\begin{aligned}
\frac{\dee n}{n} &amp;= k \dee t \\
\int \frac{\dee n}{n} &amp;= k \int \dee t \\
\ln \abs{n} &amp;= kt + c \\
n &amp;= \pm e^ce^{kt} \\
A = \pm e^c; n &amp;= Ae^{kt}
\end{aligned}
</span> Note that at <span class="math inline">t = 0</span>, <span class="math inline">n = n_0</span> for some constant <span class="math inline">n_0</span> - the starting population.<br />
So <span class="math inline">n_0 = Ae^{k0}</span> and <span class="math inline">A = n_0</span>.<br />
So <span class="math inline">n = n_0e^{kt}</span>.</p>
</blockquote>
<p>A simple variation on this population growth model is <strong>logistic growth</strong>, which also models resource exhaustion: <span class="math inline">\frac{\dee N}{\dee t} = rN\left(1 - \frac{N}{k}\right)</span>. Note that there are two equalibria - <span class="math inline">N = 0</span> and <span class="math inline">N = k</span>. <span class="math inline">k</span> is a constant called the <strong>carrying capacity</strong>.</p>
<p>For <span class="math inline">\frac{n}{k} \ll 1</span> (much less than), logistic growth behaves like exponential growth.</p>
<p>The flow field looks like arrows pointing right toward <span class="math inline">N(t) = k</span> starting from <span class="math inline">N(t) = 0</span>. Therefore, the population always tends toward <span class="math inline">k</span> in this model.</p>
<h1 id="section-14">7/2/14</h1>
<p>The main idea is that there is a lot more to the equations than just the solutions. The flow field is useful for discovering how the equation behaves.</p>
<p>Even when we solve the equation, it does not tell us much about how the function works intuitively.</p>
<p>Solve <span class="math inline">\frac{\dee N}{\dee t} = rN\left(1 - \frac{N}{k}\right)</span>:</p>
<blockquote>
<p><span class="math display">\displaystyle 
\begin{aligned}
\frac{\dee N}{\dee t} &amp;= rN\left(1 - \frac{N}{k}\right) \\
\int \frac{1}{N\left(1 - \frac{N}{k}\right)} \frac{\dee N}{\dee t} \dee t &amp;= \int r \dee t \\
\int \frac{1}{N\left(1 - \frac{N}{k}\right)} \dee N &amp;= rt + c \\
\int \frac{A}{N} + \frac{B}{1 - \frac{N}{k}} \dee N &amp;= rt + c \\
A\left(1 - \frac{N}{k}\right) + BN &amp;= 1; A = 1; B = \frac{1}{k} \\
\int \frac{1}{N} + \frac{\frac{1}{k}}{1 - \frac{N}{k}} \dee N &amp;= rt + c \\
\ln \abs{N} + \int \frac{1}{k - N} \dee N &amp;= rt + c \\
\ln \abs{N} - \ln \abs{N - k} &amp;= rt + c \\
\ln \abs{\frac{N}{N - k}} &amp;= rt + c \\
-\ln \abs{\frac{N}{N - k}} &amp;= -rt - c \\
\ln \abs{\frac{N - k}{N}} &amp;= -rt - c \\
\abs{\frac{N - k}{N}} &amp;= e^{-rt - c} \\
\frac{N - k}{N} &amp;= \pm e^{-rt} e^{-c} \\
F &amp;= \pm e^{-c} \\
1 - \frac{k}{N} &amp;= Fe^{-rt} \\
\frac{k}{N} &amp;= Fe^{-rt} + 1 \\
N &amp;= \frac{k}{1 + Fe^{-rt}}
\end{aligned}
</span> Note that all solutions tend toward <span class="math inline">k</span>, which we can verify by taking the limit of <span class="math inline">N</span> at infinity.<br />
Now we will solve for <span class="math inline">F</span> - at <span class="math inline">t = 0</span>, <span class="math inline">N = N_0</span>. Assume <span class="math inline">t = 0</span>.<br />
So <span class="math inline">N_0 = \frac{k}{1 + Fe^{-r0}}</span> and <span class="math inline">N_0 + FN_0 = k</span>, so <span class="math inline">F = \frac{k}{N_0} - 1</span>.<br />
So <span class="math inline">N = \frac{k}{1 + \left(\frac{k}{N_0} - 1\right)e^{-rt}}</span>.</p>
</blockquote>
<h1 id="section-15">10/2/14</h1>
<p>Differential equations appear quite often in equations for time based physical phenomena.</p>
<p>Separable differential equations are one type of differential equation that can be directly solved. However, there are other types.</p>
<h2 id="linear-differential-equations">Linear Differential Equations</h2>
<p><strong>Linear differential equations</strong> are those of the form <span class="math inline">\frac{\dee y}{\dee x} = A(x) y + B(x), A(x) \ne B(x)</span>. It is called linear because the degree of <span class="math inline">y</span> on the right side is 1.</p>
<p>If <span class="math inline">A(x) = B(x)</span>, then the equation is separable since <span class="math inline">A(x)y + B(x) = (y + 1)A(x)</span>, so it would be simpler to solve it that way, but the following technique would also work.</p>
<p>We can solve these by splitting the equation into two separable equations and then solving each of those. This technique is developed by Euler.</p>
<p>Note that if we multiply the equation by an arbitrary function <span class="math inline">I(x)</span>, we get <span class="math inline">I(x) \frac{\dee y}{\dee x} = I(x) A(x) y + I(x) B(x)</span>.</p>
<h3 id="first-equation">First equation</h3>
<p>So <span class="math inline">I(x) \frac{\dee y}{\dee x} - I(x) A(x) y = I(x) B(x)</span>.</p>
<p>Assume <span class="math inline">I(x)</span> is a function that satisfies <span class="math inline">\frac{\dee}{\dee x} (I(x) y) = I(x) B(x)</span> or <span class="math inline">I(x) y = \int I(x) B(x) \dee x</span>.</p>
<p>So <span class="math inline">y = \frac{1}{I(x)} \left(\int I(x) B(x) \dee x\right)</span>.</p>
<p>Clearly, <span class="math inline">\frac{\dee}{\dee x} I(x) y = y \frac{\dee}{\dee x} I(x) + I(x) \frac{\dee y}{\dee x} = I(x) B(x) = I(x) \frac{\dee y}{\dee x} - I(x) A(x) y</span></p>
<p>So <span class="math inline">y \frac{\dee}{\dee x} I(x) + I(x) \frac{\dee y}{\dee x} = I(x) \frac{\dee y}{\dee x} - I(x) A(x) y</span> and <span class="math inline">y \frac{\dee}{\dee x} I(x) = -I(x) A(x) y</span>.</p>
<h3 id="second-equation">Second equation</h3>
<p>So <span class="math inline">\frac{\dee}{\dee x} I(x) = -I(x) A(x)</span>. This is a separable differential equation.</p>
<p>Solving, we get <span class="math inline">\int \frac{1}{I(x)} \dee I(x) = -\int A(x) \dee x</span>.</p>
<p>Clearly, <span class="math inline">\int \frac{1}{I(x)} \dee I(x) = \ln \abs{I(x)}</span> so <span class="math inline">\abs{I(x)} = e^{-\int A(x) \dee x}</span> and <span class="math inline">I(x) = \pm e^{-\int A(x) \dee x}</span>.</p>
<p>Here, <span class="math inline">I(x)</span> is called the <strong>integrating factor</strong>. In general, <span class="math inline">I(x) = \pm e^{-\int A(x) \dee x}</span>.</p>
<h3 id="substitution">Substitution</h3>
<p>Now we substitute back into the original equation: <span class="math inline">y = \frac{1}{I(x)} \int I(x) B(x) \dee x = \frac{1}{\pm e^{-\int A(x) \dee x}} \int (\pm e^{-\int A(x) \dee x} B(x)) \dee x = \frac{1}{e^{-\int A(x) \dee x}} \int e^{-\int A(x) \dee x} B(x) \dee x</span>.</p>
<p>The <strong>general rule</strong> is that given <span class="math inline">\frac{\dee y}{\dee x} = A(x) y + B(x)</span>, <span class="math inline">y = \frac{1}{I(x)} \int I(x) B(x) \dee x</span> where <span class="math inline">I(x) = e^{-\int A(x) \dee x}</span>.</p>
<p>Consider the velocity of a falling object, <span class="math inline">\frac{\dee v}{\dee t} = g - \beta v</span>, where <span class="math inline">g</span> is gravitational acceleration and <span class="math inline">\beta</span> is the drag coefficient:</p>
<blockquote>
<p>Clearly, this is an equation of the form <span class="math inline">\frac{\dee v}{\dee t} = A(t) v + B(t)</span> where <span class="math inline">A(t) = -\beta</span> and <span class="math inline">B(x) = g</span>.<br />
So <span class="math inline">I(x) = e^{-\int (-\beta) \dee t} = e^{\beta t}</span>.<br />
So <span class="math inline">v = \frac{1}{e^{\beta t}} \int e^{\beta t} g \dee x = \frac{1}{e^{\beta t}} \left(\frac{g}{\beta} e^{\beta t} + c\right)</span>.<br />
So <span class="math inline">v = \frac{1}{e^{\beta t}} \left(\frac{g}{\beta} e^{\beta t} + c\right) = \frac{g}{\beta} + ce^{-\beta t}</span>.<br />
Now we need to find <span class="math inline">c</span>. Since <span class="math inline">v(t) = v(0) = v_0 = \frac{g}{\beta} + ce^{-\beta 0}</span>, <span class="math inline">c = v_0 - \frac{g}{\beta}</span>.<br />
So <span class="math inline">v = \frac{g}{\beta} + \left(v_0 - \frac{g}{\beta}\right)e^{-\beta t}</span>.<br />
We can check our answer by substituting <span class="math inline">v</span> back into the original equation: <span class="math inline">\frac{\dee}{\dee t} \left(\frac{g}{\beta} + \left(v_0 - \frac{g}{\beta}\right)e^{-\beta t}\right) = g - \beta \left(\frac{g}{\beta} + \left(v_0 - \frac{g}{\beta}\right)e^{-\beta t}\right) = g - \left(g + (\beta v_0 - g)e^{-\beta t}\right) = (g - \beta v_0)e^{-\beta t}</span>, which is correct.</p>
</blockquote>
<p>Consider <span class="math inline">x^2 \frac{\dee y}{\dee x} + xy = 1</span> for <span class="math inline">y(x) = y(1) = 2, x &gt; 0</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">x^2 \frac{\dee y}{\dee x} + xy = 1</span> is equivalent to <span class="math inline">\frac{\dee y}{\dee x} + \frac{1}{x}y = \frac{1}{x^2}</span> or <span class="math inline">\frac{\dee y}{\dee x} = -\frac{1}{x}y + \frac{1}{x^2}</span>.<br />
So <span class="math inline">I(x) = e^{-\int \left(-\frac{1}{x}\right) \dee x} = e^{\ln x} = x</span>.<br />
So <span class="math inline">y = \frac{1}{x} \int x \frac{1}{x^2} \dee x = \frac{\ln x + c}{x}</span>.<br />
Since <span class="math inline">y(x) = y(1) = 2</span>, <span class="math inline">2 = \frac{\ln 1 + c}{1}</span> and <span class="math inline">c = 2</span>.<br />
So <span class="math inline">y = \frac{\ln x + 2}{x}</span>.</p>
</blockquote>
<h1 id="section-16">12/2/14</h1>
<p>Often when solving differential equations, it is not possible to get an explicit solution (where the variable is isolated on one side). Instead, it is often only possible to get an implicit solution, like <span class="math inline">2\ln y + y^2 = x</span>.</p>
<p>Midterm Review:</p>
<ul>
<li>Techniques of Integration
<ul>
<li>Review</li>
<li>Integration by Substitution</li>
<li>Integration by Parts</li>
<li>Trigonometric Substitution</li>
<li>Partial Fraction Decomposition</li>
</ul></li>
<li>Applications
<ul>
<li>Volumes of Solids
<ul>
<li>Method of Shells</li>
<li>Method of Disks</li>
</ul></li>
<li>Improper Integrals</li>
<li>Differential Equations
<ul>
<li>Qualitative Analysis</li>
<li>Separable Differential Equations</li>
<li>Linear Differential Equations
<ul>
<li>Integrating Factors</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="sequences-series-taylor-polynomials">Sequences, Series, Taylor Polynomials</h2>
<p>Given a function <span class="math inline">f(x)</span>, we can often find a polynomial <span class="math inline">P(x)</span> that has the same first <span class="math inline">N</span> derivatives at a point <span class="math inline">x = a</span>.</p>
<p>For example, <span class="math inline">f(x) = \sin x</span> and <span class="math inline">P(x) = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!}</span> have the same first 7 derivatives at <span class="math inline">x = 0</span>. In other words, <span class="math inline">\frac{\dee^i f}{\dee x^i} = \frac{\dee^i P}{\dee x^i}</span> for <span class="math inline">1 \le i \le 7</span> at <span class="math inline">x = 0</span>.</p>
<p>Another example is <span class="math inline">f(x) = \frac{1}{1 - x}</span> and <span class="math inline">P(x) = 1 + x + x^2 + x^3 + \ldots + x^N</span>. The first <span class="math inline">N</span> derivates at <span class="math inline">x = 0</span> are always equal, and it works for any arbitrary <span class="math inline">N</span>.</p>
<p>In general, if <span class="math inline">P(x) = \sum_{n = 0}^N \frac{f^{(n)}(a)}{n!}(x - a)^n</span>, then <span class="math inline">f(x)</span> and <span class="math inline">P(x)</span> share the first <span class="math inline">N</span> derivative values at <span class="math inline">x = a</span>. The notation <span class="math inline">f^{(n)}(a)</span> represents <span class="math inline">\evalat{\frac{\dee^n}{\dee x^n} f(x)}_{x = a}</span>.</p>
<p>The most important use of this is approximation of very difficult functions. This allows us to use polynomials as tools to analyze many types of functions.</p>
<p>What kinds of functions does this work for?</p>
<p>In the limit <span class="math inline">N \to \infty</span>, does <span class="math inline">f(x) = P(x) = \lim_{N \to \infty} \sum_{n = 0}^N \frac{f^{(n)}(a)}{n!}(x - a)^n</span> for all <span class="math inline">x</span>? Does the limit even exist?</p>
<h2 id="sequences">Sequences</h2>
<p>A <strong>sequence</strong> is an ordered list of numbers. We denote it with <span class="math inline">a_0, a_1, \ldots, a_n</span>, or simply <span class="math inline">a_n = f(n)</span>. For example, <span class="math inline">a_n = 2n</span> is equivalent to <span class="math inline">0, 2, 4, 6, \ldots</span></p>
<p>A sequence <strong>converges</strong> if it has a limit as <span class="math inline">n \to \infty</span>.</p>
<p>Sequences are often easier to work with than functions. For example, the <span class="math inline">\epsilon-\delta</span> definition of limits is much simpler.</p>
<p>The definition of the limit of a sequence is: a sequence <span class="math inline">a_n</span> has a limit <span class="math inline">L</span> if and only if for any <span class="math inline">\epsilon &gt; 0</span>, we can find <span class="math inline">k \in \mb{Z}</span> such that <span class="math inline">\abs{a_n - L} &lt; \epsilon</span> whenever <span class="math inline">n &gt; k</span>.</p>
<p>Formally, the limit <span class="math inline">L</span> exists if and only if <span class="math inline">\forall \epsilon &gt; 0, \exists k \in \mb{Z}, n &gt; k \implies \abs{a_n - L} &lt; \epsilon</span>.</p>
<p>This is similar to the definition of limits at infinity. For example, the sequence <span class="math inline">0.3, 0.33, 0.333, 0.3333, \ldots</span> has the limit <span class="math inline">L = \frac{1}{3}</span>, but <span class="math inline">1, -1, 1, -1, \ldots</span> has no limit.</p>
<p>Use the definition of the limit to prove that the limit of <span class="math inline">a_n = \frac{n}{1 + n}</span> is 1:</p>
<blockquote>
<p>Let <span class="math inline">\epsilon \in \mb{R}</span>. Construct <span class="math inline">k = \frac{1}{\epsilon} - 1</span>.<br />
Assume <span class="math inline">n &gt; k</span>. Then <span class="math inline">n &gt; \frac{1}{\epsilon} - 1</span> and <span class="math inline">\frac{1}{1 + n} &lt; \epsilon</span>, so <span class="math inline">\abs{\frac{n}{1 + n} - 1} &lt; \epsilon</span>.<br />
So by definition, <span class="math inline">\lim_{n \to \infty} a_n = 1</span>.</p>
</blockquote>
<p>If <span class="math inline">a_n</span> and <span class="math inline">L</span> lie in the domain of a continuous function <span class="math inline">f</span> and <span class="math inline">a_n \to L</span> as <span class="math inline">n \to \infty</span>, then <span class="math inline">\lim_{n \to \infty} f(a_n) = f(L)</span>. In other words, the limit of a sequence is the same as the limit of its corresponding function at infinity.</p>
<p>Sequences are easy to deal with if they are explicit functions of the index <span class="math inline">n</span>, but a lot of sequences are defined recursively, like <span class="math inline">a_{n + 1} = a_n + \frac{1}{n!}, a_0 = 1</span>.</p>
<p>;wip: try <span class="math inline">a_n = 7^{\frac{1}{2} + \frac{1}{n}}\tan \frac{\pi n + 1}{4n}</span> limit at infinity - </p>
<h1 id="section-17">14/2/14</h1>
<p>It is in fact easy to determine if any sequence converges or diverges.</p>
<p>Sequences that are defined only in terms of the current index are easy to find the limit of. For example, <span class="math inline">a_n = \frac{n}{n + 1}</span> converges to 1 at infinity.</p>
<p>However, sequences defined recursively are not so straightforward. For example, <span class="math inline">a_{n + 1} = a_n + \frac{1}{n!}, a_0 = 1</span>. This is an <strong>implicitly defined sequence</strong>.</p>
<h3 id="monotone-convergence-theorem">Monotone Convergence Theorem</h3>
<p>If the terms of a sequence are <strong>bounded</strong>, and the sequence is <strong>monotone</strong>, then the sequence converges.</p>
<p>There are two possible cases:</p>
<ul>
<li>If the sequence has an upper bound <span class="math inline">a_n \le b</span> and is monotonially increasing, then it converges.</li>
<li>If the sequence has a lower bound <span class="math inline">a_n \ge b</span> and is monotonically decreasing, then it converges.</li>
</ul>
<p><strong>Boundedness</strong> means that every element in the sequence is between a lower and upper bound. Formally, a sequence <span class="math inline">a_n</span> is bounded if and only if <span class="math inline">\exists u, \exists v, \forall n, u \le a_n \le v</span>.</p>
<p>We often prove boundedness by comparing to a known sequence (like <span class="math inline">\frac{1}{n!} \le \frac{1}{2^{n - 1}}</span>) or by using induction.</p>
<p><strong>Monotonicity</strong> means that once we start going up, we never go down again, and once we start going down, we never go up again. Basically, <span class="math inline">a_0 \le a_1 \le a_2 \le \ldots</span>, or <span class="math inline">a_0 \ge a_1 \ge a_2 \ge \ldots</span>.</p>
<p>Formally, a sequence <span class="math inline">a_n</span> is monotone if and only if <span class="math inline">(\forall u, \forall v, u &lt; v \implies a_u &lt; a_v) \vee (\forall u, \forall v, u &lt; v \implies a_u &gt; a_v)</span>.</p>
<p>Proof:</p>
<blockquote>
<p>It is intuitively obvious that if a value is always increasing, and cannot exceed a value, then it must converge to some value.<br />
Without loss of generality, assume that <span class="math inline">a_n</span> is increasing and bounded by <span class="math inline">a_n \le b</span>.<br />
Let <span class="math inline">p</span> be the smallest possible upper bound on <span class="math inline">a_n</span>.<br />
As an aside, <span class="math inline">p</span> is the limit of the sequence - any number less than this is not an upper bound, and any number greater than this can be smaller while still being an upper bound.<br />
Let <span class="math inline">\epsilon &gt; 0</span>.<br />
Clearly, <span class="math inline">p - \epsilon &lt; p</span>, so <span class="math inline">\exists k, p - \epsilon &lt; a_k</span>, since any value less than the tight upper bound must be exceeded by some element in the sequence.<br />
Assume <span class="math inline">n &gt; k</span>. Clearly, <span class="math inline">a_k \le a_n</span> (since the sequence is monotonically increasing).<br />
Clearly, <span class="math inline">a_n \le p &lt; p + \epsilon</span>.<br />
So <span class="math inline">p - \epsilon &lt; a_n &lt; p + \epsilon</span> and <span class="math inline">-\epsilon &lt; a_n - p &lt; \epsilon</span>.<br />
So <span class="math inline">\abs{a_n - p} &lt; \epsilon</span>, and by the definition of the limit, <span class="math inline">p</span> is the limit and the sequence converges.</p>
</blockquote>
<p>Does <span class="math inline">a_0 = 1, a_{n + 1} = a_n + \frac{1}{n!}</span> converge?</p>
<blockquote>
<p>Clearly, <span class="math inline">\frac{1}{n!}</span> is always positive, so <span class="math inline">a_{n + 1} = a_n + \frac{1}{n!}</span> is monotonically increasing.<br />
Clearly, <span class="math inline">n! \le 2^{n - 1}</span>, since <span class="math inline">1 \cdot \ldots \cdot k \le 2 \cdot \ldots \cdots 2 \text{ (} k - 1 \text{ times)}</span>.<br />
So <span class="math inline">\frac{1}{n!} \le \frac{1}{2^{k - 1}}</span> and <span class="math inline">a_n \le 1 + 1 + \frac{1}{2} + \frac{1}{2^2} + \ldots + \frac{1}{2^{n - 1}}</span>.<br />
Clearly, this is a monotonically increasing geometric progression, and so we can determine that <span class="math inline">1 + 1 + \frac{1}{2} + \frac{1}{2^2} + \ldots + \frac{1}{2^{n - 1}} = \frac{1 - \left(\frac{1}{2}\right)^n}{1 - \frac{1}{2}}</span>.<br />
Clearly, <span class="math inline">\lim_{n \to \infty} \frac{1 - \left(\frac{1}{2}\right)^n}{1 - \frac{1}{2}} = \frac{1}{\frac{1}{2}} = 2</span>.<br />
So <span class="math inline">a_n \le \frac{1}{2^{k - 1}} \le 2</span>, and by the convergence theorem, the sequence converges.<br />
As an aside, it converges to <span class="math inline">e</span>.</p>
</blockquote>
<p>Does <span class="math inline">a_1 = 1, a_{n + 1} = \sqrt{3 + 2a_n}</span> converge?</p>
<blockquote>
<p>The first few elements of the sequence are <span class="math inline">1, 2.23606797749979, 2.73352079834772, 2.90981813807933, 2.96978724425819</span>.<br />
Clearly, <span class="math inline">a_{n + 1} \ge a_n \iff \sqrt{3 + 2a_n} \ge a_n \iff a_n^2 - 2a_n - 3 \le 0</span>, or <span class="math inline">-1 \le a_n \le 3</span>.<br />
So <span class="math inline">a_n</span> is monotonically increasing if <span class="math inline">[-1, 3]</span>.<br />
Assume <span class="math inline">a_n \le 3</span>. Then <span class="math inline">3 + 2a_n \le 9</span> and <span class="math inline">\sqrt{3 + 2a_n} \le 3</span>. So <span class="math inline">a_{n + 1} \le 3</span>.<br />
So by induction, <span class="math inline">a_n</span> has an upper bound of 3.<br />
So by the monotone convergence theorem, the sequence converges.<br />
Also, note that if the limit exists, we can set <span class="math inline">n \to \infty</span> and so <span class="math inline">a_{n + 1} = a_n</span>.<br />
So <span class="math inline">a_n^2 - 2a_n - 3 = 0</span> and <span class="math inline">a_n = -1, 3</span>. -1 is a extraneous answer since the function is always positive, so <span class="math inline">\lim_{n \to \infty} a_n = 3</span>.</p>
</blockquote>
<h1 id="section-18">24/2/14</h1>
<p>The monotone convergence theorem only tells us whether the sequence converges, but not what the actual limit is.</p>
<p>We usually prove the monotonicity and boundedness of sequences by comparing them to sequences with known properties (like geometric series), or by using induction.</p>
<p>To use induction to prove monotonicity, we simply need to prove that <span class="math inline">a_{n + 1} \ge a_n</span> for any <span class="math inline">n</span>.</p>
<p>To use induction to prove boundedness, we first need to guess a <span class="math inline">k</span> that might be an upper or lower bound. Then, we verify that it works for the first element of the sequence, and then that <span class="math inline">a_n \le k \implies a_{n + 1} \le k</span>.</p>
<p>If we know that the limit exists, sometimes we can find the limit by setting <span class="math inline">n \to \infty</span>, which implies that <span class="math inline">a_{n + 1} = a_n</span> (since we are at the limit).</p>
<p>Then we can write <span class="math inline">a_{n + 1}</span> in terms of <span class="math inline">a_n</span>, and we get a function over <span class="math inline">a_n</span>, which we can often isolate and solve for, which gives us the limit <span class="math inline">L = a_n</span>. The previous example uses this technique.</p>
<p>This doesn't always work. For example, it work doesn't for <span class="math inline">a_0 = 1, a_{n + 1} = a_n + \frac{1}{n!}</span>. If we try to substitute it, we get <span class="math inline">a_n = a_n + \frac{1}{n!} = a_n + \frac{1}{\infty} = a_n</span>. This doesn't help us find the limit.</p>
<h2 id="series">Series</h2>
<p>A series is a sum of terms. We denote this as <span class="math inline">S_N = \sum_{n = 0}^N a_n, a_n \in \mb{R}</span>. Here, <span class="math inline">N \in \mb{Z}, N \ge 0</span>.</p>
<p>For now, <span class="math inline">a_n</span> is a constant, which can depend on <span class="math inline">n</span>. Eventually, we want to be able to build and analyze sequences of functions, which can depend on other variables like <span class="math inline">x</span>.</p>
<p>If <span class="math inline">N</span> is finite, then <span class="math inline">S_N</span> is known as a <strong>partial sum</strong>.</p>
<p>We analyze series by analyzing the sequence of the series values: <span class="math inline">\sum_{n = 0}^0 a_n, \sum_{n = 0}^1 a_n, \sum_{n = 0}^2 a_n, \ldots</span>.</p>
<p>So just as we take the limit of a sequence, we can take the limit of a series with <span class="math inline">\lim_{N \to \infty} \sum_{n = 0}^N a_n</span>. This is the relation between sequences and series.</p>
<p>A sequence <strong>converges</strong> if this limit exists. Otherwise, it <strong>diverges</strong>. A series converges if and only if the limit of its partial sum to infinity is a finite value.</p>
<p>For example, we previously saw the sequence <span class="math inline">a_0 = 1, a_{n + 1} = a_n + \frac{1}{n!}</span>, which is actually equivalent to the series <span class="math inline">S_N = \sum_{n = 0}^1 \frac{1}{n!}</span>. They are equivalent because <span class="math inline">a_n = S_N</span> when <span class="math inline">n = N</span>.</p>
<p>We also define <span class="math inline">\sum a_n = \sum_{n = k}^\infty a_n, k \in \mb{Z}</span> for convenience.</p>
<h1 id="section-19">26/2/14</h1>
<h3 id="geometric-series">Geometric Series</h3>
<p>The geometric series is <span class="math inline">S_N = \sum_{n = 0}^N x^n = 1 + x + x^2 + x^3 + \ldots + x^n</span>.</p>
<p>The geometric series is a rare example of a series that can be written in <strong>closed form</strong> - non-recursively and in a finite number of symbols. In other words, we can write the value of the partial sum of the series as a function of <span class="math inline">n</span>.</p>
<p>Which values of <span class="math inline">n</span> make the series converge?</p>
<p>First, we start with the identity of <span class="math inline">1 - x^{N + 1} = (1 - x)(1 + x + x^2 + x^3 + \ldots + x^N)</span>. This is true because <span class="math inline">(1 - x)(1 + x + x^2 + x^3 + \ldots + x^N) = (1 + x + x^2 + x^3 + \ldots + x^N) - (x + x^2 + x^3 + \ldots + x^{N + 1}) = 1 + x - x + x^2 - x^2 + x^3 - x^3 + \ldots + x^N - x^N - x^{N + 1} = 1 - x^{N + 1}</span>.</p>
<p>So <span class="math inline">S_N = \sum_{n = 0}^N x^n = 1 + x + x^2 + x^3 + \ldots + x^N = \frac{1 - x^{N + 1}}{1 - x}</span>.</p>
<p>So the limit is <span class="math inline">\lim_{N \to \infty} \frac{1 - x^{N + 1}}{1 - x} = \frac{1}{1 - x} - \frac{x}{1 - x} \lim_{N \to \infty} x^N</span>.</p>
<p>If <span class="math inline">x = 1</span>, then <span class="math inline">\lim_{N \to \infty} \sum_{n = 0}^N 1^n = 1 + \ldots + 1 = \infty</span>, and the sequence diverges.</p>
<p>If <span class="math inline">x = -1</span>, then <span class="math inline">\lim_{N \to \infty} \sum_{n = 0}^N (-1)^n = 1 - 1 + 1 - 1 + \ldots + 1 - 1 = ?</span>. This sum either has the value 0 or 1, and oscillates infinitely as we go to infinity. Therefore, the sequence diverges.</p>
<p>Clearly, if <span class="math inline">x &gt; 1</span> or <span class="math inline">x &lt; -1</span>, the value goes to positive or negative infinity, and the sequence diverges.</p>
<p>Therefore, the geometric series converges only for <span class="math inline">-1 &lt; x &lt; 1</span> (<span class="math inline">\abs{x} &lt; 1</span>), since if this is the case, <span class="math inline">\lim_{N \to \infty} x^N = 0</span> and <span class="math inline">\lim_{N \to \infty} S_N = \frac{1}{1 - x}</span>.</p>
<p>Does <span class="math inline">\sum_{k = 1}^\infty 3^{2k}5^{1 - k}</span> converge?</p>
<blockquote>
<p>Clearly, <span class="math inline">\sum_{k = 1}^\infty 3^{2k}5^{1 - k} = \sum_{k = 1}^\infty 9^k5^{1 - k} = 5\sum_{k = 1}^\infty 9^k5^{-k} = 5\sum_{k = 1}^\infty \frac{9^k}{5^k} = 5\sum_{k = 1}^\infty \left(\frac{9}{5}\right)^k</span>.<br />
Since <span class="math inline">\frac{9}{5} \ge 1</span>, the geometric sequence diverges as the limit of <span class="math inline">\left(\frac{9}{5}\right)^k</span> goes to infinity.</p>
</blockquote>
<p>Does <span class="math inline">3 - \frac{3}{2}x^2 + \frac{3}{4}x - \frac{3}{8}x^2</span> converge? ;wip: what was the original question again? this doesn't seem right</p>
<blockquote>
<p>Clearly, <span class="math inline">3 - \frac{3}{2}x^2 + \frac{3}{4}x - \frac{3}{8}x^2 = 3 \sum_{n = 0}^\infty \left(-\frac{x}{2}\right)^n</span>.<br />
Clearly, in order to converge, <span class="math inline">-1 \le -\frac{x}{2} \le -1</span>, or <span class="math inline">-1 \le \frac{x}{2} \le 1</span>.<br />
As an aside, it converges to <span class="math inline">\frac{3}{1 + \frac{x}{2}} = \frac{6}{2 + x}</span>.</p>
</blockquote>
<h1 id="section-20">28/2/14</h1>
<p>The value of the geometric series is <span class="math inline">S_N = \sum_{n = 0}^N x^n = 1 + x + x^2 + \ldots + x^N = \begin{cases} \frac{1 - x^N}{1 - x} &amp;\text{if } x \ne 1 \\ N + 1 &amp;\text{if } x = 1 \end{cases}</span></p>
<h3 id="convergence">Convergence</h3>
<p>One of the simplest tests for convergence is that if the terms of a series are not getting closer and closer to 0, the series can never converge. In other words, <span class="math inline">\lim_{n \to \infty} a_n = 0</span> is a requirement for convergence.</p>
<p>Formally, if <span class="math inline">\lim_{n \to \infty} \abs{a_n} \ne 0</span>, then the sequence does not converge.</p>
<p>This is known as the <strong>simple limit test</strong> for series.</p>
<p>Our convergence tests can decide whether a series converges or not, but do not provide information about what it converges to.</p>
<p>The sum of two convergent series is also convergent - <span class="math inline">\sum a_n + \sum b_n = \sum (a_n + b_n)</span> if <span class="math inline">\sum a_n</span> and <span class="math inline">\sum b_n</span> are both convergent. However, the sum of two divergent series is not necessarily always divergent. For example, <span class="math inline">\sum_{n = 1}^\infty (-1)^n</span> and <span class="math inline">\sum_{n = 1}^\infty (-1)^{n + 1}</span> are both divergent, but <span class="math inline">\sum_{n = 1}^\infty {(-1)^n + (-1)^{n + 1}} = 0</span>.</p>
<h2 id="p-series">P-series</h2>
<p>A <strong>P-series</strong> is a series of the form <span class="math inline">\sum_{n = 1}^\infty \frac{1}{n^P}</span> where <span class="math inline">P \in \mb{R}</span>.</p>
<h3 id="convergence-1">Convergence</h3>
<p>We want to figure out which values of <span class="math inline">P</span> allow the series to converge.</p>
<p>Clearly, <span class="math inline">\sum_{n = 1}^\infty \frac{1}{n^P} = \sum_{n = 1}^\infty n^{-P}</span>.</p>
<p>Clearly, if <span class="math inline">P \le 0</span>, then <span class="math inline">\lim_{n \to \infty} n^{-P} \ne 0</span>. So by the simple limit test, the sequence does not converge.</p>
<p>If <span class="math inline">P &gt; 0</span>, then <span class="math inline">f(n) = \frac{1}{n^P}</span> is continuous, positive, and decreasing.</p>
<p>Clearly, <span class="math inline">\int_1^\infty \frac{1}{x^P} \dee x = \frac{1}{1 - P} \evalat{x^{1 - P}}_1^\infty</span> converges if and only if <span class="math inline">P &gt; 1</span>.</p>
<p>So by the integral test, <span class="math inline">\sum_{n = 1}^\infty \frac{1}{n^P}</span> converges if and only if <span class="math inline">P &gt; 1</span>.</p>
<p>So <span class="math inline">\sum_{n = 1}^\infty \frac{1}{n^P}</span> converges if and only if <span class="math inline">P &gt; 1</span>.</p>
<h3 id="considerations">Considerations</h3>
<p>The series <span class="math inline">\sum_1^\infty \frac{1}{n}</span> is called the <strong>harmonic series</strong>. It diverges (very slowly, like the logarithmic functions), and this can be proven since it is a special case of the P-series where <span class="math inline">P = 1</span>. This is a useful series because <span class="math inline">\lim_{n \to \infty} \frac{1}{n} = 0</span>, yet the series diverges, so this is an example of the simple convergence test not giving a conclusive result.</p>
<p>For example, a P-series where <span class="math inline">P = 2</span> is <span class="math inline">\frac{\pi^2}{6}</span>. ;wip: how?</p>
<p>As an aside, we have closed forms for P-series for all even <span class="math inline">P</span> - always in the form of <span class="math inline">\frac{m}{n}\pi^P</span>. However, we do not know anything at this time about odd <span class="math inline">P</span>.</p>
<p>For example, a P-series where <span class="math inline">P = 3</span> results in a value that has no known exact form, and is still an unsolved problem in methematics.</p>
<h2 id="integral-test">Integral Test</h2>
<p>This is based on the connection between an infinite series (like a Riemann sum) and integration.</p>
<p>Let <span class="math inline">\sum_{n = 0}^\infty a_n</span> be an infinite series. Then we can write <span class="math inline">a_n</span> be a function of <span class="math inline">n</span>, like <span class="math inline">f(n)</span>.</p>
<p>For example, for <span class="math inline">\sum_{n = 0}^\infty \frac{1}{n^2}</span>, <span class="math inline">f(n) = \frac{1}{n^2}</span>.</p>
<p>Now we can develop the <strong>integral test</strong>.</p>
<p>Given <span class="math inline">f(n) = a_n</span>, if <span class="math inline">f(n)</span> is <strong>continuous</strong>, <strong>positive</strong>, and <strong>decreasing</strong> for all <span class="math inline">n \ge 1</span>, then <span class="math inline">\int_1^\infty f(n) \dee n</span> converges if and only if <span class="math inline">\sum_{n = 1}^\infty a_n</span> converges.</p>
<h3 id="error-estimation">Error Estimation</h3>
<p>For series that satisfy the hypetheses of the integral test, we can estimate the error/remainder <span class="math inline">R_N = \sum_1^\infty a_n - \sum_1^N a_n</span> for any <span class="math inline">N</span>.</p>
<p>This is useful because we can't explicitly calculate <span class="math inline">\sum_1^\infty a_n</span>, but we can calculate <span class="math inline">\sum_1^N a_n</span>.</p>
<p>So given <span class="math inline">f(n) = a_n</span> being continuous, positive, and decreasing, the error is bounded by <span class="math inline">\int_{N + 1}^\infty f(x) \dee x \le R_N \le \int_N^\infty f(x) \dee x</span>.</p>
<p>In other words, the error is bounded between <span class="math inline">\int_{N + 1}^\infty f(x)</span> and <span class="math inline">\int_N^\infty f(x) \dee x</span>.</p>
<p>For example, for the series <span class="math inline">S_N = \sum_{n = 1}^N \frac{1}{n^2}</span>, <span class="math inline">S_{10} \approxeq 1.54977</span>. We know that since <span class="math inline">f(n) = \frac{1}{n^2}</span> is continuous, positive, and decreasing, and <span class="math inline">\int_1^\infty \frac{1}{n^2}</span>. ;wip</p>
<h1 id="section-21">3/3/14</h1>
<h2 id="comparison-test-series">Comparison Test (Series)</h2>
<p>There is a deep connection between infinite series and improper integrals.</p>
<p>Like the improper integral, we can also have a form of the comparison test, but it is easier to use than with integrals.</p>
<p>Given <span class="math inline">\sum a_n</span> and <span class="math inline">\sum b_n</span>, two series, with <span class="math inline">0 \le a_n \le b_n</span>:</p>
<ul>
<li>If <span class="math inline">\sum a_n</span> diverges, then <span class="math inline">\sum b_n</span> also diverges.</li>
<li>If <span class="math inline">\sum b_n</span> converges, then <span class="math inline">\sum a_n</span> also converges.</li>
</ul>
<p>Here, <span class="math inline">\sum a_n</span> is the series we are interested in and <span class="math inline">\sum b_n</span> is the series we chose to compare it with.</p>
<h3 id="limit-comparison-test">Limit Comparison Test</h3>
<p>For series only - not integrals - we can rewrite this in a more useful form.</p>
<p>Let <span class="math inline">\sum a_n</span> and <span class="math inline">\sum b_n</span> be two series, with <span class="math inline">a_n \ge 0, b_n \ge 0</span>.</p>
<p>Let <span class="math inline">\rho = \lim_{n \to \infty} \frac{a_n}{b_n}</span>.</p>
<p>If <span class="math inline">0 &lt; \rho &lt; \infty</span> (<span class="math inline">\rho</span> is positive and finite), then:</p>
<ul>
<li><span class="math inline">\sum a_n</span> and <span class="math inline">\sum b_n</span> both diverge.</li>
<li><span class="math inline">\sum a_n</span> and <span class="math inline">\sum b_n</span> both converge.</li>
</ul>
<p>This is easily proved via contradiction or similar.</p>
<p>Note that if <span class="math inline">\rho = 0</span> or <span class="math inline">\rho = \infty</span>, then we cannot say anything about whether they converge or not, and we need to pick a better comparison.</p>
<p>Prove that <span class="math inline">\sum_{n = 1}^\infty \frac{\abs{\sin n}}{\sqrt{n + n^3}}</span> converges:</p>
<blockquote>
<p>Clearly, <span class="math inline">\frac{\abs{\sin n}}{\sqrt{n + n^3}} \le \frac{1}{\sqrt{n + n^3}} &lt; \frac{1}{\sqrt{n^3}} = \frac{1}{n^\frac{3}{2}}</span>.<br />
Since this is a P-series where <span class="math inline">P = \frac{3}{2}</span>, <span class="math inline">\sum_{n = 1}^\infty \frac{1}{n^\frac{3}{2}}</span> converges.<br />
So by the comparison test, <span class="math inline">\sum_{n = 1}^\infty \frac{\abs{\sin n}}{\sqrt{n + n^3}}</span> converges.</p>
</blockquote>
<h1 id="section-22">5/3/14</h1>
<p>We can find useful comparisons to make by finding something bigger than the numerator, and smaller than the denominator, and trying that as a comparison.</p>
<p>For example, <span class="math inline">\sum_1^\infty \frac{\sqrt{n}}{n^2 + 2} &lt; \sum_1^\infty \frac{\sqrt{n}}{n^2} = \sum_1^\infty \frac{1}{n^\frac{3}{2}}</span>, which converges as it is a P-series with <span class="math inline">P = \frac{3}{2}</span>.</p>
<p>For example, <span class="math inline">\sum_1^\infty \frac{1}{2^nn} \le \sum_1^\infty \frac{1}{2^n} = \sum_1^\infty \left(\frac{1}{2}\right)^n</span>, which converges since it is a geometric series with <span class="math inline">x = \frac{1}{2}</span>.</p>
<p>Does <span class="math inline">\sum_1^\infty \frac{1}{n^{1 + \frac{1}{n}}}</span> exist?</p>
<blockquote>
<p>Clearly, <span class="math inline">\sum_1^\infty \frac{1}{n^{1 + \frac{1}{n}}} = \sum_1^\infty \frac{1}{n}\frac{1}{n^\frac{1}{n}} &lt; \sum_1^\infty \frac{1}{n}</span>.<br />
Using the limit comparison test, <span class="math inline">\rho = \lim_{n \to \infty} \frac{\frac{1}{n}\frac{1}{n^\frac{1}{n}}}{\frac{1}{n}} = \lim_{n \to \infty} n^{-\frac{1}{n}} = e^{-\lim_{n \to \infty} \frac{1}{n}\ln n} \lH e^{-\lim_{n \to \infty} \frac{\frac{1}{n}}{1}} = e^{-0} = 1</span>.<br />
Since <span class="math inline">0 &lt; \rho &lt; \infty</span>, and <span class="math inline">\sum_1^\infty \frac{1}{n}</span> diverges, then <span class="math inline">\sum_1^\infty \frac{1}{n^{1 + \frac{1}{n}}}</span> also diverges.</p>
</blockquote>
<p>Proof of limit comparison test:</p>
<blockquote>
<p>Let <span class="math inline">\sum a_n</span> and <span class="math inline">\sum b_n</span> be two series, with <span class="math inline">a_n \ge 0, b_n \ge 0</span>.<br />
Let <span class="math inline">\rho = \lim_{n \to \infty} \frac{a_n}{b_n}</span>. Assume <span class="math inline">0 &lt; \rho &lt; \infty</span>.<br />
Clearly, <span class="math inline">\exists m, M &gt; 0, 0 &lt; m &lt; \rho &lt; M &lt; \infty</span>.<br />
Clearly, <span class="math inline">\lim_{n \to \infty} \frac{a_n}{b_n} \iff (\exists K, n &gt; K \implies m &lt; \frac{a_n}{b_n} &lt; M)</span>.<br />
So <span class="math inline">mb_n &lt; a_n &lt; Mb_n</span> and <span class="math inline">\sum mb_n &lt; \sum a_n &lt; \sum Mb_n</span>, or <span class="math inline">m\sum b_n &lt; \sum a_n &lt; M\sum b_n</span>.<br />
Suppose <span class="math inline">\sum b_n</span> converges. Then <span class="math inline">\sum a_n &lt; M\sum b_n</span> and by the comparison test, <span class="math inline">\sum a_n</span> converges.<br />
Suppose <span class="math inline">\sum b_n</span> diverges. Then <span class="math inline">m\sum b_n &gt; \sum a_n</span> and by the comparison test, <span class="math inline">\sum a_n</span> diverges.<br />
So <span class="math inline">\sum a_n</span> converges if and only if <span class="math inline">\sum b_n</span> converges.</p>
</blockquote>
<p>Also, we can prove that sequences diverge by proving that they are increasing or decreasing without bound, or assuming that the sequence does converge, and deriving a contradiction.</p>
<h1 id="section-23">7/3/14</h1>
<h2 id="alternating-series">Alternating Series</h2>
<p>These are series where the sign of the terms alternate.</p>
<p>These usually take the form of <span class="math inline">\sum a_n = \sum (-1)^n p_n, p_n &gt; 0</span>.</p>
<p>Alternating series are useful to study because they have several useful properties.</p>
<h3 id="error">Error</h3>
<p>The remainder/error after <span class="math inline">N</span> terms is easy to estimate. Clearly, <span class="math inline">\abs{R_N} = \abs{\sum^\infty (-1)^n p_n - \sum^N (-1)^n p_n}</span>. So <span class="math inline">\abs{R_N} \le p_{N + 1}</span>.</p>
<p>This is true because the terms of the series keep bouncing back and forth across the limit, so the remainder is always bounded by the value of the next term.</p>
<p>For example, <span class="math inline">\sum_1^\infty (-1)^{n + 1} \frac{1}{n} = 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \ldots = \ln 2</span>. We can estimate the error with <span class="math inline">\abs{R_N} = \frac{1}{N + 1}</span>.</p>
<h3 id="convergence-2">Convergence</h3>
<p>For an alternating series, if <span class="math inline">\lim_{n \to \infty} p_n = 0</span>, and <span class="math inline">p_{n + 1} \le p_n</span>, then the series converges.</p>
<p>In other words, if the terms of the sum tend to 0, and they are monotonically decreasing, then the series converges. This is one of the simplest convergence tests, but it only works on alternating series.</p>
<p>Alternating series also have special nomenclature that can be applied to them.</p>
<p>Let <span class="math inline">\sum a_n = \sum (-1)^n p_n</span> be an alternating series.</p>
<p><span class="math inline">\sum a_n</span> is <strong>absolutely convergent</strong> if <span class="math inline">\sum a_n</span> and <span class="math inline">\sum \abs{a_n}</span> converge.</p>
<p>Absolute convergence means that the series is <strong>well behaved</strong> - it behaves like an ordinary number. We can add, subtract, multiply, and divide absolutely convergent series and the result is still sensible.</p>
<p><span class="math inline">\sum a_n</span> is <strong>conditionally convergent</strong> if <span class="math inline">\sum a_n</span> converges, but <span class="math inline">\sum \abs{a_n}</span> diverges.</p>
<p>Conditional convergence means the series might not be well behaved.</p>
<p>For example, consider <span class="math inline">1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \ldots</span>.</p>
<p>For an absolutely convergent series, re-arrangement does nothing. This is not true for conditionally convergent series. In fact, the above can have its terms rearranged such that it sums up to any value we want, and this was proved by Riemann.</p>
<p>For example, we will make it sum up to 1.5:</p>
<blockquote>
<p>First, we add up positive terms until we pass 1.5: <span class="math inline">1 + \frac{1}{3} + \frac{1}{5} \approxeq 1.53</span>.<br />
Then we add negative terms until we fall below 1.5 again: <span class="math inline">1 + \frac{1}{3} + \frac{1}{5} - \frac{1}{2} \approxeq 1.03</span>.<br />
Then we repeat: <span class="math inline">1 + \frac{1}{3} + \frac{1}{5} - \frac{1}{2} + \frac{1}{7} + \frac{1}{9} + \frac{1}{11} + \frac{1}{13} + \frac{1}{15} \approxeq 1.52</span>.<br />
We can do this as many times as needed to get the desired value.</p>
</blockquote>
<p>Even though there are far more positive terms than negative terms, we can do this because we have an infinite number of terms that we can add up. This only works because the series is infinite.</p>
<h1 id="section-24">10/3/14</h1>
<h2 id="ratio-test">Ratio Test</h2>
<p>This is the most useful of the convergence tests.</p>
<p>Let <span class="math inline">\sum a_n</span> be a series. Let <span class="math inline">L = \lim_{n \to \infty} \abs{\frac{a_{n + 1}}{a_n}}</span>.</p>
<p>If <span class="math inline">L &lt; 1</span>, then <span class="math inline">\sum a_n</span> converges absolutely.</p>
<p>If <span class="math inline">L &gt; 1</span>, then <span class="math inline">\sum a_n</span> diverges.</p>
<p>Otherwise, if <span class="math inline">L = 1</span>, the test is inconclusive. This test is very effective for powers and factorials, and especially for power series and Taylor series.</p>
<p>Determine if <span class="math inline">\sum_{n = 0}^\infty \frac{(n + 4)!}{4!n!4^n}</span> converges:</p>
<blockquote>
<p>We will use the ratio test.<br />
Let <span class="math inline">L = \lim_{n \to \infty} \abs{\frac{((n + 1) + 4)!}{4!(n + 1)!4^(n + 1)} \frac{4!n!4^n}{(n + 4)!}} = \lim_{n \to \infty} \frac{n + 5}{4!(n + 1)!4^(n + 1)} 4!n!4^n = \lim_{n \to \infty} \frac{n + 5}{4(n + 1)!} n! = \lim_{n \to \infty} \frac{n + 5}{4(n + 1)} \lH \lim_{n \to \infty} \frac{1}{4} = \frac{1}{4}</span>.<br />
Since <span class="math inline">L &lt; 1</span>, <span class="math inline">\sum_{n = 0}^\infty \frac{(n + 4)!}{4!n!4^n}</span> converges absolutely.</p>
</blockquote>
<p>Proof:</p>
<blockquote>
<p>The idea is that if <span class="math inline">L &lt; 1</span>, then we can compare <span class="math inline">\sum a_n</span> to a convergent geometric series.<br />
Assume <span class="math inline">L &lt; 1</span>. Then <span class="math inline">\exists r \in \mb{R}, L &lt; r &lt; 1</span>.<br />
Note that <span class="math inline">\lim_{n \to \infty} \abs{\frac{a_{n + 1}}{a_n}}</span> means that <span class="math inline">\exists K &gt; 0, n \ge K \implies \abs{\frac{a_{n + 1}}{a_n}} &lt; L</span>.<br />
So <span class="math inline">\exists 0 \le N \le K, n \ge N \implies \abs{\frac{a_{n + 1}}{a_n}} &lt; r</span>.<br />
Assume <span class="math inline">n \ge N</span>. Then <span class="math inline">\abs{\frac{a_{n + 1}}{a_n}} &lt; r</span> and <span class="math inline">\abs{a_{n + 1}} &lt; r\abs{a_n}</span>.<br />
So <span class="math inline">\forall k, \abs{a_{N + k}} &lt; \abs{a_N}r^k</span>. For example, <span class="math inline">\abs{a_{N + 3}} &lt; \abs{a_{N + 2}}r &lt; \abs{a_{N + 1}}r^2 &lt; \abs{a_N}r^3</span>.<br />
So <span class="math inline">\sum_{k = 0}^\infty \abs{a_{N + k}} &lt; \sum_{k = 0}^\infty \abs{a_{N}}r^k</span>.<br />
Clearly, <span class="math inline">\sum_{k = 0}^\infty \abs{a_{N}}r^k = \abs{a_{N}}\sum_{k = 0}^\infty r^k</span>, which converges since it is a geometric series with <span class="math inline">x &lt; 1</span>.<br />
So by the comparison test, <span class="math inline">\sum a_n &lt; \abs{a_{N}}\sum_{k = 0}^\infty r^k</span>, so <span class="math inline">\sum a_n</span> converges.<br />
A similar proof can be made for the case when <span class="math inline">L &gt; 1</span>.</p>
</blockquote>
<p>Another example is <span class="math inline">e^x = \sum_{n = 0}^\infty \frac{x^n}{n!}</span>. Note that if we take the limit of the series, we get the same series back.</p>
<h3 id="root-test">Root Test</h3>
<p>Let <span class="math inline">\sum a_n</span> be a series. Let <span class="math inline">L = \lim_{n \to \infty} \sqrt[n]{\abs{a_n}}</span>.</p>
<p>If <span class="math inline">L &lt; 1</span>, then <span class="math inline">\sum a_n</span> converges absolutely.</p>
<p>If <span class="math inline">L &gt; 1</span>, then <span class="math inline">\sum a_n</span> diverges.</p>
<p>This can be proved in a manner similar to the ratio test.</p>
<h1 id="section-25">12/3/14</h1>
<h2 id="using-convergence-tests">Using Convergence Tests</h2>
<p>Let <span class="math inline">\sum a_n</span> be a series.</p>
<ol type="1">
<li>Simple Limit Test: If <span class="math inline">\lim_{n \to \infty} a_n \ne 0</span>, then <span class="math inline">\sum a_n</span> diverges.</li>
<li>Alternating Series Test: If the series is alternating and decreasing (<span class="math inline">\abs{a_{n + 1}} &lt; \abs{a_n}</span>), then <span class="math inline">\sum a_n</span> converges.</li>
<li>Ratio Test/Root Test: Let <span class="math inline">L = \lim_{n \to \infty} \abs{\frac{a_{n + 1}}{a_n}}</span> or <span class="math inline">L = \lim_{n \to \infty} \sqrt[n]{\abs{a_n}}</span>, whichever is easier to evaluate:
<ol type="1">
<li>If <span class="math inline">L &lt; 1</span>, then <span class="math inline">\sum a_n</span> converges.</li>
<li>If <span class="math inline">L &gt; 1</span>, then <span class="math inline">\sum a_n</span> diverges.</li>
</ol></li>
<li>If <span class="math inline">a_n</span> is an algebraic (polynomials and roots) function of <span class="math inline">n</span>, then try using the Comparison Test with a P-series, <span class="math inline">\sum \frac{1}{n^P}</span>.</li>
<li>If <span class="math inline">a_n</span> is closely related to a geometric series, then try using the Comparison Test with a geometric series, <span class="math inline">\sum x^n</span>.</li>
<li>If <span class="math inline">f(n) = a_n</span> is positive, decreasing, and integrable, then try the Integral Test.</li>
</ol>
<p>Prove whether the following converge or diverge:</p>
<ul>
<li><span class="math inline">\sum_{n = 1}^\infty \frac{n^2 + 7n}{\sqrt{n^5 + 4n^3 - 2}} \le \frac{1}{\sqrt{n}}</span>.</li>
<li><span class="math inline">\sum_{n = 1}^\infty \frac{n + 5}{5^n}</span></li>
<li><span class="math inline">\sum_{n = 1}^\infty n^2 e^{-n}</span></li>
<li><span class="math inline">\sum_{n = 1}^\infty \frac{1}{(\ln n)^{\ln n}}</span></li>
<li><span class="math inline">\sum_{n = 1}^\infty \frac{e^\frac{1}{n}}{n^2}</span></li>
</ul>
<p>;wip</p>
<h2 id="power-series">Power Series</h2>
<p>A power series is a series of the form <span class="math inline">\sum_{n = 0}^\infty a_n (x - x_0)^n</span>, where <span class="math inline">a_n \in \mb{R}</span>.</p>
<p>Here, <span class="math inline">x_0</span> is the <strong>center</strong> of the power series.</p>
<p>We want to figure out for which values of <span class="math inline">x</span> our series converges for. For this, we will usually use the ratio test.</p>
<p>For example, check if <span class="math inline">\sum_{n = 1}^\infty \frac{(-1)^n x^n}{3^n \sqrt{n}}</span> converges:</p>
<blockquote>
<p>Let <span class="math inline">L = \lim_{n \to \infty} \abs{\frac{(-1)^{n + 1} x^{n + 1}}{3^{n + 1} \sqrt{n + 1}} \frac{3^n \sqrt{n}}{(-1)^n x^n}} = \lim_{n \to \infty} \abs{\frac{-x}{3 \sqrt{n + 1}} \sqrt{n}} = \frac{\abs{x}}{3} \lim_{n \to \infty} \frac{1}{\sqrt{n + 1}} \sqrt{n} = \frac{\abs{x}}{3} \lim_{n \to \infty} \sqrt{\frac{n}{n + 1}} = \frac{\abs{x}}{3}</span>. ;wip: use l'hospital's rule or something to evaluate the limit properly Clearly, <span class="math inline">L &lt; 1</span> whenever <span class="math inline">-3 &lt; x &lt; 3</span>, so the series converges for any <span class="math inline">-3 &lt; x &lt; 3</span>.<br />
Clearly, <span class="math inline">L &gt; 1</span> whenever <span class="math inline">x &lt; -3 \vee x &gt; 3</span>, so the series diverges for any <span class="math inline">x &lt; -3 \vee x &gt; 3</span>.<br />
Now we need to consider <span class="math inline">L = 1</span>, where <span class="math inline">x = \pm 3</span>. Assume <span class="math inline">x = 3</span>.<br />
Then <span class="math inline">\sum_{n = 1}^\infty \frac{(-1)^n x^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{(-1)^n 3^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{(-1)^n}{\sqrt{n}}</span>.<br />
This is an alternating series, and since <span class="math inline">\lim_{n \to \infty} \frac{1}{\sqrt{n}} = 0</span> and <span class="math inline">\frac{1}{\sqrt{n + 1}} &lt; \frac{1}{\sqrt{n}}</span>, the series converges (conditionally) by the alternating series test.<br />
Assume <span class="math inline">x = -3</span>.<br />
Then <span class="math inline">\sum_{n = 1}^\infty \frac{(-1)^n x^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{(-1)^n (-3)^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{(-1)^n (-1)^n 3^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{1}{\sqrt{n}}</span>.<br />
This is a P-series where <span class="math inline">P = \frac{1}{2}</span>, so the series diverges.<br />
So the series converges absolutely if and only if <span class="math inline">x \in (-3, 3)</span>, and converges conditionally for <span class="math inline">x = 3</span>.</p>
</blockquote>
<h3 id="radius-of-convergence">Radius of Convergence</h3>
<p>The <strong>radius of convergence</strong> for a power series is the maximum magnitude of the values of <span class="math inline">\abs{x - x_0}</span> on the imaginary plane such that all numbers inside this radius of <span class="math inline">x_0</span> allow the power series to converge absolutely, and all numbers outside of this radius diverge.</p>
<p>The behaviour when <span class="math inline">\abs{x - x_0} = \rho</span> is not important, just that it is a bounding radius.</p>
<p>The values of <span class="math inline">x</span> that allow the series to converge are known as the <strong>interval of convergence</strong>. Unlike the radius of convergence, we also need to consider the endpoints of the interval for convergence.</p>
<p>This is a number <span class="math inline">\rho \in \mb{R}</span> such that:</p>
<ul>
<li><span class="math inline">\sum_{n = 0}^\infty c_n (x - x_0)^n</span> converges absolutely for all <span class="math inline">\abs{x - x_0} &lt; \rho</span></li>
<li><span class="math inline">\sum_{n = 0}^\infty c_n (x - x_0)^n</span> diverges for all <span class="math inline">\abs{x - x_0} &gt; \rho</span></li>
<li><span class="math inline">\sum_{n = 0}^\infty c_n (x - x_0)^n</span> may converge or diverge for <span class="math inline">\abs{x - x_0} = \rho</span></li>
</ul>
<p>In the above example, the radius of convergence is 3.</p>
<p>All geometric series are power series where <span class="math inline">a_n = 1</span> and <span class="math inline">x_0 = 0</span>.</p>
<p>The interval of convergence for a geometric series <span class="math inline">\sum_{n = 0}^\infty x^n</span> is <span class="math inline">\abs{x} &lt; 1</span>.</p>
<h1 id="section-26">14/3/14</h1>
<p>Within the radius of convergence, a power series behaves like an ordinary function. The idea is that if we are inside the radius of convergence, then we can treat the infinite series like a finite polynomial.</p>
<p>Let <span class="math inline">f(x) = \sum_{n = 0}^\infty a_n (x - x_0)^n, g(x) = \sum_{n = 0}^\infty b_n (x - x_0)^n</span>:</p>
<ul>
<li><span class="math inline">f(x) \pm g(x) = \sum_{n = 0}^\infty (a_n \pm b_n) (x - x_0)^n</span>.</li>
<li><span class="math inline">f(x) g(x) = \sum_{n = 0}^\infty c_n (x - x_0)^n</span> where <span class="math inline">c_n = a_0 b_n + a_1 b_{n - 1} + \ldots + a_{n - 1} b_1 + a_n b_0</span>.</li>
<li>If <span class="math inline">g(x) \ne 0</span>, then <span class="math inline">\frac{f(x)}{g(x)} = \sum_{n = 0}^\infty d_n (x - x_0)^n</span> ;wip: what is d_n?</li>
</ul>
<p>More importantly, we can differentiate and integrate the terms of the sum:</p>
<p>So <span class="math inline">\frac{\dee f}{\dee x} = \frac{\dee}{\dee x} (a_0 + a_1(x - x_0) + a_2 (x - x_0)^2 + \ldots) = 0 + a_1 + 2a_2 (x - x_0) + \ldots</span>. Note that the first term became 0, so we don't need to sum it.</p>
<p>So <span class="math inline">\frac{\dee f}{\dee x} = \sum_{n = 0}^\infty a_n n(x - x_0)^{n - 1}</span>.</p>
<p>So <span class="math inline">\int f(x) \dee x = \sum_{n = 0}^\infty \int a_n (x - x_0)^n \dee x = c + \sum_{n = 0}^\infty a_n \frac{(x - x_0)^{n + 1}}{n + 1}</span>.</p>
<p>Find the power series of <span class="math inline">\frac{1}{1 - x}</span> and use it to approximate <span class="math inline">\ln</span>:</p>
<blockquote>
<p>Clearly, this is the value of the geometric series, as we saw earlier: <span class="math inline">\frac{1}{1 - x} = \sum_{n = 0}^\infty x^n</span> for <span class="math inline">\abs{x} &lt; 1</span>.<br />
Clearly, <span class="math inline">\int_0^t \frac{1}{1 - x} \dee x = -\ln \abs{1 - t} = \sum_{n = 0}^\infty \int_0^t x^n \dee x = \sum_{n = 0}^\infty \frac{t^{n + 1}}{n + 1}</span> for <span class="math inline">\abs{t} &lt; 1</span>.<br />
So <span class="math inline">\ln \abs{1 - t} = -\sum_{n = 1}^\infty \frac{t^n}{n}</span> for <span class="math inline">\abs{t} &lt; 1</span>.<br />
Note that this only works for <span class="math inline">\abs{t} &lt; 1</span>. However, there are tricks we can use to avoid this issue.<br />
For example, we can't use this approximation to find <span class="math inline">\ln 3</span>, since for <span class="math inline">\ln \abs{1 - t}</span>, <span class="math inline">t = -2</span>, but note that <span class="math inline">\ln \frac{1}{3} = -\ln 3</span>, so <span class="math inline">\ln 3 = -\ln \frac{1}{3} = -\ln \abs{1 - \frac{2}{3}} = \sum_{n = 1}^\infty \frac{1}{n} \frac{2}{3}^n</span>.<br />
We want a general form for all values in the domain of <span class="math inline">\ln x</span>, so <span class="math inline">x &gt; 0</span>.<br />
Clearly, <span class="math inline">\ln \abs{1 - (-t)} - \ln \abs{1 - t} = \ln \abs{\frac{1 + t}{1 - t}} = -\sum_{n = 1}^\infty \frac{(-t)^n}{n} + \sum_{n = 1}^\infty \frac{t^n}{n} = \sum_{n = 1}^\infty (1 - (-1)^n)\frac{t^n}{n} = 2t + \frac{2}{3}t^3 + \frac{2}{5}t^5 + \ldots = \sum_{n = 1}^\infty \frac{2}{2n - 1}t^{2n - 1}</span>.<br />
Let <span class="math inline">x = \abs{\frac{1 + t}{1 - t}}</span>. Then <span class="math inline">t = \abs{\frac{x - 1}{x + 1}} = \frac{x - 1}{x + 1}</span>, since <span class="math inline">x &gt; 0</span>.<br />
So <span class="math inline">\abs{t} &lt; 1 \iff -x &lt; x &lt; x + 2 \iff x &gt; 0</span>, so <span class="math inline">\abs{t} &lt; 1</span> for all <span class="math inline">x</span> in the domain, as required.<br />
Then we can write <span class="math inline">\ln x = \ln \frac{1 + t}{1 - t} = \sum_{n = 1}^\infty \frac{2}{2n - 1}\left(\frac{x - 1}{x + 1}\right)^{2n - 1}</span>, for <span class="math inline">x &gt; 0</span>.</p>
</blockquote>
<p>This is actually how calculators evaluate these sorts of functions - by calculating the partial sums of a power series to a given error.</p>
<p>Find the power series for <span class="math inline">\frac{1}{1 + x^2}</span> and use it to approximate <span class="math inline">\arctan</span>:</p>
<blockquote>
<p>Let <span class="math inline">u = -x^2</span>. Then <span class="math inline">\frac{1}{1 + x^2} = \frac{1}{1 - u} = \sum_{n = 0}^\infty u^n = \sum_{n = 0}^\infty (-1)^n x^{2n}</span> for <span class="math inline">\abs{u} &lt; 1</span>.<br />
Clearly, <span class="math inline">\int_0^t \frac{1}{1 + x^2} \dee x = \arctan t = \sum_{n = 0}^\infty \int_0^t (-1)^n x^{2n} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1} t^{2n + 1}</span> for <span class="math inline">\abs{t} &lt; t</span>.<br />
So <span class="math inline">\arctan t = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1} t^{2n + 1}</span> for <span class="math inline">-1 &lt; t &lt; 1</span>.</p>
</blockquote>
<h2 id="taylor-series">Taylor Series</h2>
<p>What power series is identical to a function <span class="math inline">f(x)</span> and all its derivatives at a point <span class="math inline">x = x_0</span>?</p>
<p>For <span class="math inline">\abs{x - x_0} &lt; \rho</span>, where <span class="math inline">\rho</span> is the radius of convergence, <span class="math inline">f(x) = \sum_{n = 0}^\infty \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n</span> where <span class="math inline">f^{(n)}(x_0) = \evalat{\frac{\dee^n f}{\dee x^n}}_{x = x_0}</span>, and <span class="math inline">f^{(0)}(x_0) = f(x_0)</span>. This is known as a <strong>Taylor series</strong>.</p>
<p>A <strong>Taylor polynomial</strong> is a partial sum of a Taylor series - all partial sums of Taylor series are simply polynomials. <span class="math inline">\sum_{n = 0}^k \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n</span> is known as a <span class="math inline">k</span>-degree Taylor polynomial.</p>
<p>Find the Taylor polynomial for <span class="math inline">e^x</span> and use it to estimate <span class="math inline">\int_0^1 e^{-x^2} \dee x</span>:</p>
<blockquote>
<p>Let <span class="math inline">f(x) = e^x, x_0 = 0</span>. Then <span class="math inline">f^{(n)} = \evalat{\frac{\dee^n f}{\dee x^n}}_{x = x_0} = \evalat{e^x}_{x = x_0} = 1</span>.<br />
Then <span class="math inline">f(x) = e^x = \sum_{n = 0}^\infty \frac{x^n}{n!}, \abs{x - x_0} &lt; \rho</span>.<br />
Let <span class="math inline">L = \lim_{n \to \infty} \abs{\frac{x^{n + 1}}{(n + 1)!} \frac{n!}{n^n}} = \lim_{n \to \infty} \abs{\frac{x}{n + 1}} = 0</span>.<br />
Then by the ratio test, the series converges for all <span class="math inline">0 &lt; 1</span>, and the radius of covnergence is <span class="math inline">\rho = \infty</span>.<br />
So <span class="math inline">\int_0^1 e^{-x^2} \dee x = \int_0^1 f(-x^2) \dee x = \sum_{n = 0}^\infty \int_0^1 \frac{(-x^2)^n}{n!} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{n!(2n + 1)}</span>.</p>
</blockquote>
<h1 id="section-27">17/3/14</h1>
<p>;wip: check to make sure assignment marks are on LEARN</p>
<p>The Taylor series has the same derivative and integral as the function for all possible values of <span class="math inline">x</span> within the radius of convergence.</p>
<p>The <span class="math inline">N</span>th partial sum of a Taylor series has the same zero to <span class="math inline">N</span>th derivatives.</p>
<p>Find the Taylor series for <span class="math inline">\sin x</span> and <span class="math inline">\cos x</span>:</p>
<blockquote>
<p>Let <span class="math inline">f(x) = \sin x, x_0 = 0</span>. Then <span class="math inline">f^{(n)} = \evalat{\frac{\dee^n f}{\dee x^n}}_{x = x_0}</span>. Clearly, <span class="math inline">f^{(0)}(0) = 0, f^{(1)}(0) = 1, f^{(1)}(0) = 0, f^{(1)}(0) = -1, \ldots</span>.<br />
Since all the even powers are 0, then we simply omit those terms.<br />
So <span class="math inline">f(x) = \sin x = \sum_{n = 0}^\infty \frac{f^{(n)}(x_0)}{n!}x^n = x - \frac{x^3}{3} + \frac{x^5}{5!} - \frac{x^7}{7!} + \ldots = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}, \abs{x - x_0} &lt; \rho</span>.<br />
Let <span class="math inline">L = \lim_{n \to \infty} \abs{\frac{(-1)^{n + 1} x^{2n + 3}}{(2n + 3)!} \frac{(2n + 1)!}{(-1)^n}} = \lim_{n \to \infty} \abs{\frac{x^2}{(2n + 3)(2n + 2)}} = 0</span>.<br />
Then by the ratio test, the series converges for all <span class="math inline">0 &lt; 1</span>, and the radius of covnergence is <span class="math inline">\rho = \infty</span>.<br />
So the Taylor series is <span class="math inline">\sin x = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}</span>.<br />
We can find the Taylor series for <span class="math inline">\cos x</span> by taking derivatives of both sides: <span class="math inline">\frac{\dee}{\dee x} \sin x = \cos x = \frac{\dee}{\dee x} \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!} = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n}}{(2n)!}</span>.</p>
</blockquote>
<p>Taylor series allow us to do interesting analyses. For example, it is easy to see that <span class="math inline">\sin(-x) = -\sin x</span> from the fact that <span class="math inline">\sum_{n = 0}^\infty \frac{(-1)^n (-x)^{2n + 1}}{(2n + 1)!} = -\sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}</span>.</p>
<p>;wip: use the taylor series to show that <span class="math inline">e^{i \theta} = \cos \theta + \imag \sin \theta</span> - prove euler's identity</p>
<p>We want to find a simple formula to find <span class="math inline">(1 + x)^P</span> for any natural number <span class="math inline">P</span>. This was found to be <span class="math inline">1 + Px + \frac{P(P - 1)x^2}{2!} + \frac{P(P - 1)(P - 2)}{3!} + \ldots + \frac{P \cdot (P - 1) \cdot \ldots \cdot (P - (n - 1))}{n!}x^n + \ldots</span>.</p>
<p>Clearly, for any whole number <span class="math inline">P</span> the series must terminate after <span class="math inline">P + 1</span> terms - when one of the factors <span class="math inline">(P - k)</span> becomes 0. However, if <span class="math inline">P</span> is a fraction, then the series actually becomes infinite. As it turns out, this works for negative numbers too.</p>
<p>For example, <span class="math inline">\sqrt{1 - x} = (1 + x)^\frac{1}{2} = 1 - \frac{1}{2}x - \frac{1}{8}x^2 - \frac{1}{16}x^3 - \ldots</span>.</p>
<p>Some common Taylor series are:</p>
<ul>
<li>Geometric series: <span class="math inline">\sum_{n = 0}^\infty x^n = \frac{1}{1 - x}, \abs{x - x_0} &lt; \rho</span></li>
<li>Exponential series: <span class="math inline">\sum_{n = 0} \frac{x^n}{n!} = e^x, \abs{x - x_0} &lt; \rho</span></li>
<li>Trigonometric series: <span class="math inline">\sin x = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}</span></li>
<li>Binomial series: <span class="math inline">1 + Px + \frac{P(P - 1)}{2!}x^2 + \frac{P(P - 1)(P - 2)}{3!}x^3 + \ldots + \frac{P \cdot (P - 1) \cdot \ldots \cdot (P - (n - 1))}{n!}x^n + \ldots = (1 + x)^P</span></li>
</ul>
<h1 id="section-28">19/3/14</h1>
<h2 id="properties-of-taylor-series">Properties of Taylor Series</h2>
<p>So far we have derived power series by integrating geometric series, or by using the Taylor formula.</p>
<p>Is the Taylor series of a function unique? Are there multiple ways to write out the power series of a function?</p>
<p>First, we define the partial sum of a Taylor series for a function <span class="math inline">f(x)</span>, <span class="math inline">P_{N, x_0}(x) = \sum_{n = 0}^N \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n</span>.</p>
<p>Then the remainder - the difference between the function and the partial sum - is <span class="math inline">R_N(x) = f(x) - P_{N, x_0}(x) = \sum_{n = N + 1}^\infty \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n</span>.</p>
<p>For example, given <span class="math inline">f(x) = e^x</span>, <span class="math inline">P_{3, 0}(x) = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!}</span> and <span class="math inline">R_{3, 0} = e^x - 1 - x - \frac{x^2}{2!} - \frac{x^3}{3!}</span>.</p>
<h3 id="uniqueness-of-taylor-series">Uniqueness of Taylor Series</h3>
<p>If <span class="math inline">f^{(n)}(x)</span> exists for all <span class="math inline">n \in \mb{N}</span> for some interval <span class="math inline">\mb{I}</span> such that <span class="math inline">x_0 \in \mb{I}</span>, and <span class="math inline">\forall n \in \mb{N}, x \in \mb{I}, \abs{f^{(n)}(x)} &lt; \infty</span>, then <span class="math inline">\forall x \in \mb{I}, \lim_{N \to \infty} \abs{f(x) - P_{N, x_0}(x)} = 0</span>.</p>
<p>In other words, if the function has all derivatives on an interval containing <span class="math inline">x = x_0</span>, and all these derivatives are finite, then as we add more terms to the partial sum, the partial sum eventually converges to exactly the function.</p>
<p>As a result, <span class="math inline">P_{N, x_0}</span> is <strong>unique</strong>. Practically speaking, this means we can generate Taylor series using any method we want to, and the result will always be the one true Taylor series for a given <span class="math inline">f(x)</span> and <span class="math inline">x_0</span>.</p>
<p>Proof:</p>
<blockquote>
<p>;wip</p>
</blockquote>
<p>Derive the Taylor series for <span class="math inline">f(x) = e^{-x^2}</span> for <span class="math inline">x_0 = 0</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">f^{(0)}(0) = 1, f^{(1)}(0) = 0, \ldots</span>, and the derivatives keep getting more and more complicated as we keep differentiating. It is impractical to calculate <span class="math inline">f^{(n)}</span>.<br />
Instead, we use a substitution: let <span class="math inline">u = -x^2</span>. Then <span class="math inline">e^u = 1 + u + \frac{u^2}{2!} + \frac{u^3}{3!} + \ldots</span>.<br />
Then <span class="math inline">e^{-x^2} = 1 - x^2 + \frac{x^4}{2!} - \frac{x^6}{3!} + \ldots</span>.</p>
</blockquote>
<p>This is a faster way to derive series - by using <strong>substitutions</strong> to make the functions simpler, converting the simpler function into a series, and then substituting the variable back into the series.</p>
<p>Derive a Taylor series for <span class="math inline">f(x) = \sin x^3</span> at <span class="math inline">x_0 = 0</span>:</p>
<blockquote>
<p>Let <span class="math inline">u = x^3</span>. Then <span class="math inline">\sin x^3 = \sin u = \sum_{n = 0}^\infty \frac{(-1)^n u^{2n + 1}}{(2n + 1)!} = \sum_{n = 0}^\infty \frac{(-1)^n x^{6n + 3}}{(2n + 1)!} = \sin x^3</span>.</p>
</blockquote>
<p>Derive the Taylor series for <span class="math inline">f(x) = \frac{1 + x}{1 - x}</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">f(x) = (1 + x)\frac{1}{1 - x} = (1 + x)\sum_{n = 0}^\infty x^n = \sum_{n = 0}^\infty x^n + \sum_{n = 1}^\infty x^n = 1 + \sum_{n = 1}^\infty x^n + \sum_{n = 1}^\infty x^n = 1 + 2\sum_{n = 1}^\infty x^n</span>.</p>
</blockquote>
<p>Derive the Taylor series for <span class="math inline">\arcsin x</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\arcsin x = \int_0^x \frac{1}{\sqrt{1 - t^2}} \dee t</span>.<br />
Let <span class="math inline">u = -t^2</span>. Clearly, <span class="math inline">\frac{1}{\sqrt{1 - t^2}} = (1 + u)^{-\frac{1}{2}} = 1 - \frac{1}{2}u + \frac{3}{4}\frac{u^2}{2!} - \frac{15}{8}\frac{u^3}{3!} + \frac{105}{16} \frac{u^4}{4!} + \ldots</span>.<br />
So <span class="math inline">(1 + u)^{-\frac{1}{2}} = \frac{1}{\sqrt{1 - t^2}} = 1 + \frac{1}{2}t^2 + \frac{3}{2^2}\frac{t^4}{2!} + \frac{15}{2^3}\frac{t^6}{3!} + \frac{105}{2^4} \frac{t^8}{4!} + \ldots</span>.<br />
So <span class="math inline">\int_0^x \frac{1}{\sqrt{1 - t^2}} \dee t = \arcsin x = \int_0^x 1 \dee t + \int_0^x \frac{1}{2}t^2 \dee t + \int_0^x \frac{3}{2^2}\frac{t^4}{2!} \dee t + \int_0^x \frac{15}{2^3}\frac{t^6}{3!} \dee t + \int_0^x \frac{105}{2^4} \frac{t^8}{4!} \dee t + \ldots = x + \frac{1}{3}\frac{1}{2}t^3 + \frac{1}{5}\frac{3}{2^2}\frac{t^5}{2!} + \frac{1}{7}\frac{15}{2^3}\frac{t^7}{3!} + \frac{1}{9}\frac{105}{2^4} \frac{t^9}{4!} + \ldots</span>.</p>
</blockquote>
<h1 id="section-29">21/3/14</h1>
<h2 id="truncation-error">Truncation Error</h2>
<p>We can actually estimate the error in <span class="math inline">P_{N, x_0}(x)</span>, even without knowing much about <span class="math inline">f(x)</span>.</p>
<h3 id="taylors-remainder-theorem">Taylor's Remainder Theorem</h3>
<p>If <span class="math inline">f^{(n + 1)}(x)</span> is continuous on an interval <span class="math inline">\mb{I}</span> such that <span class="math inline">x_0 \in \mb{I}</span>, then <span class="math inline">\forall x \in \mb{I}, \exists \min(x_0, x) &lt; c &lt; \max(x_0, x), f(x) - P_{N, x_0}(x) = R_N(x) = \frac{f^{(N + 1)}(c)}{(N + 1)!}(x - x_0)^{N + 1}</span>.</p>
<p>In other words, there exists a value <span class="math inline">c</span> between <span class="math inline">x</span> and <span class="math inline">x_0</span> exclusive such that the error is <span class="math inline">\frac{f^{(N + 1)}(c)}{(N + 1)!}(x - x_0)^{N + 1}</span> - the <span class="math inline">N + 1</span>th term evaluated with a certain value of the <span class="math inline">N + 1</span>th derivative.</p>
<p>This can be proved using the Intermediate Value Theorem, but it is a messy proof.</p>
<p>Clearly, if <span class="math inline">f(x) - P_{N, x_0}(x) = \frac{f^{(N + 1)}(c)}{(N + 1)!}(x - x_0)^{N + 1}</span>, then <span class="math inline">\abs{f(x) - P_{N, x_0}(x)} = \abs{R_N(x)} = \abs{\frac{f^{(N + 1)}(c)}{(N + 1)!}(x - x_0)^{N + 1}} = \abs{f^{(N + 1)}(c)}\abs{\frac{(x - x_0)^{N + 1}}{(N + 1)!}} = \abs{f^{(N + 1)}(c)}\frac{\abs{x - x_0}^{N + 1}}{(N + 1)!}</span>.</p>
<p>Clearly, if <span class="math inline">\exists M \in \mb{R}, \forall x \in \mb{I}, \abs{f^{(N + 1)}(x)} \le M</span>, then <span class="math inline">\abs{f^{(N + 1)}(c)} \le M</span> and <span class="math inline">\abs{R_N(x)} \le M\frac{\abs{x - x_0}^{N + 1}}{(N + 1)!}</span>.</p>
<p>This is called the <strong>Taylor's inequality</strong>, and is a more practically useful form of the Taylor Remainder Theorem.</p>
<p>Basically, if <span class="math inline">f^{(n + 1)}(x)</span> is continuous on an interval <span class="math inline">\mb{I}</span> such that <span class="math inline">x_0 \in \mb{I}</span>, and <span class="math inline">\exists M \in \mb{R}, \forall x \in \mb{I}, \abs{f^{(N + 1)}(x)} \le M</span>, then <span class="math inline">\abs{R_{N, x_0}} \le M\frac{\abs{x - x_0}^{N + 1}}{(N + 1)!}</span>.</p>
<p>In other words, if we can bound <span class="math inline">f^{N + 1}(x)</span>, then we can bound the error.</p>
<p>Estimate the error in the Taylor polynomial for <span class="math inline">\sin x</span> about <span class="math inline">x_0 = 0</span> after <span class="math inline">N</span> terms:</p>
<blockquote>
<p>Clearly, the error is <span class="math inline">\abs{R_N(x)} = \abs{\sin x - \sum_{n = 0}^N \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}}</span>.<br />
We want to find an <span class="math inline">M</span> such that <span class="math inline">\abs{f^{(((2N + 1) + 1))}(x)} \le M</span>. Note that we simply added 1 to the derivative depth, not to <span class="math inline">N</span> itself (<span class="math inline">N</span> here actually means <span class="math inline">2N + 1</span>).<br />
Clearly, <span class="math inline">f^{(((2N + 1) + 1))}(x)</span> is either <span class="math inline">\pm \sin x</span> or <span class="math inline">\pm \cos x</span>, and so <span class="math inline">\abs{f^{(2N + 2)}(x)} \le 1</span>.<br />
Then by the Taylor Remainder Theorem, <span class="math inline">\abs{R_N(x)} \le \frac{\abs{x - x_0}^{N + 1}}{(N + 1)!} = \frac{\abs{x}^{N + 1}}{(N + 1)!}</span>.</p>
</blockquote>
<p>We almost always want to minimise the error. To do this, we should keep <span class="math inline">x</span> as close to <span class="math inline">x_0</span> as possible (<span class="math inline">x - x_0</span> can be made smaller), or use more terms in the partial sum (<span class="math inline">(N + 1)</span> can be made larger). Also, we always want the smallest possible <span class="math inline">M</span>, so we want to pick the tightest possible bound for <span class="math inline">f^{(N + 1)}(x)</span>.</p>
<p>Estimate the error in the Taylor polynomial for <span class="math inline">e^x</span> about <span class="math inline">x_0 = 0</span> after <span class="math inline">N</span> terms for <span class="math inline">x \in [-1, 1]</span>, and determine the number of terms before the error is less than 0.000005:</p>
<blockquote>
<p>Clearly, the error is <span class="math inline">\abs{R_N(x)} = \abs{e^x - \sum_{n = 0}^N \frac{x^n}{n!}}</span>.<br />
We want to find <span class="math inline">M</span> such that <span class="math inline">\abs{f^{(N + 1)}(x)} \le M</span>.<br />
Clearly, <span class="math inline">f^{(N + 1)}(x) = e^x</span>, and the largest possible value occurs at <span class="math inline">x = 1</span>, so <span class="math inline">\abs{f^{(N + 1)}(x)} \le e^1</span>, so <span class="math inline">M \ge e</span>.<br />
Then by the Taylor Remainder Theorem, <span class="math inline">\abs{R_N(x)} \le e\frac{\abs{x}^{N + 1}}{(N + 1)!}</span>. We can use any <span class="math inline">M \ge e</span> we want to simplify our calculations, but larger <span class="math inline">M</span> means less useful error bounds.<br />
We want <span class="math inline">\abs{R_N(x)} \le e\frac{\abs{x}^{N + 1}}{(N + 1)!} \le t(N) \le 0.000005</span>, where <span class="math inline">t(N)</span> is a function of <span class="math inline">N</span> only, without <span class="math inline">x</span>.<br />
Since <span class="math inline">\abs{x}^{N + 1} \le 1</span>, <span class="math inline">\frac{e}{(N + 1)!} \le \frac{e\abs{\pm 1}^{N + 1}}{(N + 1)!} \le 0.000005</span>, or <span class="math inline">(N + 1)! \le 200000e</span>.<br />
Clearly, <span class="math inline">400000 = 200000 \cdot 2 \le 200000e \le 200000 \cdot 3 = 600000</span>.<br />
Since <span class="math inline">9! \le 200000</span> and <span class="math inline">10! &gt; 600000</span>, <span class="math inline">N + 1 \ge 10 \iff (N + 1)! &gt; 200000e</span> and <span class="math inline">N \ge 9</span>.<br />
So the error is less than 0.000005 when <span class="math inline">N \ge 9</span>.</p>
</blockquote>
<h1 id="section-30">24/3/14</h1>
<p>A <strong>Maclaurin series</strong> is a Taylor series where <span class="math inline">x_0 = 0</span> - a Taylor series centered around 0.</p>
<p>Clearly, <span class="math inline">\sum_{n = 0}^\infty \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n = \frac{f^{(0)}(x_0)}{0!}(x - x_0)^0 + \ldots + \frac{f^{(N)}(x_0)}{N!}(x - x_0)^N + R_N(x)</span> for some finite <span class="math inline">N</span>.</p>
<p>Let <span class="math inline">\mb{I} = [a, b]</span> such that <span class="math inline">x_0 \in \mb{I}</span>, within the interval of convergence. Clearly, Taylor series are always continuous.</p>
<p>By the Taylor remainder theorem, <span class="math inline">\abs{R_{N, x_0}} = \frac{f^{(N + 1)}(c)}{(N + 1)!}\abs{x - x_0}^{N + 1}</span> for some <span class="math inline">c</span>. Clearly, <span class="math inline">\frac{f^{(N + 1)}(c)}{(N + 1)!}\abs{x - x_0}^{N + 1}</span> is a scalar multiple of <span class="math inline">\frac{f^{(N + 1)}(x)}{(N + 1)!}\abs{x - x_0}^{N + 1}</span>.</p>
<p>So <span class="math inline">R_N(x) = O(1) \frac{f^{(N + 1)}(x)}{(N + 1)!}\abs{x - x_0}^{N + 1}</span>. In other words, we can write the remainder as a scalar multiple of the next term.</p>
<p>So we can actually write the series as <span class="math inline">\frac{f^{(0)}(x_0)}{0!}(x - x_0)^0 + \ldots + \frac{f^{(N)}(x_0)}{N!}(x - x_0)^N + O(1) \frac{f^{(N + 1)}(x_0)}{(N + 1)!}(x - x_0)^{N + 1}</span>.</p>
<p>For example, <span class="math inline">\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + O(1)\frac{x^9}{9!}</span>.</p>
<h2 id="operations-on-taylor-series">Operations on Taylor Series</h2>
<p>The reason we use Taylor series to represent functions is in order to more easily evaluate limits, integrals, and infinite series. It is also useful for approximating the functions with actual numbers, all while being able to get the error bounds in our evaluation.</p>
<h3 id="limits">Limits</h3>
<p>If we take a limit as <span class="math inline">x \to x_0</span>, then the coefficients of a Taylor series already has l'Hospital's rule built in.</p>
<p>Consider <span class="math inline">\lim_{x \to 0} \frac{\sin x}{x}</span>:</p>
<blockquote>
<p>We could find this geometrically, using l'Hospital's rule, or using infinite series.<br />
Clearly, <span class="math inline">\lim_{x \to 0} \frac{\sin x}{x} = \lim_{x \to 0} \frac{x - \frac{x^3}{3!} + \frac{x^5}{5!} + M\frac{x^7}{7!}}{x} = \lim_{x \to 0} 1 - \frac{x^2}{3!} + \frac{x^4}{5!} + M\frac{x^6}{7!} = 1 - 0 + 0 + M0 = 1</span>.</p>
</blockquote>
<p>Evaluate <span class="math inline">\lim_{x \to 0} \frac{e^{\sin x} - 1}{x}</span>:</p>
<blockquote>
<p>Let <span class="math inline">u = \sin x</span>. Clearly, <span class="math inline">\lim_{x \to 0} \frac{e^{\sin x} - 1}{x} = \lim_{x \to 0} \frac{e^u - 1}{x} = \lim_{x \to 0} \frac{(1 + u + \frac{u^2}{2!} + \ldots) - 1}{x} = \lim_{x \to 0} \frac{\sin x + \frac{\sin^2 x}{2!} + \ldots}{x} = \lim_{x \to 0} \frac{\sin x}{x}\left(1 + \frac{\sin x}{2!} + \ldots\right) = \lim_{x \to 0} \frac{\sin x}{x} \lim_{x \to 0} \left(1 + \frac{\sin x}{2!} + \ldots\right) = 1</span>.</p>
</blockquote>
<p>However, it is usually faster and easier to just use l'Hospital's rule.</p>
<h1 id="section-31">26/3/14</h1>
<p>The Taylor inequality basicaly states that the remainder of a Taylor polynomial is a multiple of the next term if the derivative is bounded.</p>
<h3 id="estimating-definite-integrals">Estimating Definite Integrals</h3>
<p><span class="math inline">e^{-x^2}</span> is a Guassian function, which have the general form of <span class="math inline">e^{-\frac{(x - a)^2}{2\sigma^2}}</span>. This is also an error function. It is heavily used in statistics as a probability distribution, and looks like a bell curve. <span class="math inline">\sigma</span> represents the standard deviation of the distribution.</p>
<p>This is also associated with scientific literature claims of &quot;six-sigma&quot; accuracy or similar.</p>
<p>The interesting thing about this function is that it has no antiderivative.</p>
<p>Evaluate <span class="math inline">\int_0^1 e^{-x^2} \dee x</span>:</p>
<blockquote>
<p>Let <span class="math inline">u = -x^2</span>. Clearly, <span class="math inline">e^{-x^2} = \sum_{n = 0}^\infty \frac{(-x^2)^n}{n!} = \sum_{n = 0}^\infty \frac{(-1)^nx^{2n}}{n!}</span>.<br />
So <span class="math inline">\int_0^1 e^{-x^2} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{n!}\int_0^1 x^{2n} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{n!}\evalat{\frac{x^{2n + 1}}{2n + 1}}_0^1 = \sum_{n = 0}^\infty \frac{(-1)^n}{n!(2n + 1)}</span>.</p>
</blockquote>
<p>Estimate <span class="math inline">\int_0^1 x^x \dee x</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\int_0^1 x^x \dee x = \int_0^1 e^{x \ln x} \dee x = \sum_{n = 0}^\infty \frac{1}{n!} \int_0^1 x^n \ln^n x \dee x</span>.<br />
Clearly, <span class="math inline">\int_0^1 x^n \ln^n x \dee x = \frac{(-1)^{n + 1}n!}{n^n}</span>. ;wip: what? how? even WolframAlpha can't evaluate this one So <span class="math inline">\int_0^1 x^x \dee x = \sum_{n = 0}^\infty \frac{(-1)^{n + 1}}{n^n}</span>.</p>
</blockquote>
<p>Estimate <span class="math inline">\int_0^1 \frac{\sin \ln x}{\ln x} \dee x</span>:</p>
<blockquote>
<p>Let <span class="math inline">u = \ln x</span>. Then <span class="math inline">\frac{\sin \ln x}{\ln x} = \frac{1}{u}\sin u = \sum_{n = 0}^\infty \frac{1}{u}\frac{(-1)^n}{(2n + 1)!} u^{2n + 1} = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1)!} \frac{u^{2n + 1}}{u} = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1)!} \ln^{2n} x</span>.<br />
So <span class="math inline">\int_0^1 \frac{\sin \ln x}{\ln x} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1)!} \int_0^1 \ln^{2n} x \dee x</span>.<br />
By taking a few values of <span class="math inline">n</span> and integrating by parts, we find that <span class="math inline">\int_0^1 \ln^{2n} x \dee x = (2n)!</span>.<br />
So <span class="math inline">\int_0^1 \frac{\sin \ln x}{\ln x} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1)!} (2n)! = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1}</span>.<br />
Recall that <span class="math inline">\arctan x = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1} x^{2n + 1}</span>. So <span class="math inline">\arctan 1 = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1}</span>.<br />
So <span class="math inline">\int_0^1 \frac{\sin \ln x}{\ln x} \dee x = \arctan 1 = \frac{\pi}{4}</span>.</p>
</blockquote>
<h1 id="section-32">27/3/14</h1>
<h3 id="evaluating-infinite-series">Evaluating Infinite Series</h3>
<p>We often want a closed form of a series.</p>
<p>Evaluate <span class="math inline">\sum_{n = 1}^\infty \frac{1}{n^2}</span>:</p>
<blockquote>
<p>All we know right now is that this converges and is between 1 and 2. Euler found several ways to find the exact value of this series.<br />
Clearly, <span class="math inline">\frac{\sin x}{x} = \frac{1}{x} \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!} = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n}}{(2n + 1)!}</span>.<br />
Clearly, <span class="math inline">\frac{\sin x}{x} = 1</span> if <span class="math inline">x = 0</span>, and <span class="math inline">\frac{\sin x}{x} = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n}}{(2n + 1)!}</span> if <span class="math inline">x \ne 0</span>.<br />
Clearly, any finite polynomial <span class="math inline">P(x)</span> such that <span class="math inline">P(0) = 1</span> and roots <span class="math inline">r_1, \ldots, r_n</span> can be written as <span class="math inline">(1 - \frac{x}{r_1}) \cdots (1 - \frac{x}{r_n})</span>.<br />
Assume this is also true for infinite polynomials as well. ;wip: this assumption is not always true Clearly, the roots of <span class="math inline">\frac{\sin x}{x}</span> are <span class="math inline">x = \pm \pi, \pm 2\pi, \ldots</span>.<br />
So <span class="math inline">\frac{\sin x}{x} = \left(\left(1 - \frac{x}{\pi}\right)\left(1 + \frac{x}{\pi}\right)\right)\left(\left(1 - \frac{x}{2\pi}\right)\left(1 + \frac{x}{2\pi}\right)\right) \cdots = \left(1 - \frac{x^2}{\pi^2}\right)\left(1 - \frac{x^2}{2^2\pi^2}\right) \cdots</span>.<br />
So <span class="math inline">\sum_{n = 0}^\infty \frac{(-1)^n x^{2n}}{(2n + 1)!} = \left(1 - \frac{x^2}{\pi^2}\right)\left(1 - \frac{x^2}{2^2\pi^2}\right) \cdots</span>.<br />
Clearly, <span class="math inline">\left(1 - \frac{x^2}{\pi^2}\right)\left(1 - \frac{x^2}{2^2\pi^2}\right) \cdots = 1 - \frac{x^2}{\pi^2}\left(\frac{1}{1^2} + \frac{1}{1^2} + \ldots\right) + x^4(\ldots) - x^6(\ldots) + \ldots</span>.<br />
Clearly, the coefficients of <span class="math inline">x^2</span> must match. So <span class="math inline">-\frac{1}{3!} = -\frac{1}{\pi}^6 \sum_{n = 1}^\infty \frac{1}{n^2}</span>.<br />
So <span class="math inline">\sum_{n = 1}^\infty \frac{1}{n^2} = \frac{\pi^2}{6}</span>.<br />
In fact, we can also equate the coefficients of <span class="math inline">x^4</span>, <span class="math inline">x^6</span>, and etc. to obtain things like <span class="math inline">\sum_{n = 1}^\infty \frac{1}{26} = \frac{1315862 \pi^{26}}{11094481976030578125}</span>.<br />
;wip: talk about odd powers and how to derive the even powers directly</p>
</blockquote>
<h2 id="parametric-curves">Parametric Curves</h2>
<p>We now consider functions with a single output and a vector output. For example, the position of a particle with respect to time, <span class="math inline">\vec{r}(t) = \begin{bmatrix} x(t) \\ y(t) \\ z(t) \end{bmatrix}</span>. This has many applications in physics.</p>
<p>The function <span class="math inline">\vec{r}(t)</span> defines a curve in the dimension of the vector. Here, <span class="math inline">t</span> is the <strong>parameter</strong> of the function.</p>
<p>These functions are also called <strong>parametric curves</strong>.</p>
<p>We do calculus on these functions by working with each component separately. As a result, calculus on parametric curves are no more difficult than calculus on normal functions.</p>
<p>For example, <span class="math inline">\vec{r}(t) = \begin{bmatrix} t \\ \abs{t} \end{bmatrix}</span> simply looks like the absolute value function on <span class="math inline">\begin{bmatrix} x \\ y \end{bmatrix} = \vec{r}(t)</span>.</p>
<p>However, the additional information is the direction along the curve - the velocity, in our case.</p>
<h1 id="section-33">31/3/14</h1>
<p>Parametric curves allow us to describe curves that would be very difficult or impossible to represent as s imple functions of <span class="math inline">x</span>. This is much more general than curves on a plane.</p>
<p>Parametric curves also have a direction vector along the curve. The direction always goes from a low <span class="math inline">t</span> to a high <span class="math inline">t</span>. This contrasts with curves on a plane, which does not have a direction along the curve.</p>
<p>For example, <span class="math inline">\vec{r}(t) = (t^2, t), t \in [0, 1]</span>. Since <span class="math inline">x = t^2</span> and <span class="math inline">y = t</span>, <span class="math inline">y = \sqrt{x} = t</span>, which is a form that allows us to plot the function easily.</p>
<p>Parametric curves are hard to plot because we are not used to them. However, parametric curves of the form <span class="math inline">\vec{r}(t) = (t, f(t))</span> can simply be plotted using <span class="math inline">y = f(t)</span>. Likewise, parametric curves of the form <span class="math inline">\vec{r}(t) = (f(t), t)</span> can simply be plotted using <span class="math inline">x = f(t)</span>, or <span class="math inline">y = f^{-1}(t)</span>. Also, the direction vector is rightwards, because as <span class="math inline">t</span> increases, the corresponding coordinate <span class="math inline">\vec{r}(t)</span> moves rightward.</p>
<p>Consider <span class="math inline">\vec{r}(t) = (a \cos t, a \sin t), t \in [0, 2\pi]</span>. Since <span class="math inline">x = a \cos t, y = a \sin t</span>, <span class="math inline">x^2 + y^2 = a^2(\sin^2 t + \cos^2 t) = a^2</span>. So this is a circle of radius <span class="math inline">a</span>. The circle starts at <span class="math inline">(a, 0)</span>, and travels counterclockwise until it reaches the starting point again.</p>
<p>Given a value of <span class="math inline">t</span> for <span class="math inline">\vec{r}(t) = (f(t), g(t))</span> and <span class="math inline">y = f(x)</span>, we can plot it in an inverval of <span class="math inline">t \in [a, b]</span> by plotting for <span class="math inline">x \in [f(a), f(b)]</span>.</p>
<p>The parameterization of a curve is not unique, just like normal curves. Every parametric curve has infinite different ways of being represented mathematically, but when drawn on a plane each curve has only one shape.</p>
<p>For example, consider <span class="math inline">\vec{r}(t) = (a \cos t, b \sin t)</span>. This is an ellipse where <span class="math inline">a &gt; b</span> stretches it horiontally and <span class="math inline">b &gt; a</span> stretches it vertically. We can rewrite it as <span class="math inline">\frac{x^2}{a^2} + \frac{y^2}{b^2} = 1</span> to plot it on a Cartesian plane.</p>
<p>We plot parametric curves by solving for <span class="math inline">t</span> in <span class="math inline">x = x(t)</span>, so <span class="math inline">t = x^{-1}(x)</span>, then subsituting into <span class="math inline">y(t)</span> to get <span class="math inline">y = y(x^{-1}(x))</span>, which is a non-parametric function we can plot more easily.</p>
<p>Alternatively, we would have to plot both <span class="math inline">y = y(t)</span> and <span class="math inline">x = x(t)</span>, and use these graphs to plot the points on <span class="math inline">\vec{r}(t) = (x(t), y(t))</span>.</p>
<h3 id="hyperbolic-functions">Hyperbolic Functions</h3>
<p>The functions <span class="math inline">\vec{r} = (a \cos t, b \sin t)</span> are called <strong>circular/elliptical trigonometric fucntions</strong>.</p>
<p>The hyperbolic trigonometric funnctions are called hyperbolic for a reason. Consider <span class="math inline">\vec{r}(t) = (a \cosh t, b \sinh t)</span>.</p>
<p>In fact, this creates a <strong>hyperbola</strong>, which looks like a parabola and another instance of that parabola flipped about the x-axis, or the same thing sideways. They are always symmetrical about the x-axis and y-axis.</p>
<p>A hyperbola is a curve defined by <span class="math inline">\frac{x^2}{a^2} - \frac{y^2}{b^2} = 1</span>. We can derive this form by using the identity <span class="math inline">\cosh^2 t - \sinh^2 t = 1</span>.</p>
<h1 id="section-34">2/4/14</h1>
<p>;wip: final exam MC 4061 thursday April 10 4pm</p>
<p>We can sketch this by rearranging the formula to get <span class="math inline">y = \pm \sqrt{\frac{b^2}{a^2}x^2 - b^2}</span>.</p>
<p>When <span class="math inline">x</span> or <span class="math inline">y</span> gets large, <span class="math inline">y \approxeq \pm \frac{b}{a}x</span> - the function has lines for asymptotes.</p>
<p>At <span class="math inline">x = 0</span>, <span class="math inline">y = \pm \sqrt{-b^2}</span>, which is imaginary, so there is no y-intercept.</p>
<p>At <span class="math inline">y = 0</span>, <span class="math inline">x = \pm a</span>, which are the x-intercepts.</p>
<p>Imagine a wheel of radius <span class="math inline">a</span> rolling along a level surface. If we observe from the reference frame of the surface, then a point on the edge of the wheel would create a bumpy curve. This curve is called a <strong>cycloid curve</strong>.</p>
<p>The cycloid curve can easily be parametrically defined by <span class="math inline">\vec{r}(t) = (at - a \sin t, a - a \cos t)</span>. The <span class="math inline">at</span> term moves the curve horizontally, and the <span class="math inline">a</span> term moves above the x-axis.</p>
<p>This function is very difficult to write in terms of <span class="math inline">y(x)</span>.</p>
<p>;wip: figure out how to convert parametrics to implicit functions</p>
<p>Parametric curves are not limited to <span class="math inline">\mb{R}^2</span>. If we extend them into <span class="math inline">\mb{R}^n</span>, then we can have <span class="math inline">n</span> dimensional curves.</p>
<h3 id="calculus-on-parametric-curves">Calculus on Parametric Curves</h3>
<p>To perform calculus on vector valued functions, we simply note that the vector valued function is a vector of single variable functions: <span class="math inline">\vec{r}(t) = (x(t), y(t))</span>, and we can apply the operations to the single variable functions.</p>
<p>For example, <span class="math inline">\lim_{t \to a} \vec{r}(t) = \vec{L} \iff \lim_{t \to a} x(t) = L_1 \wedge \lim_{t \to a} y(t) = L_2</span>.</p>
<p>In the same way, <span class="math inline">\frac{\dee \vec{r}}{\dee t} = (\frac{\dee x}{\dee t}, \frac{\dee y][\dee t})</span>. This is also known as the <strong>tangent vector</strong>.</p>
<p>This is the reason that the velocity of the object is tangent to its motion - it is the tangent vector of position.</p>
<p>Consider <span class="math inline">\magn{\frac{\dee \vec{r}}{\dee t}}</span>. This is the speed if <span class="math inline">\vec{r}(t)</span> is the position. This allows us to find the length of a curve (also known as distance or arclength) given its parametric curve.</p>
<p>The length of a curve from <span class="math inline">t = a</span> to <span class="math inline">t = b</span> is <span class="math inline">\int_a^b \magn{\frac{\dee \vec{r}}{\dee t}} \dee t</span>.</p>
<p>For example, find the circumference of the circle <span class="math inline">\vec{r}(t) = (a \cos t, a \sin t)</span> for <span class="math inline">t \in [0, 4\pi]</span>:</p>
<blockquote>
<p>Clearly, the length is <span class="math inline">\int_a^b \magn{\frac{\dee \vec{r}}{\dee t}} \dee t = \int_0^{4 \pi} \sqrt{\left(\frac{\dee}{\dee t} a \cos t\right)^2 + \left(\frac{\dee}{\dee t} a \sin t\right)^2} \dee t</span> ;wip</p>
</blockquote>
<p>For example, <span class="math inline">\vec{r}(t) = (a \cos t, a \sin t, t)</span> is a spiral upwards.</p>
<h1 id="section-35">4/4/14</h1>
<p>Find the arc length of <span class="math inline">\vec{r}(t) = (a \cos t, a \sin t, t)</span> for <span class="math inline">t \in [0, 4 \pi]</span>:</p>
<blockquote>
<p>This is a spiral going upwards.<br />
Clearly, <span class="math inline">\frac{\dee \vec{r}}{\dee t} = (-a \sin t, a \cos t, 1)</span>.<br />
Clearly, the arc length is <span class="math inline">\int_0^{4 \pi} \magn{\frac{\dee \vec{r}}{\dee t}} \dee t = \int_0^{4 \pi} \sqrt{a^2 \sin^2 t + a^2 \cos^2 t + 1^2} \dee t = \int_0^{4 \pi} \sqrt{a^2 + 1} \dee t</span>.<br />
So the arc length is <span class="math inline">4 \pi \sqrt{a^2 + 1}</span>.</p>
</blockquote>
<p>Find the arc length of the cycloid function <span class="math inline">\vec{r}(t) = (at - a \sin t, a - a \cos t)</span> for <span class="math inline">t \in [0, 2 \pi]</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\frac{\dee \vec{r}}{\dee t} = (a - a \cos t, a \sin t)</span> and <span class="math inline">\magn{\frac{\dee \vec{r}}{\dee t}}</span>.<br />
Clearly, <span class="math inline">\magn{\frac{\dee \vec{r}}{\dee t}} = \sqrt{a^2 - 2a^2 \cos t + a^2 \cos^2 t + a^2 \sin t} = \sqrt{2a^2 - 2a^2 \cos t} = a\sqrt{2 - 2 \cos t} = a\sqrt{4\left(\frac{1}{2} - \frac{1}{2} \cos t\right)} = 2a\sqrt{\frac{1}{2} - \frac{1}{2} \cos t}</span>.<br />
Recall the half angle formula <span class="math inline">\sin^2 t = \frac{1}{2} - \frac{1}{2} \cos 2t</span>.<br />
Clearly, <span class="math inline">2a\sqrt{\frac{1}{2} - \frac{1}{2} \cos t} = 2a\sqrt{\sin^2 \frac{t}{2}} = 2a\abs{\sin \frac{t}{2}}</span>.<br />
Since we are working in a range where <span class="math inline">\frac{t}{2} \in [0, \pi]</span>, <span class="math inline">\abs{\sin \frac{t}{2}} = \sin \frac{t}{2}</span>.<br />
Clearly, <span class="math inline">\int_0^{2\pi} \magn{\frac{\dee \vec{r}}{\dee t}} \dee t = 2a\int_0^{2\pi} \sin \frac{t}{2} \dee t = 2a\evalat{2\cos \frac{t}{2}}_0^{2\pi} = 8a</span>.<br />
So the arc length is <span class="math inline">8a</span>.</p>
</blockquote>
<h3 id="slope">Slope</h3>
<p>The <strong>slope of a tangent vector</strong> is <span class="math inline">\frac{\dee y}{\dee x}</span>. We can find it using <span class="math inline">\frac{\dee y}{\dee x} = \frac{\frac{\dee y}{\dee t}}{\frac{\dee x}{\dee t}}</span>.</p>
<p>Find the slope of <span class="math inline">\vec{r}(t) = (\cos t, \sin t)</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">\frac{\dee y}{\dee x} = \frac{-\sin t}{\cos t} = -\tan t</span>.<br />
This is where the <span class="math inline">\tan</span> function gets its name - it is the slope of the tangent of a circle at any given angle.</p>
</blockquote>
<p>Consider <span class="math inline">\frac{\dee^2 y}{\dee x^2}</span>. We might think that <span class="math inline">\frac{\dee^2 y}{\dee x^2} = \frac{\frac{\dee^2 y}{\dee t^2}}{\frac{\dee^2 x}{\dee t^2}}</span>, but this is incorrect.</p>
<p>In fact, <span class="math inline">\frac{\dee^2 y}{\dee x^2} = \frac{\dee}{\dee x} \frac{\dee y}{\dee x} = \frac{\frac{\dee}{\dee t} \frac{\dee y}{\dee x}}{\frac{\dee x}{\dee t}} = \frac{\frac{\dee}{\dee t} \frac{\dee y}{\dee x}}{\frac{\dee x}{\dee t}}</span>.</p>
<h3 id="area">Area</h3>
<p>The area under a curve of a function is given by <span class="math inline">y = F(x)</span> is <span class="math inline">A = \int_{x_1}^{x_2} F(x) \dee x</span>.</p>
<p>For parametric curves, we have <span class="math inline">x = x(t)</span> and <span class="math inline">y = y(t)</span>. Then there exists <span class="math inline">y = F(x)</span> - a function of <span class="math inline">x</span> equivalent to <span class="math inline">y</span>, and <span class="math inline">y(t) = F(x)</span>.</p>
<p>Then <span class="math inline">x_1 = x(t_1)</span> and <span class="math inline">x_2 = x(t_2)</span>, and <span class="math inline">\dee x = \frac{\dee x}{\dee t} \dee t</span>.</p>
<p>So <span class="math inline">A = \int_{t_1}^{t_2} F(x) \dee x = \int_{t_1}^{t_2} y(t) \dee x = \int_{t_1}^{t_2} y(t) \frac{\dee x}{\dee t} \dee t</span>.</p>
<p>This allows us to find the area under a curve.</p>
<p>;wip: I finally get <span class="math inline">u</span> substitution - it was inconsistent because sometimes u was a function of u, and sometimes x is a function of u.</p>
<p>;wip: is the limit test adding 1 to the exponent, or is it the next term when we have things like <span class="math inline">x^{2n}</span>? wikipedia says the latter but in class it was the former</p>
<p>Find the area under the cycloid curve <span class="math inline">\vec{r}(t) = (at - a \sin t, a - a \cos t)</span> for <span class="math inline">t \in [0, 2 \pi]</span>:</p>
<blockquote>
<p>Clearly, <span class="math inline">A = \int_0^{2 \pi} (a - a \cos t) \frac{\dee}{\dee t} (at - a \sin t) \dee t = \int_0^{2 \pi} (a - a \cos t)(a - a \cos t) \dee t = 2 \pi a^2 + \int_0^{2 \pi} -2a^2 \cos t \dee t + \int_0^{2 \pi} + a^2 \cos^2 t \dee t = 3 \pi a^2</span>.<br />
So the cycloid curve has an area of <span class="math inline">3 \pi a^2</span> units.</p>
</blockquote>
<p>To find the value of an infinite series, we take a known series, then apply transformations to it until it is the function we need.</p>
<div class="status-banner" style="display: none; position: fixed; bottom: 0; left: 0; right: 0; text-align: center;">
    <div style="display: inline-block; padding: 0.8em 2em 0.5em 2em; background: black; color: white; font-size: 2em;">
        Rendering <svg xmlns="http://www.w3.org/2000/svg" height="1.4em" viewbox="0 0 1200 500" style="vertical-align: text-bottom"><title>LaTeX logo</title><g transform="matrix(45 0 0 45 40 40)" fill="white"><path d="M5.5 4.4C5.5 4.4 5.2 4.4 5.2 4.4 5.1 5.4 5 6.7 3.2 6.7 3.2 6.7 2.4 6.7 2.4 6.7 1.9 6.7 1.9 6.6 1.9 6.3 1.9 6.3 1.9 1 1.9 1 1.9 0.6 1.9 0.5 2.9 0.5 2.9 0.5 3.2 0.5 3.2 0.5 3.2 0.5 3.2 0.2 3.2 0.2 2.8 0.2 1.9 0.2 1.5 0.2 1.1 0.2 0.3 0.2 0 0.2 0 0.2 0 0.5 0 0.5 0 0.5 0.2 0.5 0.2 0.5 1 0.5 1 0.6 1 0.9 1 0.9 1 6.2 1 6.2 1 6.6 1 6.7 0.2 6.7 0.2 6.7 0 6.7 0 6.7 0 6.7 0 7 0 7 0 7 5.2 7 5.2 7 5.2 7 5.5 4.4 5.5 4.4z"/><path d="M5.3 0.2C5.3 0 5.2 0 5.1 0 5 0 4.9 0 4.9 0.2 4.9 0.2 3.3 4.2 3.3 4.2 3.2 4.4 3.1 4.7 2.5 4.7 2.5 4.7 2.5 5 2.5 5 2.5 5 4 5 4 5 4 5 4 4.7 4 4.7 3.7 4.7 3.5 4.6 3.5 4.4 3.5 4.3 3.5 4.3 3.6 4.2 3.6 4.2 3.9 3.4 3.9 3.4 3.9 3.4 5.9 3.4 5.9 3.4 5.9 3.4 6.3 4.4 6.3 4.4 6.3 4.4 6.3 4.5 6.3 4.5 6.3 4.7 5.9 4.7 5.8 4.7 5.8 4.7 5.8 5 5.8 5 5.8 5 7.7 5 7.7 5 7.7 5 7.7 4.7 7.7 4.7 7.7 4.7 7.6 4.7 7.6 4.7 7.1 4.7 7.1 4.7 7 4.5 7 4.5 5.3 0.2 5.3 0.2zM4.9 0.9C4.9 0.9 5.8 3.1 5.8 3.1 5.8 3.1 4 3.1 4 3.1 4 3.1 4.9 0.9 4.9 0.9z"/><path d="M13.3 0.2C13.3 0.2 7.2 0.2 7.2 0.2 7.2 0.2 7 2.5 7 2.5 7 2.5 7.3 2.5 7.3 2.5 7.4 0.9 7.6 0.5 9.1 0.5 9.3 0.5 9.5 0.5 9.6 0.6 9.8 0.6 9.8 0.7 9.8 0.9 9.8 0.9 9.8 6.2 9.8 6.2 9.8 6.5 9.8 6.7 8.8 6.7 8.8 6.7 8.4 6.7 8.4 6.7 8.4 6.7 8.4 7 8.4 7 8.8 6.9 9.8 6.9 10.3 6.9 10.7 6.9 11.7 6.9 12.2 7 12.2 7 12.2 6.7 12.2 6.7 12.2 6.7 11.8 6.7 11.8 6.7 10.7 6.7 10.7 6.5 10.7 6.2 10.7 6.2 10.7 0.9 10.7 0.9 10.7 0.7 10.7 0.6 10.9 0.6 11 0.5 11.3 0.5 11.5 0.5 13 0.5 13.1 0.9 13.2 2.5 13.2 2.5 13.5 2.5 13.5 2.5 13.5 2.5 13.3 0.2 13.3 0.2z"/><path d="M18.7 6.7C18.7 6.7 18.4 6.7 18.4 6.7 18.2 8.2 17.9 8.9 16.2 8.9 16.2 8.9 14.9 8.9 14.9 8.9 14.4 8.9 14.4 8.8 14.4 8.5 14.4 8.5 14.4 5.9 14.4 5.9 14.4 5.9 15.3 5.9 15.3 5.9 16.3 5.9 16.4 6.2 16.4 7 16.4 7 16.6 7 16.6 7 16.6 7 16.6 4.4 16.6 4.4 16.6 4.4 16.4 4.4 16.4 4.4 16.4 5.2 16.3 5.5 15.3 5.5 15.3 5.5 14.4 5.5 14.4 5.5 14.4 5.5 14.4 3.2 14.4 3.2 14.4 2.8 14.4 2.8 14.9 2.8 14.9 2.8 16.2 2.8 16.2 2.8 17.7 2.8 18 3.3 18.1 4.7 18.1 4.7 18.4 4.7 18.4 4.7 18.4 4.7 18.1 2.5 18.1 2.5 18.1 2.5 12.5 2.5 12.5 2.5 12.5 2.5 12.5 2.8 12.5 2.8 12.5 2.8 12.7 2.8 12.7 2.8 13.5 2.8 13.5 2.9 13.5 3.2 13.5 3.2 13.5 8.4 13.5 8.4 13.5 8.8 13.5 8.9 12.7 8.9 12.7 8.9 12.5 8.9 12.5 8.9 12.5 8.9 12.5 9.2 12.5 9.2 12.5 9.2 18.2 9.2 18.2 9.2 18.2 9.2 18.7 6.7 18.7 6.7z"/><path d="M21.7 3.1C21.7 3.1 23 1.1 23 1.1 23.3 0.8 23.6 0.5 24.5 0.5 24.5 0.5 24.5 0.2 24.5 0.2 24.5 0.2 22.1 0.2 22.1 0.2 22.1 0.2 22.1 0.5 22.1 0.5 22.5 0.5 22.7 0.7 22.7 0.9 22.7 1 22.7 1.1 22.6 1.2 22.6 1.2 21.5 2.8 21.5 2.8 21.5 2.8 20.2 0.9 20.2 0.9 20.2 0.9 20.1 0.8 20.1 0.8 20.1 0.7 20.4 0.5 20.8 0.5 20.8 0.5 20.8 0.2 20.8 0.2 20.4 0.2 19.7 0.2 19.3 0.2 19 0.2 18.4 0.2 18 0.2 18 0.2 18 0.5 18 0.5 18 0.5 18.2 0.5 18.2 0.5 18.8 0.5 19 0.5 19.2 0.8 19.2 0.8 21 3.6 21 3.6 21 3.6 19.4 6 19.4 6 19.2 6.2 18.9 6.7 17.9 6.7 17.9 6.7 17.9 7 17.9 7 17.9 7 20.3 7 20.3 7 20.3 7 20.3 6.7 20.3 6.7 19.8 6.7 19.7 6.4 19.7 6.2 19.7 6.1 19.7 6.1 19.8 6 19.8 6 21.2 3.9 21.2 3.9 21.2 3.9 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.4 22.8 6.5 22.6 6.7 22.2 6.7 22.2 6.7 22.2 7 22.2 7 22.5 6.9 23.2 6.9 23.6 6.9 24 6.9 24.5 7 24.9 7 24.9 7 24.9 6.7 24.9 6.7 24.9 6.7 24.7 6.7 24.7 6.7 24.2 6.7 24 6.6 23.8 6.3 23.8 6.3 21.7 3.1 21.7 3.1z"/></g></svg> math...
    </div>
</div>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Anthony Zhang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2017 Anthony Zhang.
</div>
</body>
</html>
